\chapter{Pathways to coeffects} 
\label{ch:related-work} 

%---------------------------------------------------------------------------------------------------

There are many different directions from which the concept of \emph{coeffects} can be approached 
and, indeed, discovered. In the previous chapter, we motivated it by practical applications, but 
coeffects also naturally arise as an extension to a number of programming language theories.
Thanks to the Curry-Howard-Lambek correspondence, we can approach coeffects from the perspective of 
type theory, logic and also category theory. This chapter gives an overview of the most 
important directions.

We start by revisiting practical applications and existing language features that are related to 
coeffects (Section~\ref{sec:path-apps}), then we look at coeffects as the dual of effect systems
(Section~\ref{sec:path-eff}) and extend the duality to category theory, looking at the categorical 
dual of monads known as \emph{comonads} (Section~\ref{sec:path-sem}). Finally we look at logically 
inspired type systems that are closely related to our structural coeffects 
(Section~\ref{sec:path-logic}).

This chapter serves two purposes. Firstly, it provides a high-level overview of the  related work, 
although technical details are often postponed until later. Secondly it recasts existing ideas in 
a way that naturally leads to the coeffect systems developed later in the thesis. For this reason, 
we are not always faithful to the referenced work -- sometimes we focus on aspects that the 
authors consider unimportant or present the work differently than originally intended. The reason 
is to fulfil the second goal of the chapter. When we do so, this is explicitly said in the text.

%===================================================================================================

\section{Through applications}
\label{sec:path-apps}

The general theme of this thesis is improving programming languages to better support writing
\emph{context-dependent} (or \emph{context-aware}) computations. With current trends in the 
computing industry such as mobile and ubiquitous computing, this is becoming an important topic.
In software engineering and programming community, a number of authors have addressed this problem
from different perspectives. Hirschfeld et al. propose \emph{Context-Oriented Programming} (COP)
as a methodology \cite{app-cop-method}, and the subject has also been addressed in mobile
computations \cite{app-cop-mobile,app-cop-mobile2}. In programming languages, Costanza 
\cite{app-cop-contextl} develops a domain-specific LISP-like language ContextL and Bardram 
\cite{app-cop-javafwk} proposes a Java framework for COP.

We approach the problem from a different perspective, building on the tradition of 
statically-typed functional programming languages and their theories. However, even in this field,
there is a number of calculi or language features that can be viewed as context-dependent.

%---------------------------------------------------------------------------------------------------

\subsection{Motivation for flat coeffects}

In a number of systems, the execution environment provides some additional data, resources or 
information about the execution context, but are independent of the variables used by the 
program. We look at implicit parameters and rebindable resources (that both provide additional
identifiers that can be accessed similarly to variables, but follow different scoping rules),
distributed programming, cross-compilation and data-flow.

%---------------------------------------------------------------------------------------------------

\paragraph{Implicit parameters} In Haskell, implicit parameters \cite{app-implicit-parameters} are 
a special kind of variables that may behave as dynamically scoped. This means, if a function uses 
parameter $\ident{?p}$, then the caller of the function must define $\ident{?p}$ and set its value.
Implicit parameters can be used to parameterise a computation (involving a chain of function calls)
without passing parameters explicitly as additional arguments of all involved functions. A simple 
language with implicit parameters has an expression $\ident{?p}$ to read a parameter value and an 
expression\footnote{Haskell uses $\kvd{let}~\ident{?p} = e_1~\kvd{in}~e_2$, but we use a different keyword to 
avoid confusion.} $\kvd{letdyn}~?p = e_1~\kvd{in}~e_2$ that sets a parameter $\ident{?p}$ to the value of $e_1$ 
and evaluates $e_2$ in a context containing $\ident{?p}$

An interesting question arises when we use implicit parameters in a nested function. The following 
function does some pre-processing and then returns a function that builds a formatted string based 
on two implicit parameters $\ident{?width}$ and $\ident{?size}$:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{format} = \lambda \ident{str}~\rightarrow \\
\quad \kvd{let}~\ident{lines} = \ident{formatLines}~\ident{str}~\ident{?width}~\kvd{in}\\
\quad (\lambda \ident{rest}~\rightarrow~\ident{append}~
         \ident{lines}~\ident{rest}~\ident{?width}~\ident{?size})\\
\end{array}
\end{equation*}
%
The body of the outer function accesses the parameter $\ident{?width}$, so it certainly requires a context 
$\{ \ident{?width} : \ident{int} \}$. The nested function (returned as a result) uses the parameter 
$\ident{?width}$, but in addition also uses $\ident{?size}$. Where should the parameters of the nested 
function come from?

In a purely dynamically scoped system, they would have to be defined when the user invokes the nested function.
However, in Haskell, implicit parameters behave as a combination of lexical and dynamic scoping. This means
that the nested function can capture the value of $\ident{?width}$ and require just $\ident{?size}$
In Haskell, this corresponds to the following type:
%
\begin{equation*}
(\ident{?width} :: \ident{Int}) \Rightarrow \ident{String} \rightarrow 
  ((\ident{?size} :: \ident{Int}) \Rightarrow \ident{String} \rightarrow \ident{string})
\end{equation*}
%
As a result, the function can be called as follows:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{formatHello} = \\
\quad(~\kvd{letdyn}~\ident{?width}=5~\kvd{in}\\
\quad~~\ident{format}~\texttt{"Hello"})~~\kvd{in}\\
\kvd{letdyn}~\ident{?size} = 10~\kvd{in}~\ident{formatHello}~\texttt{"world"}
\end{array}
\end{equation*}
%
This way of assigning type to \ident{format} and calling it is not the only possible, though. 
We could also say that the outer function requires both of the implicit parameters and the result
is a (pure) function with no context requirements. This interaction between implicit parameters 
and lambda abstraction demonstrates one of the key aspects of coeffects and will be discussed 
later. Implicit parameters will also sever as one of our examples in Chapter~Y.

%---------------------------------------------------------------------------------------------------

\paragraph{Type classes}
Implicit parameters are closely related to \emph{type classes} \cite{app-type-classes}. In Haskell,
type classes provide a principled form of ad-hoc polymorphism (overloading). When a code uses 
an overloaded operation (e.g.~comparison or numeric operators) a constraint is placed on the 
context in which the operation is used. For example:
%
\begin{equation*}
\begin{array}{l}
\ident{twoTimes}~::~\ident{Num}~\alpha \Rightarrow \alpha \rightarrow \alpha \\
\ident{twoTimes}~x=x+x
\end{array}
\end{equation*}
%
The constraint $\ident{Num}~a$ on the function type arises from the use of the $+$ operator. 
From the implementation perspective, the type class constraint means that the function takes 
a hidden parameter -- a dictionary that provides the operation $+ :: \alpha \rightarrow \alpha \rightarrow \alpha$.
Thus, the type $\ident{Num}~\alpha \Rightarrow \alpha \rightarrow \alpha$ can be viewed as
$(\ident{Num}_\alpha \times \alpha) \rightarrow \alpha$. Implicit parameters work in exactly
the same way -- they are passed around as hidden parameters.

The implementation of type classes and implicit parameters shows two important points about 
context-dependent properties. First, they are associated with some \emph{scope}, such as the body
of a function. Second, they are associated with the input. To call a function that takes an 
implicit parameter or has a type-class constraint, the caller needs to pass a (hidden) parameter
together with the function inputs.

%---------------------------------------------------------------------------------------------------

\paragraph{Rebindable resources}
The need for parameters that do not strictly follow static scoping rules also arises in distributed
computing. This problem has been addressed, for example, by Bierman et al. and Sewell et al. 
\cite{app-distributed-rebinding,app-distributed-acute}. To quote the first work: \emph{``Dynamic 
binding is required in various guises, for example when a marshalled value is received from the 
network, containing identifiers that must be rebound to local resources.''}

This situation arises when marshalling and transferring function values. A function may depend 
on a local resource (e.g.~a database available only on the server) and also resources that are 
available on the target node (e.g.~current time). In the following example, the construct
$\kvd{access}~\ident{Res}$ represents access to a re-bindable resource named $\ident{Res}$:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{recentEvents} = \lambda () \rightarrow\\
\quad\kvd{let}~\ident{db} = \kvd{access}~\ident{News}~\kvd{in}\\
\quad\ident{query}~\ident{db}~\str{"SELECT * WHERE Date > \%1"}~(\kvd{access}~\ident{Clock})
\end{array}
\end{equation*}
%
When \ident{recentEvents} is created on a server and sent to a client, a remote reference to the 
database (available only on the server) must be captured. If the client device supports a clock, 
then \ident{Clock} can be locally \emph{rebound}, e.g., to accommodate time-zone changes. 
Otherwise, the date and time needs to be obtained from the server too.

The use of re-bindable resources creates a context requirement similar to the one arising from
the use of implicit parameters. For function values, such context-requirements can be satisfied
in different ways -- resources must be available either at the declaration site (i.e.~when a 
function is created) or at the call site (i.e.~when a function is called).

%---------------------------------------------------------------------------------------------------

\paragraph{Distributed computing and multi-targetting}

An increasing number of programming languages is capable of running across multiple different 
platforms or execution environments. Functional programming languages that can be compiled to
JavaScript (to target web and mobile clients) include, among others, F\#, Haskell and OCaml \cite{app-ocaml-js}.

Links \cite{app-distributed-links}, F\# libraries \cite{app-fsharp-webapps,app-fsharp-webtools},
ML5 and QWeSST \cite{app-distributed-ml5, app-distributed-qwesst} and Hop \cite{app-hop-lang} go 
further and allow a single source program to be compiled to multiple target runtimes. This posses 
additional challenges -- it is necessary to track where each part of computation runs and statically 
guarantee that it will be possible to compile code to the required target platform 
(safe \emph{multi-targetting}).

We demonstrate the problem by looking at input validation. In distributed applications 
that communicate over unsecured HTTP channel, user input needs to be validated interactively
on the client-side (to provide immediate response) and then again on the server-side (to 
guarantee safety). For example:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{validateInput} = \lambda \ident{name} \rightarrow\\
\quad\ident{name} \neq \str{""} ~~\&\&~~ \ident{forall~isLetter~name}
\\[0.5em]
\kvd{let}~\ident{displayProduct} = \lambda \ident{name} \rightarrow\\
\quad\kvd{if}~\ident{validateInput name}~\kvd{then}~\ident{displayProductPage~name}\\
\quad\kvd{else}~\ident{displayErrorPage}~() 
\end{array}
\end{equation*}
%
The function \ident{validateInput} can be compiled to both JavaScript (for client-side) and
native code (for server-side). However, \ident{displayProduct} uses other functionality
(generating web pages) that is only available on the server-side, so it can only be compiled to
native code.

In Links \cite{app-distributed-links}, functions can be annotated as client-side, server-side
and database-side. F\# WebTools \cite{app-fsharp-webtools} adds functions that support multiple
targets (mixed-side). However, these are single-purpose language features and they are not 
extensible. For example, in modern mobile development it is also important to track minimal 
supported version of runtime\footnote{Android Developer guide \cite{app-android-multitarget} 
demonstrates how difficult it is to solve the problem without language support.}. 

Requirements on the execution environment can be viewed as contextual properties, but could be
also presented as effects (use of some API required only in certain environment is a computational
effect). We discuss the difference in Section~X. Furthermore, the theoretical foundations of
distributed languages like ML5 \cite{app-distributed-ml5} suggest that a contextual treatment
is more appropriate. We return to ML5 when discussing semantics in Section~\ref{sec:path-sem-contextdep}.

%---------------------------------------------------------------------------------------------------

\paragraph{Data-flow languages}

The examples discussed so far are all -- to some extent -- similar. They attach additional 
information (implicit parameters, dictionaries) or restrictions (on execution environment) to the
context where code evaluates. By \emph{context}, we mean, most importantly, the values of variables
and declarations that are in scope. The examples so far add more information to the context, but
do not operate on the variable values.

Data-flow languages provide a different example. Lucid \cite{app-lucid} is a declarative data-flow 
language designed by Wadge and Ashcroft. In Lucid, variables represent streams and programs
are written as transformations over streams. A function application $\mathit{square}(a)$ represents
a stream of squares calculated from the stream of values $a$.

The data-flow approach has been successfully used in domains such as development of real-time embedded 
application where many \emph{synchronous languages} \cite{app-synchronous-lang} build on the data-flow
paradigm. The following example is inspired by the Lustre \cite{app-synchronous-lustre} language
and implements program to count the number of edges on a Boolean stream:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{edge} = \ident{false}~\kvd{fby}~(\ident{input}~\&\&~\ident{not}~(\kvd{prev}~\ident{input}))
\\[0.5em]
\kvd{let}~\ident{edgeCount} = \\
\quad 0~\kvd{fby}~ (~\kvd{if}~\ident{edge}~\kvd{then}~\kvd{prev}~\ident{edgeCount}\\
\quad\quad\quad~~~\, \kvd{else}~\kvd{prev}~\ident{edgeCount} ~)
\end{array}
\end{equation*}
%
The construct $\kvd{prev}~x$ returns a stream consisting of previous values of the stream 
$x$. The second value of $\kvd{prev}~x$ is first value of $x$ (and the first
value is undefined). The construct $y~\kvd{fby}~x$ returns a stream whose first element is the 
first element of $y$ and the remaining elements are values of $x$. Note that in Lucid, the constants
such as \ident{false} and $0$ are constant streams. Formally, the construct are defined as follows
(writing $x_n$ for $n$-th element of a stream $x$):
%
\[ 
(\kvd{prev}~x)_n = \left\{ 
  \begin{array}{ll}
    nil     & \; \text{if $n=0$}\\
    x_{n-1} & \; \text{if $n>0$}
  \end{array} \right.
\quad
(y~\kvd{fby}~x)_n = \left\{ 
  \begin{array}{ll}
    y_0     & \; \text{if $n=0$}\\
    x_n     & \; \text{if $n>0$}
  \end{array} \right.
\]  
%
When reading data-flow programs, we do not need to think about variables in terms of streams --
we can see them as simple values. However, the operations \kvd{fby} and \kvd{prev} cannot operate
on plain values -- they require additional \emph{context} which provides past values of variables
(for \kvd{prev}) and information about the current location in the stream (for \kvd{fby}). 

In this case, the context is not simply an additional (hidden) parameter. It completely changes
how variables must be represented. We may want to capture various \emph{contextual properties}
of Lucid programs. For example, how many past elements need to be cached when we evaluate the 
stream.

To understand the nature of the context, we later look at the semantics of Lucid. This can be
captured using a number of mathematical structures. Wadge \cite{app-lucid-monads} originally 
proposed to use monads, while Uustalu and Vene later used comonads \cite{app-dataflow-essence}.

%---------------------------------------------------------------------------------------------------

\subsection{Motivation for structural coeffects}

We now turn our attention to system where additional contextual information are associated not
with the context as a whole (or program scope), but with individual variables. We start by looking
simple static analysis -- variable \emph{liveness}. Then we revisit data-flow computations and
look at applications in security and software updating.

%---------------------------------------------------------------------------------------------------

\paragraph{Liveness analysis}

\emph{Live variable analysis} (LVA) \cite{app-modern-compiler} is a standard technique in compiler theory. 
It detects whether a free variable of an expression may be used by a program later (it is
\emph{live}) or whether it is definitely not needed (it is \emph{dead}). As an optimization, 
compiler can remove bindings to dead variables as the result is never accessed. Wadler 
\cite{app-strictness-absecnce} describes the property of a variable that is dead as the 
\emph{absence} of a variable. 

In this thesis, we first use a restricted (and not practically useful) form of liveness analysis
to introduce the theory of indexed comonads (Section~X) and then use liveness analysis as one of the
motivations for structural coeffects. Consider the following two simple functions:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{constant42} = \lambda \ident{x} \rightarrow 42\\
\kvd{let}~\ident{constant} = \lambda \ident{value} \rightarrow \lambda \ident{x} \rightarrow \ident{value}
\end{array}
\end{equation*}
%
In liveness analysis, we annotate the context with a value specifying whether the variables in
scope are \emph{live} or \emph{dead}. If we associate just a single value with the entire 
context, then the liveness analysis is very limited -- it can say that the context of the 
expression $42$ in the first function is dead, because no variables are accessed. 

A useful liveness analysis needs to consider individual variables. For example, in the body of
the second function (\ident{value}), two variables are in scope. The variable \ident{value} is
accessed and thus is \emph{live}, but the variable \ident{x} is dead.

Static analyses can be classified as either \emph{forward} or \emph{backward} (depending on how they 
propagate information) and as either \emph{must} or \emph{may} (depending on what properties they
guarantee). Liveness is a \emph{backward} analysis -- this means that the requirements propagates
from variables to their declaration sites. The distinction between \emph{must} and \emph{may} is 
apparent when we look at an example with conditionals:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{defaultArg}~= \lambda \ident{cond} \rightarrow \lambda \ident{input} \rightarrow\\
\quad\kvd{if}~\ident{cond}~\kvd{then}~42~\kvd{else}~\ident{input}
\end{array}
\end{equation*}
%
The liveness analysis is a \emph{may} analysis meaning that it marks variable as live when it
\emph{may} be used and as dead if it is \emph{definitely} not used. This means that the variable
\ident{input} is \emph{live} in the example above. A \emph{must} analysis would mark the variable
only if it was used in both of the branches (this is sometimes called \emph{neededness}).

The distinction between \emph{may} and \emph{must} analyses demonstrates the importance of 
interaction between contextual properties and certain language constructs such as conditionals.

% --------------------------------------------------------------------------------------------------

\paragraph{Data-flow languages (revisited)}
When discussing data-flow languages in the previous section, we said that the context provides 
past values of variables. This can be viewed as a flat contextual property (the context needs
to keep all past values), but we can also view it as a structural property. Consider the following
example:
%
\begin{equation*}
\kvd{let}~\ident{offsetZip} = 0~\kvd{fby}~(\ident{left} + \kvd{prev}~\ident{right})
\end{equation*}
%
The value \ident{offsetZip} adds values of \ident{left} with previous values of \ident{right}.
To evaluate a current value of the stream, we need the current value of \ident{left} and one past
value of \ident{right}. 

As mentioned earlier, a static analysis for data-flow computations could calculate how many past 
values must be cached. This can be done as a \emph{flat} coeffect analysis that produces just a 
single number for each function. However, we can design a more precise \emph{structural} analysis
and track the number of required elements for individual variables.

% --------------------------------------------------------------------------------------------------

\paragraph{Tainting and provenance}
Tainting is a mechanism where variables coming from potentially untrusted sources are marked
(\emph{tainted}) and the use of such variables is disallowed in contexts where untrusted input
can cause security issues or other problems. Tainting can be done dynamically as a runtime mark
(e.g.~in the Perl language) or statically using a type system. Tainting can be viewed as a special
case of \emph{provenance tracking}, known from database systems \cite{app-provenance-db}, where
values are annotated with more detailed information about their source.

Statically typed systems that based on tainting have been use to prevent cross-site scripting
attacks \cite{app-tainting-xss} and a well known attack known as SQL injection
\cite{app-tainting-sql,app-tainting-wasp}. In the latter chase, we want to check that SQL commands 
cannot be directly constructed from, potentially dangerous, inputs provided by the user. Consider the 
type checking of the following expression in a context containing variables \ident{id} and \ident{msg}:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{name} = \ident{query}~(\str{"SELECT Name WHERE Id = "}~+~\ident{id})~\kvd{in}\\
\ident{msg}~+~\ident{name}
\end{array}
\end{equation*}
%
In this example, \ident{id} must not come directly from a user input, because \ident{query} requires 
untainted string. Otherwise, the attacker could specify values such as \str{"1; DROP TABLE Users"}. 
The variable \ident{msg} may or may not be tainted, because it is not used in protected context 
(i.e.~to construct an SQL query). 

In runtime checking, all (string) values need to be wrapped in an object that stores Boolean 
flag (for tainting) or more complex data (for provenance). In static checking, the information
need to be associated with the variables in the variable context. We use tainting as a motivating
example for \emph{structural} coeffects in Section~X.

% --------------------------------------------------------------------------------------------------

\paragraph{Security and core dependency calculus}

The checking of tainting is a special case of checking of the \emph{non-interference} property 
in \emph{secure information flow}. Here, the aim is to guarantee that sensitive information (such
as credit card number) cannot be leaked to contexts with low secrecy (e.g.~sent via an unsecured
network channel). Volpano et al. \cite{app-secure-flow} provide the first (provably) sound type 
system that guarantees non-inference and Sabelfeld et al. \cite{app-secure-information-flow} survey
more recent work. The checking of information flows has been also integrated (as a single-purpose
extension) in the FlowCaml \cite{app-security-flowcaml} language. Finally, Russo et al. and 
Swamy et al. \cite{monad-secure-flow,monads-lightweight-ml} show that the properties can be checked
using a monadic library.

Systems for secure information flow typically define a lattice of security classes $(\mathcal{S}, \leq)$
where $\mathcal{S}$ is a finite set of classes and an ordering. For example a set $\{\ident{L}, \ident{H}\}$ 
represents low and high secrecy, respectively with $\ident{L} \leq \ident{H}$ meaning that low security
values can be treated as high security (but not the other way round).

An important aspect of secure information flow is called \emph{implicit flows}. Consider the following
example which may assign a new value to $z$:
%
\begin{equation*}
\kvd{if}~x>0~\kvd{then}~z := y
\end{equation*}
%
If the value of $y$ is high-secure, then $z$ becomes high-secure after the assignment
(this is an \emph{explicit} flow). However, if $x$ is high-secure, then the value of
$z$ becomes high-secure, regardless of the security level of $y$, because the fact whether an 
assignment is performed or not performed leaks information in its own (this is an 
\emph{implicit} flow).

Abadi et al. realized that there is a number of analyses similar to secure information flow
and proposed to unify them using a single model called Dependency Core Calculus (DCC) \cite{app-dcc}.
It captures other cases where some information about expression relies on properties of variables
in the context where it executes.  The DCC captures, for example, \emph{binding time analysis}
\cite{app-binding-time-analysis}, which detects which parts of programs can be partially evaluated
(do not depend on user input) and \emph{program slicing} \cite{app-slicing-survey} that identifies
parts of programs that contribute to the output of an expression.
	
% --------------------------------------------------------------------------------------------------

\subsection{Beyond passive contexts}

In the systems discussed so far, the context provides additional data (resources, implicit 
parameters, historical values) or meta-data (security, provenance). However, it is impossible to
write a function that modifies the context. We use the term \emph{passive} context for such 
applications. 

However, there is a number of systems where the context may be changed -- not just be evaluating
certain code block in a different scope (e.g. by wrapping it in $\ident{prev}$ in data-flow), but
also by calling a function that, for example, acquires new capabilities. While this thesis focuses
on systems with passive context, we quickly look at the most important examples of the 
\emph{active} variant.

% --------------------------------------------------------------------------------------------------

\paragraph{Calculus of capabilities}
Crary et al. \cite{app-capabilities} introduced the Calculus of Capabilities to provide 
a sound system with region-based memory management for low-level code that can be easily 
compiled to assembly language. They build on the work of Tofte and Talpin \cite{app-region-memory}
who developed an \emph{effect system} (discussed in Section~\ref{sec:path-sem-effects}) that uses
lexically scoped \emph{memory regions} to provide an efficient and controlled memory management.

In the work of Tofte and Talpin, the context is \emph{passive}. They extend a simple functional language
with the \kvd{letrgn} construct that defines a new memory region, evaluates an expression (possibly)
using memory in that region and then deallocates the memory of the region:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{calculate} = \lambda \ident{input} \rightarrow\\
\quad\kvd{letrgn}~\rho~\kvd{in}\\
\quad\kvd{let}~\ident{x} = \kvd{ref}_\rho \ident{input}~\kvd{in}~!\ident{x}
\end{array}
\end{equation*}
%
The memory region $\rho$ is a part of the context, but only in the scope of the body of 
\kvd{letrgn}. It is only available to the last line which allocates a memory cell in the region
and reads it (before the region is deallocated). There is no way to allocate a region inside a 
function and pass it back to the caller.

Calculus of capabilities differs in two ways. First, it allows explicit allocation and deallocation
of memory regions (and so region lifetimes do not follow strict LIFO ordering). Second, it
uses continuation-passing style. We ignore the latter aspect and so the following example:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{calculate} = \lambda \ident{input} \rightarrow\\
\quad \kvd{letrgn}~\rho~\kvd{in}\\
\quad \kvd{let}~\ident{x} = \kvd{ref}_\rho \ident{input}~\kvd{in}~\ident{x}
\end{array}
\end{equation*}
%
The example is almost identical to the previous one, except that it does not return the value
of reference \ident{x}. Instead, it returns the reference, which is located in a newly allocated
region. Together with the value, the function returns a \emph{capability} to access the region
$\rho$.

This is where systems with active context differ. To type check such programs, we do not only need
to know what context is required to call \ident{calculate}. We also need to know what effects it
has on the context when it evaluates and the current context meeds to be appropriately adjusted
after a function call. We briefly consider this problem in Section~X. % future work

% --------------------------------------------------------------------------------------------------

% \paragraph{Safe locking}
% Flanagan and Abadi \cite{app-safe-locking}
%
% => This has coeffect style judgments, but it has effect-style lambda
%

% --------------------------------------------------------------------------------------------------

\paragraph{Software updating}
Dynamic software updating (DSU) is the ability to update programs at runtime without stopping them.

Stoyle et al. \cite{app-dsu-mutatis}.

% --------------------------------------------------------------------------------------------------

\paragraph{Thesis perspective}
?

\newpage
%===================================================================================================

\section{Through type and effect systems}
\label{sec:path-eff}

Introduced by Gifford and Lucassen \cite{effects-gifford,effects-polymorphic}, type and effect 
systems have been designed to track effectful operations performed by computations. Examples 
include tracking of reading and writing from and to memory locations \cite{effects-talpin-et-al}, 
communication in message-passing systems \cite{effects-messagepassing} and atomicity in concurrent 
applications \cite{effects-atomicity}.

Type and effect systems are usually specified judgements of the form $\Gamma \vdash e : \alpha, \sigma$, 
meaning that the expression $e$ has a type $\alpha$ in (free-variable) context $\Gamma$ and 
additionally may have effects described by $\sigma$. Effect systems are typically added to a 
language that already supports effectful operations as a way of increasing the safety -- the type
and effect system provides stronger guarantees than a plain type system. Filinsky 
\cite{effects-comprehensive} refers to this approach as \emph{descriptive}\footnote{In contrast
to \emph{prescriptive} effect systems that implement computational effects in a pure language 
-- such as monads in Haskell}.

%---------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\inference[(var)]
  {x:\alpha \in \Gamma }
  {\Gamma \vdash x : \alpha, \emptyset }
\quad
\inference[(write)]
  {\Gamma \vdash e : \alpha, \sigma & l:\ident{ref}_\rho~\alpha\in \Gamma}
  {\Gamma \vdash l \leftarrow e : \ident{unit}, \sigma \cup \{\ident{write}(\rho)\} }
\end{equation*}
\begin{equation*}
\inference[(fun)]
  {\Gamma, x:\alpha_1 \vdash e : \beta, \sigma }
  {\Gamma \vdash \lambda x.e : \alpha \xrightarrow{\sigma} \beta, \emptyset }
\quad  
\inference[(app)]
  {\Gamma \vdash e_1 : \alpha \xrightarrow{\sigma_1} \beta, \sigma_2 \\
   \Gamma \vdash e_2 : \alpha, \sigma_3 }
  {\Gamma \vdash e_1~e_2 : \beta, \sigma_1 \cup \sigma_2 \cup \sigma_3 }
\end{equation*}

\caption{Simple effect system}
\label{fig:path-eff}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Simple effect system}
The structure of a simple effect system is demonstrated in Figure~\ref{fig:path-eff}. The example
shows typing rules for a simply typed lambda calculus with an additional (effectful) operation
$l \leftarrow e$ that writes the value of $e$ to a mutable location $l$. The type of locations
($\ident{ref}_\rho~\alpha$) is annotated with a \emph{memory region} $\rho$ of the location $l$.
The effects tracked by the type and effect system over-approximate the actual effects and memory
regions provide a convenient way to build such over-approximation. The effects are 
represented as a set of effectful actions that an expression may perform and the effectful action
(\emph{write}) adds a primitive effect $\ident{write}(\rho)$.

The remaining rules are shared by a majority of effect systems. Variable access (\emph{var}) 
has no effects, application (\emph{app}) combines the effects of both expressions, together with 
the latent effects of the function to be applied. Finally, lambda abstraction (\emph{fun}) is a
pure computation that turns the \emph{actual} effects of the body into \emph{latent} effects of 
the created function.

%---------------------------------------------------------------------------------------------------

\paragraph{Simple coeffect system}
When writing the judgements of coeffect systems, we want to emphasize the fact that coeffect 
systems talk about \emph{context} rather than \emph{results}. For this reason, we write the 
judgements in the form $\Gamma @ \sigma \vdash e : \alpha$, associating the additional information
with the context (left-hand side) of the judgement rather than with the result (right-hand side)
as in $\Gamma \vdash e : \alpha, \sigma$. This change alone would not be very interesting -- we 
simply used different syntax to write a predicate with four arguments. As already mentioned, the 
key difference follows from the lambda abstraction rule. 

The language in Figure~\ref{fig:path-coeff} extends simple lambda calculus with resources and
with a construct $\kvd{access}~e$ that obtains the resource specified by the expression $e$.
Most of the typing rules correspond to those of effect systems. Variable access (\emph{var}) 
has no context requirements, application (\emph{app}) combines context requirements of the two
sub-expressions and latent context-requirements of the function. 

The (\emph{fun}) rule is different -- the resources requirements of the body $\sigma_1 \cup \sigma_2$
are split between the \emph{immediate context-requirements} associated with the current context 
$\Gamma @ \sigma_1$ and the \emph{latent context-requirements} of the function.

As demonstrated by examples in the Chapter~\ref{ch:introduction}, this means that the resource
can be captured when a function is declared (e.g.~when it is constructed on the server-side
where database access is available), or when a function is called (e.g.~when a function created
on server-side requires access to current time-zone, it can use the resource available on the
client-side).

%---------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\inference[(var)]
  {x:\alpha \in \Gamma }
  {\Gamma @ \emptyset \vdash x : \alpha }
\quad
\inference[(access)]
  { \Gamma @ \sigma \vdash e : \ident{res}_\rho~\alpha }
  {\Gamma @ \sigma_1 \cup \{\ident{access}(\rho)\} \vdash \kvd{access}~e : \alpha }
\end{equation*}
\begin{equation*}
\inference[(fun)]
  {\Gamma, x:\alpha @ \sigma_1 \cup \sigma_2 \vdash e : \beta }
  {\Gamma @ \sigma_1 \vdash \lambda x.e : \alpha \xrightarrow{\sigma_2} \beta}
\quad  
\inference[(app)]
  {\Gamma \vdash e_1 : \alpha \xrightarrow{\sigma_1} \beta, \sigma_2 \\
   \Gamma \vdash e_2 : \alpha, \sigma_3 }
  {\Gamma \vdash e_1~e_2 : \beta, \sigma_1 \cup \sigma_2 \cup \sigma_3 }
\end{equation*}

\caption{Simple effect system}
\label{fig:path-coeff}
\end{figure}

%===================================================================================================

\section{Through language semantics}
\label{sec:path-sem}

Another pathway to coeffects leads through the semantics of effectful and context-dependent 
computations. In a pioneering work, Moggi \cite{monad-notions} showed that effects (including
partiality, exceptions, non-determinism and I/O) can be modelled uisng the category theoretic
notion of \emph{monad}.

When using monads, we distinguish effect-free values $\alpha$ from programs, or 
computations $\mtyp{}{\alpha}$. The \emph{monad} $\mtyp{}{}$ abstracts the \emph{notion of 
computation} and provides a way of constructing and composing effectful computations:

\begin{definition}
A \emph{monad} over a category $\catc$ is a triple $(M, \ident{unit}, \ident{bind})$ where:
\begin{compactitem}
\item $M$ is a mapping on objects (types) $M : \catc \rightarrow \catc$
\item $\ident{unit}$ is a mapping $\alpha \rightarrow \mtyp{}{\alpha}$ 
\item $\ident{bind}$ is a mapping $(\alpha \rightarrow \mtyp{}{\beta}) 
  \rightarrow (\mtyp{}{\alpha} \rightarrow \mtyp{}{\beta})$
\end{compactitem}
such that, for all $f:\alpha \rightarrow \mtyp{}{\beta}, g:\beta \rightarrow \mtyp{}{\gamma}$:
\begin{align}
\tag{\emph{left identity}}
  \ident{bind}~\ident{unit} &= \idf{}
  \\
\tag{\emph{right identity}}
  \ident{bind}~f \circ \ident{unit} &= f
  \\
\tag{\emph{associativity}}
  \ident{bind}~(\ident{bind}~g \circ f) &= (\ident{bind}~f) \circ (\ident{bind}~g)
\end{align}
\end{definition}

\noindent
Without providing much details, we note that well known examples of monads include the partiality
monad ($\mtyp{}{\alpha} = \alpha + {\bot}$) also corresponding to the \ident{Maybe} type in 
Haskell, list monad ($\mtyp{}{\alpha} = \mu \gamma.1 + (\alpha \times \gamma)$) and other.
In programming language semantics, monads can be used in two distinct ways.

%---------------------------------------------------------------------------------------------------

\subsection{Effectful languages and meta-languages}

Moggi uses monads to define two formal systems. In the first formal system, a monad is used to model 
the \emph{language} itself. This means that the semantics of a language is given in terms of a 
one specific monad and the semantics can be used to reason about programs in that language. To quote 
\emph{``When reasoning about programs one has only one monad, because the programming language is 
fixed, and the main aim is to prove properties of programs''} \cite[p. 5]{monad-notions}.

In the second formal system, monads are added to the programming language as type constructors, 
together with additional constructs corresponding to monadic \ident{bind} and \ident{unit}.
A single program can use multiple monads, but the key benefit is the ability to reason
about multiple languages. To quote \emph{``When reasoning about programming languages one has different 
monads, one for each programming language, and the main aim is to study how they relate to each 
other''} \cite[p. 5]{monad-notions}.

In this thesis, we generally follow the first approach -- this means that we work with an existing
programming language (without needing to add additional constructs corresponding to the primitives
of our semantics). To explain the difference in greater detail, the following two sections show a
minimal example of both formal systems. We follow Moggi and start with language where judgements have
the form $x:\alpha \vdash e : \beta$ with exactly one variable\footnote{This simplifies the examples
as we do not need \emph{strong} monad, but that is an orthogonal issue to the distinction between
language semantics and meta-language.}.

%---------------------------------------------------------------------------------------------------

\paragraph{Language semantics} When using monads to provide semantics of a language, we do not
need to extend the language in any way -- we assume that the language already contains the 
effectful primitives (such as the assignment operator $x \leftarrow e$ or other). A judgement
of the form $x:\alpha \vdash e : \beta$ is interpreted as a morphism $\alpha \rightarrow \mtyp{}{\beta}$,
meaning that any expression is interpreted as an effectful computation. The semantics of variable
access ($x$) and the application of a primitive function $f$ is interpreted as follows:
%
\begin{equation*}
\begin{array}{rcl}
\sem{x:\alpha \vdash x : \alpha} &=& \ident{unit}_\mtyp{}{}\\
\sem{x:\alpha \vdash f~e : \gamma} &=& (\ident{bind}_\mtyp{}{}~f) \circ \sem{e}\\
\end{array}
\end{equation*}
%
Variable access is an effect-free computation, that returns the value of the variable, wrapped
using $\ident{unit}_\mtyp{}{}$. In the second rule, we assume that $e$ is an expression using
the variable $x$ and producing a value of type $\beta$ and that $f$ is a (primitive) function
$\beta \rightarrow \mtyp{}{\gamma}$. The semantics lifts the function $f$ using $\ident{bind}_\mtyp{}{}$
to a function $\mtyp{}{\beta} \rightarrow \mtyp{}{\gamma}$ which is compatible with the 
interpretation of the expression $e$.

%---------------------------------------------------------------------------------------------------

\paragraph{Meta-language interpretation} When designing meta-language based on monads, we need to
extend the lambda calculus with additional type(s) and expressions that correspond to monadic
primitives:
%
\begin{align*}
\alpha, \beta, \gamma &:= \tau \sep \alpha \rightarrow \beta \sep \mtyp{}{\alpha} \\
e &:= x \sep f~e \sep \kvd{return}_\mtyp{}{}~e \sep \kvd{let}_\mtyp{}{}~x \Leftarrow e_1~\kvd{in}~e_2
\end{align*}
%
The types consist of primitive type ($\tau$), function type and a type constructor that 
represents monadic computations. This means that the expressions in the language can create both
effect-free values, such as $\alpha$ and computations $\mtyp{}{\alpha}$. The additional expression
$\kvd{return}_\mtyp{}{}$ is used to create a monadic computation (with no actual effects) from a
value and $\kvd{let}_\mtyp{}{}$ is used to sequence effectful computations. In the semantics, 
monads are not needed to interpret variable access and application, they are only used in the 
semantics of additional (monadic) constructs:
%
\begin{equation*}
\begin{array}{rcl}
\sem{x:\alpha \vdash x : \alpha} &=& \idf{}\\
\sem{x:\alpha \vdash f~e : \beta} &=& f \circ \sem{e}\\
\sem{x:\alpha \vdash \kvd{return}_\mtyp{}{}~e : \mtyp{}{\beta}} &=& \ident{unit}_\mtyp{}{} \circ \sem{e}\\
\sem{x:\alpha \vdash \kvd{let}_\mtyp{}{}~y \Leftarrow e_1~\kvd{in}~e_2 : \mtyp{}{\beta}} &=& 
  \ident{bind}_\mtyp{}{}~\sem{e_2} \circ \sem{e_1}
\end{array}
\end{equation*}

\noindent
In this system, the interpretation of variable access becomes a simple identity function and
application is just composition. Monadic computations are constructed explicitly using 
$\kvd{return}_\mtyp{}{}$ (interpreted as $\ident{unit}_\mtyp{}{}$) and they are also sequenced
explicitly using the $\kvd{let}_\mtyp{}{}$ construct. As noted by Moggi, the first formal system
can be easily translated to the latter by inserting appropriate monadic constructs.

Moggi regards the meta-language system as more fundamental, because \emph{``its models are more 
general''}. Indeed, this is a valid and reasonable perspective. Yet, we follow the first style,
precisely because it is \emph{less general} -- our aim is to develop concrete context-aware 
programming languages (together with their type theory and semantics) rather than to build a 
general framework for reasoning about languages with context-dependent properties.

%---------------------------------------------------------------------------------------------------

\subsection{Marriage of effects and monads}
\label{sec:path-sem-effects}

The work on effect systems and monads both tackle the same problem -- representing and tracking of 
computational effects. The two lines of research have been joined by Wadler and Thiemann
\cite{monads-effects-marriage}. This requires extending the categorical structure. A monadic
computation $\alpha \rightarrow \mtyp{}{\beta}$ means that the computation has \emph{some} 
effects while the judgement $\Gamma \vdash e : \alpha, \sigma$ specifies \emph{what} effects
the computation has.

To solve this mismatch, Wadler and Thiemann use a \emph{family} of monads $\mtyp{\sigma}{\alpha}$
with an annotation that specifies the effects that may be performed by the computation. In their
system, an effectful function $\alpha \xrightarrow{\sigma} \beta$ is modelled as a pure 
function returning monadic computation $\alpha \rightarrow \mtyp{\sigma}{\beta}$. Similarly, the
semantics of a judgement $x:\alpha \vdash e : \beta, \sigma$ can be given as a function 
$\alpha \rightarrow \mtyp{\sigma}{\beta}$. 
The precise nature of the family of monads has been later called \emph{indexed monads} (e.g.~by Tate
\cite{effects-producer-semantics}) and further developed by Atkey \cite{monads-parameterised-notions} 
in his work on \emph{parameterized monads}.

\paragraph{Thesis perspective}
The key takeaway for this thesis from the outlined line of research is that, if we want to develop a 
language with type system that captures context-dependent properties of programs more precisely,
the semantics of the language also needs to be a more fine-grained structure (akin to indexed 
monads). While monads have been used to model effects, an existing research links context-dependence
with \emph{comonads} -- the categorical dual of monads.

%---------------------------------------------------------------------------------------------------
 
\subsection{Context-dependent languages and meta-languages}
\label{sec:path-sem-contextdep}

The theoretical parts of this thesis extend the work of Uustalu and Vene who use comonads
to give the semantics of data-flow computations \cite{comonads-dataflow} and more generally, 
notions of \emph{context-dependent computations} \cite{comonads-notions}. The computations discussed 
in the latter work include streams, arrays and containers -- this is a more diverse set of examples, 
but they all mostly represent forms of collections. Ahman et al. \cite{comonads-containers} discuss
the relation between comonads and \emph{containers} in more details.

The utility of comonads has been explored by a number of authors before. Brookes and Geva
\cite{comonads-computational} use \emph{computational} comonads for intensional semantics\footnote{The
structure of computational comonad has been also used by the author of this thesis to abstract
evaluation order of monadic computations \cite{comonads-malias}.}. In functional programming,
Kieburtz \cite{comonads-and-codata} proposed to use comonads for stream programming, but also 
handling of I/O and interoperability.

Biermann and de Paiva used comonads to model the necessity modality $\square$ in intuitionistic
modal S4 \cite{logic-intuitionistic-modal}, linking programming languages derived from modal
logics to comonads. One such language has been reconstructed by Pfenning and Davies
\cite{logic-modal-reconstruction}. Nanevski et al. extend this work to Contextual Modal Type 
Theory (CMTT) \cite{logic-cmtt}, which again shows the importance of comonads for 
\emph{context-dependent} computations.

While Uustalu and Vene use comonads to define the \emph{language semantics} (the first style
of Moggi), Nanevski, Pfenning and Davies use comonads as part of meta-language, in the form 
of $\square$ modality, to reason about context-dependent computations (the second style of 
Moggi). Before looking at the details, we use the following definition of comonad:

\begin{definition}
A \emph{comonad} over a category $\catc$ is a triple $(C, \ident{counit}, \ident{cobind})$ where:
\begin{compactitem}
\item $C$ is a mapping on objects (types) $C : \catc \rightarrow \catc$
\item $\ident{counit}$ is a mapping $\ctyp{}{\alpha} \rightarrow \alpha$ 
\item $\ident{cobind}$ is a mapping $(\ctyp{}{\alpha} \rightarrow \beta) 
  \rightarrow (\ctyp{}{\alpha} \rightarrow \ctyp{}{\beta})$
\end{compactitem}
such that, for all $f:\alpha \rightarrow \mtyp{}{\beta}, g:\beta \rightarrow \mtyp{}{\gamma}$:
\begin{align}
\tag{\emph{left identity}}
  \ident{cobind}~\ident{counit} &= \idf{}
  \\
\tag{\emph{right identity}}
  \ident{counit} \circ \ident{cobind}~f &= f
  \\
\tag{\emph{associativity}}
  \ident{cobind}~(\ident{cobind}~g \circ f) &= (\ident{cobind}~f) \circ (\ident{cobind}~g)
\end{align}
\end{definition}

\noindent
The definition is similar to monad with ``reversed arrows''. Intuitively, the $\ident{counit}$ 
operation extracts a value $\alpha$ from a value that carries additional context $\ctyp{}{\alpha}$.
The $\ident{cobind}$ operation turns a context-dependent function 
$\ctyp{}{\alpha} \rightarrow \beta$ into a function that takes a value with context, applies
the context-dependent function to value(s) in the context and then propagates the context. The 
next section makes this intuitive definition more concrete. More detailed discussion about
comonads can be found in Orchard's PhD thesis \cite{comonads-dom-thesis}.

%---------------------------------------------------------------------------------------------------

\paragraph{Language semantics}
To demonstrate the approach of Uustalu and Vene, we consider the non-empty list comonad
$\ctyp{}{\alpha} = \mu \gamma.\alpha + (\alpha \times \gamma)$. A value of the type is either
the last element $\alpha$ or an element followed by another non-empty list $\alpha \times \gamma$.
Note that the list must be non-empty -- otherwise \ident{counit} would not be a complete 
function (it would be undefined on empty list). In the following, we write $(l_1, \ldots, l_n)$
for a list of $n$ elements:
%
\begin{equation*}
\begin{array}{rcl}
\ident{counit}~(l_1, \ldots, l_n) &=& l_1\\
\ident{cobind}~f~(l_1, \ldots, l_n) &=& (f (l_1, \ldots, l_n), f (l_2, \ldots, l_n), \ldots, f (l_n))
\end{array}
\end{equation*}
%
The \ident{counit} operation returns the current (first) element of the (non-empty) list.
The \ident{cobind} operation creates a new list by applying the context-dependent function $f$
to the entire list, to the suffix of the list, to the suffix of the suffix and so on.

In causal data-flow, we can interpret the list as a list consisting of past values, with the 
current value in the head. Then, the $\ident{cobind}$ operation calculates the current value
of the output based on the current and all past values of the input; the second element is
calculated based on all past values and the last element is calculated based just on the initial
input $(l_n)$. In addition to the operations of comonad, the model also uses some operations that
are specific to causal data-flow:
%
\begin{equation*}
\begin{array}{rcl}
\ident{prev}~(l_1, \ldots, l_n) &=& (l_2, \ldots, l_n)\\
\end{array}
\end{equation*}
%
The operation drops the first element from the list. In the data-flow interpretation, this means
that it returns the previous state of a value. 

Now, consider a simple data-flow language with single-variable contexts, variables, 
primitive built-in functions and a construct $\kvd{prev}~e$ that returns the previous
value of the computation $e$. We omit the typing rules, but they are simple -- assuming $e$ 
has a type $\alpha$, the expression $\kvd{prev}~e$ has also type $\alpha$. The fact that
the language models data-flow and values are lists (of past values) is a matter of semantics,
which is defined as follows:
%
\begin{equation*}
\begin{array}{rcl}
\sem{x:\alpha \vdash x : \alpha} &=& \ident{counit}_\ctyp{}{}\\
\sem{x:\alpha \vdash f~e : \gamma} &=& f \circ (\ident{cobind}_\ctyp{}{} ~\sem{e})\\
\sem{x:\alpha \vdash \kvd{prev}~e : \gamma} &=& \ident{prev} \circ (\ident{cobind}_\ctyp{}{} ~\sem{e})\\
\end{array}
\end{equation*}
%
The semantics follows that of effectful computations using monads. A variable access is interpreted
using $\ident{counit}_\ctyp{}{}$ (obtain the value and ignore additional available context); composition
uses $\ident{cobind}_\ctyp{}{}$ to propagate the context to the function $f$ and $\kvd{prev}$
is interpreted using the primitive $\ident{prev}$ (which takes a list and returns a list).

For example, the judgement $x:\alpha \vdash \kvd{prev}~(\kvd{prev}~x) : \alpha$ represents an 
expression that expects context with variable $x$ and returns a stream of values before the 
previous one. The semantics of the term expresses this behaviour: 
$(\ident{prev} \circ \ident{prev} \circ (\ident{cobind}_\ctyp{}{}~\ident{counit}_\ctyp{}{}))$.
Note that the first operation is simply an identity function thanks to the comonad laws discussed 
earlier.

In the outline presented here, we ignored lambda abstraction. Similarly to monadic semantics,
where lambda abstraction requires \emph{strong} monad, the comonadic semantics also requires
additional structure called \emph{symmetric (semi)monoidal} comonads. This structure is 
responsible for the splitting of context-requirements in lambda abstraction. We return to this
topic when discussing flat coeffect system later in the thesis.

%---------------------------------------------------------------------------------------------------

\begin{figure}
\begin{equation*}
\inference[(eval)]
  {\Gamma \vdash e : \ctyp{\emptyset}{\alpha}}
  {\Gamma \vdash !e : \alpha}
\quad
\inference[(letbox)]
  {\Gamma \vdash e_1 : \ctyp{\Phi, \Psi}{\alpha} & \Gamma, x : \ctyp{\Phi}{\alpha} \vdash e_2 : \beta }
  {\Gamma \vdash \kvd{let~box}~x=e_1~\kvd{in}~e_2 : \ctyp{\Psi}{\beta}}
\end{equation*}

\caption{Typing for a comonadic language with contextual staged computations}
\label{fig:modal-meta}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Meta-language interpretation} To briefly demonstrate the approach that employs comonads
as part of a meta-language, we look at an example inspired by the work of Pfenning, Davies and 
Nanevski et al. We do not attempt to provide precise overview of their work. The main purpose 
of our discussion is to provide a different intuition behind comonads, and to give an example
of a language that includes comonad as a type constructor, together with language primitives
corresponding to comonadic operations\footnote{In fact, Pfenning and Davies \cite{logic-modal-reconstruction,logic-cmtt}
never mention comonads explicitly. This is done in later work by Gabbay et al. \cite{logic-cmtt-semantics}, 
but the connection between the language and comonads is not as direct as in case of monadic or
comonadic semantics covered in the last few pages.}. 

In languages inspired by modal logics, types can have the form $\square \alpha$. In the work of
Pfenning and Davies, this means a term that is provable with no assumptions. In distributed 
programming language ML5, Murphy et al. \cite{app-distributed-ml5,logic-distributed-calculus} use the 
$\square \alpha$ type to mean \emph{mobile code}, that is code that can be evaluated at any node of a 
distributed system (the evaluation corresponds to the axiom $\square \alpha \rightarrow \alpha$). 
Finally, Davies and Pfenning \cite{logic-modal-staged} consider staged computations and interpret 
$\square \alpha$ as a type of (unevaluated) expressions of type $\alpha$.

In Contextual Modal Type Theory, the modality $\square$ is further annotated. To keep the syntax
consistent with earlier examples, we use $\ctyp{\Psi}{\alpha}$ for a type $\square \alpha$ with an
annotation $\Psi$. The type is a comonadic counterpart to the \emph{indexed monads} used by Wadler
and Thiemann when linking monads and effect systems and, indeed, it gives rise to a language that
tracks context-dependence of computations in a type system.

In staged computation, the type $\ctyp{\Psi}{\alpha}$ represents an expression 
that requires the context $\Psi$ (i.e.~the expression is an open term that requires variables $\Psi$).
The Figure~\ref{fig:modal-meta} shows two typing rules for such language. The rules directly
correspond to the two operations of a comonad and can be interpreted as follows:

\begin{itemize}
\item (\emph{eval}) corresponds to $\ident{counit} : \ctyp{\emptyset}{\alpha} \rightarrow \alpha$. It means
  that we can evaluate a closed (unevaluated) term and obtain a value. Note that the rule requires
  a specific context annotation. It is not possible to evaluate an open term.

\item (\emph{letbox}) corresponds to $\ident{cobind} : (\ctyp{\Psi}{\alpha} \rightarrow \beta) 
  \rightarrow \ctyp{\Psi, \Phi}{\alpha} \rightarrow \ctyp{\Phi}{\beta}$. It means that given
  a term which requires variable context $\Psi, \Phi$ (expression $e_1$) and a function that turns 
  a term needing $\Psi$ into an evaluated value (expression $e_2$), we can construct a term 
  that requires just $\Phi$.
\end{itemize}

\noindent
The fact that the (\emph{eval}) rule requires a specific context is an interesting relaxation
from ordinary comonads where \ident{counit} needs to be defined for all values. Here, the indexed
\ident{counit} operation needs to be defined only on values annotated with $\emptyset$.

The annotated \ident{cobind} operation that corresponds to (\emph{letbox}) is in details 
introduced in Chapter~X. An interesting aspect is that it propagates the context-requirements
``backwards''. The input expression (second parameter) requires a combination of contexts that
are required by the two components -- those required by the input of the function (first
argument) and those required by the resulting expression (result). This is another key aspect
that distinguishes coeffects from effect systems.
  
\paragraph{Thesis perspective}
As mentioned earlier, we are interested in designing context-dependent languages and so we
use comonads as \emph{language semantics}. Uustalu and Vene present a semantics of 
context-dependent computations in terms of comonads. We provide the rest of the story known 
from the marriage of monads and effects. We develop coeffect calculus with a type system that 
tracks the context requirements more precisely (by annotating the types) and we add indexing 
to comonads and link the two by giving a formal semantics. 

The \emph{meta-language} approach of Pfenning, Davies and Nanevski et al. is closely related to
our work. Most importantly, Contextual Modal Type Theory (CMTT) uses indexed $\square$ modality
which seems to correspond to indexed comonads (in a similar way in which effect systems 
correspond to indexed monads). The relation between CMTT and comonads has been suggested by
Gabbay et al. \cite{logic-cmtt-semantics}, but the meta-language employed by CMTT does not 
directly correspond to comonadic operations. For example, our \ident{let box} typing rule from
Figure~\ref{fig:modal-meta} is not a primitive of CMTT and would correspond to 
$\ident{box}(\Psi, \ident{letbox}(e_1, x, e_2))$. Nevertheless, the indexing in CMTT provides a useful
hint for adding indexing to the work of Uustalu and Vene.

%===================================================================================================

\section{Through sub-structural and bunched logics}
\label{sec:path-logic}

In the coeffect system for tracking resource usage outlined earlier, we associated additional
contextual information (set of available resources) with the variable context of the typing 
judgement: $\Gamma @ \sigma \vdash e : \alpha$. In other words, our work focuses on ``what is
happening on the left hand side of $\vdash$''.

In the case of resources, the additional information about the context are simply added to the
variable context (as a products), but we will later look at contextual properties that affect 
how variables are represented. More importantly, \emph{structural coeffects} link additional
information to individual variables in the context, rather than the context as a whole.

In this section, we look at type systems that reconsider $\Gamma$ in a number of ways. 
First of all, sub-structural type systems \cite{substruct-attpl-intro} restrict the use of variables
in the language. Most famously linear type systems introduced by Wadler \cite{substruct-linear-change} 
can guarantee that variable is used exactly once. This has interesting implications for memory
management and I/O. 

In bunched typing developed by O'Hearn \cite{substruct-bunched}, the variable context is a tree 
formed by multiple different constructors (e.g.~one that allows sharing and one that does not). 
Most importantly, bunched typing has contributed to the development of separation logic
\cite{substruct-separation-logic} (starting a fruitful line of research in software verification), 
but it is also interesting on its own. 

%---------------------------------------------------------------------------------------------------

\paragraph{Sub-structural type systems}

Traditionally, $\Gamma$ is viewed as a set of assumptions and typing rules admit (or explicitly
include) three operations that manipulate the variable contexts which are shown in 
Figure~\ref{fig:substructural-rules}. The (\emph{exchange}) rule allows us to reorder variables
(which is implicit, when assumptions are treated as set); (\emph{weakening}) makes it possible
to discard an assumption -- this has the implication that a variable may be declared but never
used. Finally, (\emph{contraction}) makes it possible to use a single variable multiple times
(by joining multiple variables into a single one using substitution).

\begin{figure}
\begin{equation*}
\inference[(exchange)]
  {\Gamma, x:\alpha, y:\beta \vdash e : \gamma}
  {\Gamma, y:\beta, x:\alpha \vdash e : \gamma}
\quad
\inference[(weakening)]
  {\Gamma, \Delta \vdash e : \gamma}
  {\Gamma, x:\alpha, \Delta \vdash e : \gamma}
\end{equation*}
\begin{equation*}
\inference[(contraction)]
  {\Gamma, x:\alpha, y:\alpha, \Delta \vdash e : \gamma}
  {\Gamma, x:\alpha, \Delta \vdash \subst{e}{y}{x} : \gamma}
\end{equation*}

\caption{Exchange, weakening and contraction typing rules}
\label{fig:substructural-rules}
\end{figure}

In sub-structural type systems, the assumptions are typically treated as a list. As a result,
they have to be manipulated explicitly. Different systems allow different subset of the rules.
For example, \emph{affine} systems allows exchange and weakening, leading to a system where 
variable may be used at most once; in \emph{linear} systems, only exchange is permitted and so 
every variable has to be used exactly once.

When tracking context-dependent properties associated with individual variables, we need to 
be more explicit in how variables are used. Sub-structural type systems provide a way to do this.
Even when we allow all three operations, we can track which variables are used and how
(and use that to track additional contextual information about variables). 

%---------------------------------------------------------------------------------------------------

\paragraph{Bunched type systems}
Bunched typing makes one more refinement to how $\Gamma$ is treated. Rather than having a list
of assumptions, the context becomes a tree that contains variable typings (or special identity
values) in the leaves and has multiple different types of nodes. The context can be defined,
for example, as follows:
%
\begin{equation*}
\Gamma, \Delta, \Sigma := x:\alpha \sep I \sep \Gamma, \Gamma \sep 1 \sep \Gamma; \Gamma
\end{equation*}
%
The values $I$ and $1$ represent two kinds of ``empty'' contexts. More interestingly, non-empty
variable contexts may be constructed using two distinct constructors -- $\Gamma, \Gamma$ and 
$\Gamma; \Gamma$ -- that have different properties. In particular, weakening and contraction is
only allowed for the $;$ constructor, while exchange is allowed for both.  

The structural rules for bunched typing are shown in Figure~\ref{fig:substructural-bunched}.
The syntax $\Gamma(\Delta)$ is used to mean an assumption tree that contains $\Delta$ as a 
sub-tree and so, for example, (\emph{exchange1}) can switch the order of contexts anywhere in the
tree. The remaining rules are similar to the rules of linear logic.

One important note about bunched typing is that it requires a different interpretation. The omission
of weakening and contraction in linear logic means that variable can be used exactly once. 
In bunched typing, variables may still be duplicated, but only using the ``;'' separator.
The type system can be interpreted as specifying whether a variable may be shared between the 
body of a function and the context where a function is declared. The system introduces two 
distinct function types $\alpha \rightarrow \beta$ and $\alpha~ \textendash\!\!\!\ast \beta$
(corresponding to ``;'' and ``,'' respectively). The key property is that only the first kind
of functions can share variables with the context where a function is declared, while the second
restricts such sharing. We do not attempt to give a detailed description here as it is not 
immediately to coeffects -- for more information, refer to O'Hearn's introduction 
\cite{substruct-bunched}.

\begin{figure}
\begin{equation*}
\inference[(exchange1)]
  {\Gamma(\Delta, \Sigma) \vdash e : \alpha}
  {\Gamma(\Sigma, \Delta) \vdash e : \alpha}
\quad
\inference[(weakening)]
  {\Gamma(\Delta) \vdash e : \alpha}
  {\Gamma(\Delta; \Sigma) \vdash e : \alpha}
\end{equation*}
\begin{equation*}
\inference[(exchange2)]
  {\Gamma(\Delta; \Sigma) \vdash e : \alpha}
  {\Gamma(\Sigma; \Delta) \vdash e : \alpha}
\quad
\inference[(contraction)]
  {\Gamma(\Delta; \Sigma) \vdash e : \alpha}
  {\Gamma(\Delta) \vdash \subst{e}{\Sigma}{\Delta} : \alpha}
\end{equation*}
\caption{Exchange, weakening and contraction rules for bunched typing}
\label{fig:substructural-bunched}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Thesis perspective}

Our work can be viewed as annotating bunches. Such annotations then specify additional information
about the context -- or, more specifically, about the sub-tree of the context. Although this is not
the exact definition used in Chapter~X, we could define contexts as follows:
%
\begin{equation*}
\Gamma, \Delta, \Sigma := x:\alpha \sep 1 \sep \Gamma, \Gamma \sep \Gamma @ \sigma
\end{equation*}
%
Now we can not only annotate an entire context with some information (as in the simple coeffect
system for tracking resources that used judgements of a form $\Gamma @ \sigma \vdash e : \alpha$).
We can also annotate individual components. For example, a context containing variables $x,y,z$
where only $x$ is used could be written as $(x:\alpha \,@\, \ident{used}), ((y:\alpha, z:\alpha) 
\,@\, \ident{unused})$.

For the purpose of this introduction, we ignore important aspects such as how are nested annotations
interpreted. The main goal is to show that coeffects can be easily viewed as an extension to the 
work on bunched logic. Aside from this principal connection, \emph{structural coeffects} also 
use some of the proof techniques from the work on bunched logics, because they also use tree-like
structure of variable contexts.

%===================================================================================================

\section{Summary}
Oops!

% \section{Missing}
% ~
% 
% indexed/layered/etc. monads, productors or whatever