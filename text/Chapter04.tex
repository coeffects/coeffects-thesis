%\begin{flushright}{\slshape    
%Even the most puritanical rationalist will be forced to stop arguing and \\
%use propaganda [...] because the psychological conditions have disappeared \\
%that allowed effective argument and therefore influence over the others.} \\ \medskip
%--- Paul Feyerabend, \emph{Against Method} \cite{philosophy-feyerabend}
%\end{flushright}
%\vspace{2em}

% ==================================================================================================

\chapter{Flat coeffect calculus} 
\label{ch:flat} 

Successful programming language abstractions need to generalize a wide range of recurring
problems while capturing the key commonalities. These two aims are typically in opposition -- 
more general abstractions are less powerful, while less general abstractions cannot be
used as often.

In the previous chapter, we outlined a number of systems that capture how computations
access the environment in which they are executed. We identified two kinds of systems --
\emph{flat} capturing whole-context properties and \emph{structural} capturing per-variable
properties. As we show in Chapter~\ref{ch:unified}, the systems can be unified using a single 
abstraction. This is useful when implementing and composing the systems, but such abstraction 
is  \emph{less powerful} -- \ie~its generality hides useful properties that we can see 
when we consider the systems separately. For this reason, this and the next chapter discusses 
\emph{flat} and \emph{structural} systems separately.

% ==================================================================================================

\section{Introduction}
\label{sec:flat-intro}

In the previous chapter, we looked at three important examples of systems that track whole-context 
properties. The type systems for whole-context liveness (Section~\ref{sec:applications-flat-live}) 
and whole-context data-flow (Section~\ref{sec:applications-flat-dataflow}) have a very similar 
structure -- their lambda abstraction duplicates the requirements and their application arises
from the combination of \emph{sequential} and \emph{point-wise} composition.

The system for tracking of implicit parameters (Section~\ref{sec:applications-flat-impl}), and
similar systems for rebindable resources, differ in two ways. In lambda abstraction, they split
the context requirements between the declaration-site and the call-site and they use only a single
operator on the indices, typically $\cup$.

%---------------------------------------------------------------------------------------------------

\subsection{Contributions}

All of the examples are practically useful and important and so we want to be able to capture all
of them. Despite the differences, the systems can fit the same framework. The contributions of this
chapter are as follows:

\begin{itemize}
\item We present a \emph{flat coeffect calculus} with a type system that is parameterized by a 
  \emph{flat coeffect algebra} and can be instantiated to obtain all of the three examples
  discussed (Section~\ref{sec:flat-calculus}).
  
\item We give the equational theory of the calculus and discuss type-preservation for call-by-name
  and call-by-value reduction (Section~\ref{sec:flat-syntax}). We also extend the calculus
  with pairs and recursion (Section~\ref{sec:flat-exts}).
  
\item We present the semantics of the calculus in terms of \emph{indexed comonads}, which is a
  generalization of comonads, a category-theoretical dual of monads (Section~\ref{sec:flat-semantics}).
  The semantics provides deeper insight into how (and why) the calculus works.

\item We develop an alternative presentation of the system in terms of a simple structure 
  (semi-lattice) and use it to develop a type inference algorithm for flat coeffect calculus.
\end{itemize}

%---------------------------------------------------------------------------------------------------

\subsection{Related work}

The development in this chapter can be seen as a counterpart to the well-known development of 
\emph{effect systems} \cite{effects-gifford} and the use of \emph{monads} \cite{monad-notions}
in programming languages. The syntax and type system of the flat coeffect calculus follows 
similar style as effect systems \cite{effects-polymorphic,effects-talpin-et-al}, but differs
in the structure, as explained in the previous chapter, most importantly in lambda abstraction.

Wadler and Thiemann famously show a correspondence between effect systems to monads 
\cite{monads-effects-marriage}, relating effectful functions $\tau_1 \xrightarrow{\sigma} \tau_2$ 
to monadic computations $M^\sigma \tau_1 \rightarrow \tau_2$. In this chapter, we show a similar
correspondence between \emph{coeffect systems} and \emph{comonads}. However, due to the asymmetry 
of $\lambda$-calculus, this is not a simple mechanical dualization.

The main purpose of the comonadic semantics presented in this chapter is to provide a semantic
motivation for the flat coeffect calculus. The semantics is inspired by the work of Uustalu and
Vene \cite{comonads-notions} who present the semantics of contextual computations (mainly for
data-flow) in terms of comonadic functions $C \tau_1 \rightarrow \tau_2$. Our \emph{indexed 
comonads} annotate the structure with information about the required context, \ie~$C^\sigma \tau_1 \rightarrow \tau_2$.
This is similar to the recent work on \emph{parameterized monads} by Katsumata \cite{monads-parametric}.

% ==================================================================================================

\section{Flat coeffect calculus}
\label{sec:flat-calculus}

The flat coeffect calculus is defined in terms of \emph{flat coeffect algebra}, which defines
the structure of context annotations, such as $\cclrd{r}, \cclrd{s}, \cclrd{t}$. These can be
sets of implicit parameters, integers or other values. The expressions of the calculus are those
of the $\lambda$-calculus with \emph{let} binding; assuming $T$ ranges over base types, the 
types of the calculus are defined as follows:
%
\begin{equation*}
\begin{array}{rcl}
e &::=& x \sep \lambda x.e \sep e_1~e_2 \sep \kvd{let}~x = e_1~\kvd{in}~e_2\\
\tau &::=& T \sep \tau_1 \xrightarrow{\cclrd{r}} \tau_2
\end{array}
\end{equation*}
%
We discuss pairs and recursion in Section~\ref{sec:flat-exts}. The type $\tau_1 \xrightarrow{\cclrd{r}} \tau_2$
represents a function from $\tau_1$ to $\tau_2$ that requires additional context $\cclrd{r}$.
It can be viewed as a pure function that takes $\tau_1$ \emph{with} or \emph{wrapped in} a 
context $r$. 

In the categorical semantics, the function $\tau_1 \xrightarrow{\cclrd{r}} \tau_2$ is modelled
by a morphism $C^{\cclrd{r}} \tau_1 \rightarrow \tau_2$. However, the object $C^{\cclrd{r}}$
does not exist as a syntactical value. This is because we use comonads to define the 
\emph{semantics} rather than \emph{embedding} them into the language as in the meta-language
approaches (the distinction between the two approaches has been discussed in detail in 
Section~\ref{sec:path-sem-langs}). The annotations $\cclrd{r}$ are formed by an algebraic
structure discussed next.

%---------------------------------------------------------------------------------------------------

\subsection{Reconciling lambda abstraction}
\label{sec:flat-calculus-lambda}

Recall the lambda abstraction rules for the implicit parameters system (annotating the context
with sets of required parameters) and the data-flow system (annotating the context with the
number of past required values):
%
\begin{equation*}
\tyrule{abs-imp}
  {\coctx{\Gamma, x:\tau_1}{\aclrd{r} \cup \aclrd{s}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{s}} \tau_2 }
\;
\tyrule{abs-df}
  {\coctx{\Gamma, x:\tau_1}{\aclrd{n}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{n}} \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{n}} \tau_2 }
\end{equation*}

~

In order to capture both systems using a single calculus, we need a way of unifying the two
systems. For the data-flow system, this can be achieved by over-approximating the number of 
required past elements:
%
\begin{equation*}
\tyrule{abs-min}
  {\coctx{\Gamma, x:\tau_1}{\textnormal{min}(\aclrd{n}, \aclrd{m})} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{n}} \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{m}} \tau_2 }
\end{equation*}
%
The rule (\emph{abs-df}) is admissible in a system that includes the (\emph{abs-min}) rule. 
If we include sub-typing rule (on annotations of functions) and sub-coeffecting rule (on 
annotations of contexts), then the reverse is also true -- because 
$\textit{min}(\aclrd{n}, \aclrd{m}) \leq \aclrd{m}$ and $\textit{min}(\aclrd{n}, \aclrd{m}) \leq \aclrd{n}$.

%---------------------------------------------------------------------------------------------------

\subsection{Flat coeffect algebra}
To make the flat coeffect system general enough, the algebra consists of three operations.
Two of them, $\cseq$ and $\cpar$, represent the \emph{sequential} and \emph{point-wise} composition, 
respectively and the third one, $\czip$ represents context \emph{merging}. The term merging should be 
understood semantically -- the operation models what happens when the semantics of lambda abstraction 
combines context available at the declaration-site and the call-site.

In addition to the three operations, we also require two special values used to annotate
variable access and constant access and a relation that defines the ordering.

\begin{definition}
A \emph{\cclrd{flat coeffect algebra}} $(\C, \cseq, \cpar, \czip, \cunit, \czero, \cleq)$ is a set 
$\C$ together with elements $\cunit, \czero \in \C$, relation $\cleq$ and binary operations 
$\cseq, \cpar, \czip$ such that $(\C, \cseq, \cunit)$ and $(\C, \cpar, \czero)$ are monoids,
$(\C, \cleq)$ is a pre-order and $(\C, \czip)$ is a band (idempotent semigroup). That is, 
for all $r,s,t\in \C$:
%
\begin{equation*}
\begin{array}{ccr}
r \;\cseq\; (s \;\cseq\; t) = (r \;\cseq\; s) \;\cseq\; t  &
\cunit \;\cseq\; r = r = r \;\cseq\; \cunit &
\textnormal{(monoid)}   
\\
r \;\cpar\; (s \;\cpar\; t) = (r \;\cpar\; s) \;\cpar\; t &
\czero \;\cpar\; r = r = r \;\cpar\; \czero &
\textnormal{(monoid)}   
\\
r \;\czip\; (s \;\czip\; t) = (r \;\czip\; s) \;\czip\; t &
r\; \czip\; r = r &
\textnormal{(band)}   
\\
\textnormal{if}~~r\; \cleq\; s ~~\textnormal{and}~~s\; \cleq\; t~~\textnormal{then}~~r\; \cleq\; t&
t\; \cleq\; t &
\textnormal{(pre-order)}   
\end{array}
\end{equation*}
%
In addition, the following distributivity axioms hold:
\begin{align*}
\quad (\cclrd{r}\, \cpar\, \cclrd{s}) \;\cseq\; \cclrd{t} & = (\cclrd{r} \,\cseq\, \cclrd{t}) \;\cpar\; (\cclrd{s}\, \cseq\, \cclrd{t}) \\
\quad \cclrd{t} \;\cseq\; (\cclrd{r}\, \cpar\, \cclrd{s}) & = (\cclrd{t} \,\cseq\, \cclrd{r}) \;\cpar\; (\cclrd{t}\, \cseq\, \cclrd{s})
\end{align*}
\end{definition}

\noindent
In two of the three systems, some of the operators of the flat coeffect algebra coincide,
but the data-flow system requires all three. Similarly, the two special elements also 
coincide in some, but not all systems. The required laws are motivated by the aim to capture
common properties of the three examples, without unnecessarily restricting the system:

\begin{itemize}
\item The monoid $(\C, \cseq, \cunit)$ represents \emph{sequential} composition of (semantic)
functions. The laws of a monoid are required in order to form a category structure in the 
categorical model (Section~\ref{sec:flat-semantics}).

\item The monoid $(\C, \cpar, \czero)$ represents \emph{point-wise} composition, \ie~the case when the
same context is passed to multiple (independent) computations. The monoid laws guarantee 
that usual syntactic transformations on tuples and the unit value (Section~\ref{sec:flat-exts})
preserve the coeffect. 

\item For the $\czip$ operation, we require associativity and idempotence. The idempotence
requirement makes it possible to duplicate the coeffects and place the same requirement on both
call-site and declaration-site, \ie~it makes the (\emph{abs-df}) rule admissible. In some cases, 
the operator forms a monoid with the unit being the greatest element of the set. This alternative is 
discussed when we consider recursion (Section~\ref{sec:flat-exts}).
\end{itemize}

It is worth noting that the operators $\cpar$ and $\czip$ are dual in some of the systems. For 
example, in data-flow computations, they are \emph{max} and \emph{min} respectively. However, this
duality does not hold for implicit parameters. Using the syntactic reading, they represent 
\emph{merging} and \emph{splitting} of context requirements -- in the (\emph{abs}) rule, 
$\czip$ appears in the assumption and the combined context requirements of the body are split 
between two positions in the conclusions; in the (\emph{app}) rule, $\cpar$ appears in the 
conclusion and combines two context requirements from the assumptions.

\paragraph{Ordering.}

The flat coeffect algebra requires a pre-order relation $\cleq$, which is used to define 
sub-coeffecting rule of the type system. When the monoid $(\C, \cpar, \czero)$ is idempotent
and commutative monoid (semi-lattice), the $\cleq$ relation can be defined in terms of $\cpar$ as:
%
\begin{equation*}
r \;\cleq\; s \;\Longleftrightarrow\; r \;\cpar\; s \;=\; s
\end{equation*}
%
This definition is consistent with all three examples that motivate flat coeffect calculus, but
it cannot be used with the structural coeffects (where it fails for the bounded reuse 
calculus) and so we choose not to use it.

Furthermore, the $\cunit$ coeffect is often the top (greatest) or the bottom (smallest) 
element of the semi-lattice, but not in general. When this is the case, we are able
to prove certain properties of the calculus (Section~\ref{sec:syntax}).

%---------------------------------------------------------------------------------------------------

\subsection{Understanding flat coeffects}

Before looking at the type system in Figure~\ref{fig:flat-types}, let us clarify how the rules
should be understood. The coeffect calculus provides both analysis of context dependence (type 
system) and semantics for context (how it is propagated). These two aspects provide different
ways of reading the judgements $\coctx{\Gamma}{\cclrd{r}} \vdash e : \tau$ and the typing rules
used to define it.

\begin{itemize}
\item \textbf{Analysis of context dependence.}
Syntactically, coeffect annotations $\cclrd{r}$ model \emph{context requirements}. This means
we can over-approximate them and require more than is actually needed at runtime. 

Syntactically, the typing rules should be read top-down. In (\emph{app}), the context requirements 
of multiple assumptions are \emph{merged}; in (\emph{abs}), they are split between the declaration-site
and the call-site.

\item \textbf{Semantics of context passing.}
Semantically, coeffect annotations $\cclrd{r}$ mo\-del \emph{contextual capabilities}. This means
that we can throw away capabilities, if a sub-expression requires fewer than we 
currently have.

Semantically, the typing rules should be read bottom-up. In application, the capabilities 
provided to the term $e_1~e_2$ are \emph{split} between the two sub-expressions; in abstraction,
the capabilities provided by the call-site and declaration-site are \emph{merged} and passed
to the body.
\end{itemize}

The reason for this asymmetry follows from the fact that the context appears in a \emph{negative
position} in the semantic model (Section~\ref{sec:flat-semantics}). It means that we need to be
careful about using the words \emph{split} and \emph{merge}, because they can be read as meaning
opposite things. To disambiguate, we always use the term \emph{context requirements} when using
the syntactic view and \emph{context capabilities} or just \emph{available context} when using 
the semantic view.

%---------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}
  {x : \tau \in \Gamma}
  {\coctx{\Gamma}{\cunit} \vdash x : \tau }
\end{equation*}
\begin{equation*}
\tyrule{const}
  {c : \tau \in \Delta}
  {\coctx{\Gamma}{\czero} \vdash c : \tau }
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\cclrd{r'}} \vdash e : \tau }
  {\coctx{\Gamma}{\cclrd{r}} \vdash e : \tau }\quad\quad(\cclrd{r'} \cleq \cclrd{r})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2 &
   \coctx{\Gamma}{\cclrd{s}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\cclrd{r} \;\cpar\; (\cclrd{s} \,\cseq\, \cclrd{t})} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\cclrd{r}\;\czip\;\cclrd{s}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\cclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2 }
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 &
    \coctx{\Gamma, x:\tau_1}{\cclrd{s}} \vdash e_2 : \tau_2}
  {\coctx{\Gamma}{\cclrd{s} \;\cpar\; (\cclrd{s} \,\cseq\, \cclrd{r})} \vdash \kvd{let}~x=e_1~\kvd{in}~e_2 : \tau_2 }
\end{equation*}

\caption{Type system for the flat coeffect calculus}
\label{fig:flat-types}
\end{figure}

%---------------------------------------------------------------------------------------------------

\subsection{Flat coeffect types}
The type system for flat coeffect calculus is shown in Figure~\ref{fig:flat-types}. Variables 
(\emph{var}) and constants (\emph{const}) are annotated with special values provided by the 
coeffect algebra. Following the top-down syntactic reading, the (\emph{sub}) rule allows us to 
treat an expression with fewer context requirements as an expression with more context requirements. 

The (\emph{abs}) rule is defined as discussed in Section~\ref{sec:flat-calculus-lambda}. The
body is annotated with context requirements $\cclrd{r} \,\czip\, \cclrd{s}$, which are then split
between the context-requirements on the declaration-site $\cclrd{r}$ and context-requirements on
the call-site $\cclrd{s}$. Examples of the $\czip$ operator are discussed in the next section.

In function application (\emph{app}), context requirements of both expressions and the 
function are combined as discussed in Chapter~\ref{ch:applications}. The pointwise composition
$\cpar$ is used to combine the context requirements of the expression representing a function 
$\cclrd{r}$ and the context requirements of the argument, sequentially composed with the 
context-requirements of the function $\cclrd{s}\, \cseq \,\cclrd{t}$.

The type system also includes a rule for let-binding. The rule is \emph{not} equivalent to the
derivation for $(\lambda x.e_2)~e_1$, but it represents one admissible typing derivation. We
return to let-binding after looking a number of examples. Additional constructs such 
as recursion and tuples are covered in Section~\ref{sec:flat-exts}.

%---------------------------------------------------------------------------------------------------

\subsection{Examples of flat coeffects}

The flat coeffect calculus generalizes the flat systems discussed in 
Section~\ref{sec:applications-flat} of the previous chapter. We can instantiate it to a specific
use just by providing a flat coeffect algebra. The following summary defines the systems for implicit 
parameters, liveness and data-flow. For the latter two, we obtain more general (but compatible) rule 
for lambda abstraction.

\begin{example}[Implicit parameters]
Assuming \ident{Id} is a set of implicit parameter names, the flat coeffect algebra 
is formed by $(\mathcal{P}(\ident{Id}), \cup, \cup, \cup, \emptyset, \emptyset, \subseteq)$.
\end{example}

\noindent
For simplicity, we assume that all parameters have the same type $\rho$ and so the annotations only
track sets of names. The definition uses set union for all three operations. Both variables and
constants are are annotated with $\emptyset$ and the ordering is defined by $\subseteq$. The 
definition satisfies the flat coeffect algebra laws because $(S, \cup, \emptyset)$ is an idempotent, 
commutative monoid. The system has a single additional typing rule for accessing the value of a
parameter:
%
\begin{equation*}
\tyrule{param}
  { \ident{?p} \in \cclrd{c} }
  { \coctx{\Gamma}{\cclrd{c}} \vdash \ident{?p} : \rho }
\end{equation*}
%
The rule specifies that the accessed parameter $\ident{?p}$ needs to be in the set of required
parameters $\cclrd{c}$. As discussed earlier, we use the same type $\rho$ for all parameters, but
it is easy to define an extension tracking set of parameters with type annotations.

\begin{example}[Liveness]
Let $L=\{ \ident{L}, \ident{D} \}$ be a two-point lattice such that $\ident{D} \sqsubseteq \ident{L}$
with a join $\sqcup$ and meet $\sqcap$. The flat coeffect algebra for liveness is then formed by
$(L, \sqcup, \sqcap, \sqcap, \ident{L}, \ident{D}, \sqsubseteq)$.
\end{example}

\noindent
As in Section~\ref{sec:applications-flat-live}, sequential composition $\cseq$ is modelled by 
the join operation $\sqcup$ and point-wise composition $\cpar$ is modelled by meet $\sqcap$. 
Two-point lattice is a commutative, idempotent monoid. The distributivity 
$(r \sqcap s) \sqcup t = (r \sqcup t) \sqcap (s \sqcup t)$ does not hold for \emph{every} 
lattice, but it trivially holds for a two-point lattice used here.

The definition uses meet $\sqcap$ for the $\czip$ operator that is used by lambda abstraction.
This means that, when the body is live $\ident{L}$, both declaration-site and call-site are 
marked as live $\ident{L}$. When the body is dead $\ident{D}$, the declaration-site and call-site
can be marked as dead $\ident{D}$, or as live $\ident{L}$, which is less precise, but permissible
over-approximation, which could otherwise be achieved via sub-typing.

\begin{example}[Data-flow]
In data-flow, context is annotated with natural numbers and the flat coeffect algebra is formed 
by $(\mathbb{N}, +, \mathit{max}, \mathit{min}, 0, 0, \leq)$.
\end{example}

\noindent
As discussed earlier, sequential composition $\cseq$ is represented by $+$ and point-wise 
composition $\cpar$ uses $\emph{max}$. For data-flow, we need a third separate operator for
lambda abstraction. Annotating the body with $\emph{min}(\cclrd{r}, \cclrd{s})$ ensures that
both call-site and declaration-site annotations are equal or greater than the annotation 
of the body. As with liveness, this allows over-approximation. 

As required by the laws, $(\mathbb{N}, +, 0)$ and $(\mathbb{N}, \mathit{max}, 0)$ form monoids
and $(\mathbb{N}, \mathit{min})$ forms a band. Note that data-flow is our first example where 
$+$ is not idempotent. The distributivity laws require the following to be the case:
$\mathit{max}(r,s) + t = \mathit{max}(r+t, s+t)$, which is easy to see. Finally, a simple 
data-flow language includes an additional rule for $\kvd{prev}$:
%
\begin{equation*}
\tyrule{prev}
  { \coctx{\Gamma}{\cclrd{c}} \vdash e : \tau }
  { \coctx{\Gamma}{\cclrd{c}+1} \vdash \kvd{prev}~e : \tau }
\end{equation*}
%
As a further example that was not covered earlier, it is also possible to combine liveness analysis
and data-flow. In the above calculus, $0$ denotes that we require current value, but no previous
values. However, for constants, we do not even need the current value.

\begin{example}[Optimized data-flow]
In optimized data-flow, context is annotated with natural numbers extended with the $\bot$ element,
that is $\mathbb{N}_{\bot} = \mathbb{N} \cup \{\bot \}$ such that $\forall n \in \mathbb{N}. \bot \leq n$.
The flat coeffect algebra is $(\mathbb{N}_{\bot}, +, \mathit{max}, \mathit{min}, 0, \bot, \leq)$
where $m + n$ is $\bot$ whenever $m=\bot$ or $n=\bot$ and \emph{min}, \emph{max} treat $\bot$ as the
least element.
\end{example}

\noindent
Note that $(\mathbb{N}_{\bot}, +, 0)$ is a monoid for the extended definition of $+$,
$(\mathbb{N}, \emph{max}, \bot)$ is also a monoid and $(\mathbb{N}, \emph{min})$ is a band.
The required distributivity laws also holds for this algebra.

%---------------------------------------------------------------------------------------------------

\subsection{Typing of let binding}

Recall the (\emph{let}) rule in Figure~\ref{fig:flat-types}. It annotates the expression 
$\kvd{let}~x=e_1~\kvd{in}~e_2$ with context requirements $\cclrd{s}\;\cpar\;(\cclrd{s}\,\cseq\,\cclrd{r})$.
This is a special case of typing of an expression $(\lambda x.e_2)~e_1$, using the idempotence
of $\czip$ as follows:
%
\begin{equation*}
\tyrule{app}
  {\begin{array}{l}
   \vspace{-1.5em}
   \coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1
   \end{array} &
   \tyruler{abs}
       { \coctx{\Gamma, x:\tau_1}{\cclrd{s}} \vdash e_2 : \tau_2 }
       { \coctx{\Gamma}{\cclrd{s}} \vdash \lambda x.e_2 : \tau_1 \xrightarrow{\cclrd{s}} \tau_2 } }
  { \coctx{\Gamma}{\cclrd{s}\;\cpar\;(\cclrd{s}\,\cseq\,\cclrd{r})} \vdash (\lambda x.e_2)~e_1 : \tau_2 }    
\end{equation*}
%
This design decision is similar to ML value restriction, but it works the other way round. Our
\emph{let} binding is more restrictive rather than more general. The choice is motivated by the 
fact that the typing obtained using the special rule for let-binding is more precise (with respect 
to sub-coeffecting) for all the examples considered in this chapter. Table~\ref{tab:flat-simplelet}
shows how the coeffect annotations are simplified for our examples.

\begin{table}[!h]
\begin{center}
\begin{tabular}{ | l | c | c |}
\hline
& \textbf{\footnotesize Definition\hspace{1em}} & \textbf{\footnotesize Simplified\hspace{1em}} \\ \hline
\hspace{-1em}{\footnotesize Implicit parameters} & $\cclrd{s} \cup (\cclrd{s} \cup \cclrd{r})$ & $\cclrd{s} \cup \cclrd{r}$ \\ \hline
\hspace{-1em}{\footnotesize Liveness} & $\cclrd{s} \sqcap (\cclrd{s} \sqcup \cclrd{r})$ & $\cclrd{s}$ \\ \hline
\hspace{-1em}{\footnotesize Data-flow} & $\mathit{max}(\cclrd{s}, \cclrd{s} + \cclrd{r})$ & $\cclrd{s} + \cclrd{r}$ \\ \hline
\end{tabular}
\end{center}

\vspace{-0.5em}
\caption{Simplified annotation for let binding in sample flat calculi}
\label{tab:flat-simplelet}
\end{table}

\noindent
The simplified annotations directly follow from the definitions of particular flat coeffect 
algebras. It is perhaps somewhat unexpected that the annotation can be simplified in different
ways for different examples. 

To see that the simplified annotations are \emph{better}, assume that we used arbitrary 
splitting $\cclrd{s} = \cclrd{s_1}\,\czip\,\cclrd{s_2}$ rather than idempotence. The
``Definition'' column would use $\cclrd{s_1}$ and $\cclrd{s_2}$ for the first and second 
$\cclrd{s}$, respectively. The corresponding simplified annotation (using idempotence) would
have $\cclrd{s_1}\,\czip\,\cclrd{s_2}$ instead of $\cclrd{s}$. For all our systems, the 
simplified annotation (on the right) is more precise than the original (on the left):
%
\begin{equation*}
\begin{array}{rclll}
\cclrd{s_1} \cup (\cclrd{s_2} \cup \cclrd{r}) &\supseteq& (\cclrd{s_1} \cup \cclrd{s_2}) \cup \cclrd{r} 
  && \textnormal{(implicit parameters)}\\
\cclrd{s_1} \sqcap (\cclrd{s_2} \sqcup \cclrd{r}) &\sqsupseteq&  (\cclrd{s_1} \sqcap \cclrd{s_2}) 
  && \textnormal{(liveness)} \\
\mathit{max}(\cclrd{s_1}, \cclrd{s_2} + \cclrd{r}) &\geq& \mathit{min}(\cclrd{s_1}, \cclrd{s_2}) + \cclrd{r} 
  &\quad& \textnormal{(data-flow)} \\
\end{array}
\end{equation*}
%
The inequality cannot be proved from other properties of the flat coeffect algebra. To make
the flat coeffect system as general as possible, we do not \emph{in general} require it as
an additional axiom, although the above examples provide reasonable basis for requiring 
that the specialized annotation for let binding is the least possible annotation for the 
expression $(\lambda x.e_2)~e_1$.

% ==================================================================================================

\section{Categorical motivation}
\label{sec:flat-semantics}

a

\subsection{Comonads}
\subsection{Indexed comonads}
\subsection{Semantics of flat calculus}
\subsection{Examples}

% ==================================================================================================

\section{Equational theory}
\label{sec:flat-syntax}

\subsection{Call-by-value evaluation}
\subsection{Call-by-name evaluation}

% ==================================================================================================

\section{Syntactic extensions}
\label{sec:flat-exts}

\subsection{Lambda abstraction}
\subsection{Constants and pairs}
\subsection{Recursion}

% ==================================================================================================

\section{Type inference}
\label{sec:flat-inference}

\subsection{Semi-lattice formulation}
\subsection{Type inference algorithm}

% ==================================================================================================

\section{Related work}

\subsection{What can be monad}
\label{sec:flat-related-monads}

% ==================================================================================================

\section{Summary}

\section{----------------JUNK!}




% ==================================================================================================

~
\newpage
~

%---------------------------------------------------------------------------------------------------

% comonadic semantics
\newcommand{\iftor}[1]{C^{#1}}
\newcommand{\iftorhat}[1]{\hat{C}^{#1}}

\newcommand{\cosem}[1]{\llbracket #1 \rrbracket}
\newcommand{\interp}[1]{\llbracket #1 \rrbracket}
\newcommand{\ccat}[0]{\mathcal{C}}
\newcommand{\obj}[1]{\textnormal{obj}(#1)}

\newcommand{\cobind}[2]{#1^\dagger_{#2}}
\newcommand{\cmerge}[0]{ \ident{m} }
\newcommand{\csplit}[0]{ \ident{n} }
\newcommand{\counit}[0]{ \varepsilon }

% ==================================================================================================

\section{Coeffect semantics using indexed comonads}
\label{sec:comonads}

The approach of \emph{categorical semantics} interprets terms as
morphisms in some category.  For typed calculi, typing judgments $x_1 : \tau_1 \ldots x_n : \tau_n
\vdash e: \tau$ are usually mapped to morphisms $\interp{\tau_1} \times \ldots \times
\interp{\tau_n} \rightarrow \interp{\tau}$. Moggi showed the semantics of various effectful 
computations can be captured generally using the (\emph{strong}) \emph{monad}
structure~\cite{monad-notions}. Dually, Uustalu and Vene showed that
(\emph{monoidal}) \emph{comonads} capture various kinds of context-dependent 
computation~\cite{comonads-notions}.

We extend Uustalu and Vene's approach to give a semantics for
the coeffect calculus by generalising comonads to
\emph{indexed comonads}. We emphasise semantic intuition and
abbreviate the categorical foundations for space reasons.

\vspace{-1em}
\paragraph{Indexed comonads.}

Uustalu and Vene's approach interprets well-typed terms 
as morphisms $C (\tau_1 \times \ldots
\times \tau_n) \rightarrow \tau$, where $C$ encodes contexts
and has a comonad structure~\cite{comonads-notions}.
Indexed comonads comprise a \emph{family} of object mappings 
$C^r$ indexed by a coeffect $r$ describing the contextual requirements satisfied by
the encoded context. We interpret judgments $C^r (x_1 : \tau_1, \ldots, x_n : \tau_n) \vdash e : \tau$ as
morphisms $C^r (\interp{\tau_1} \times \ldots \times \interp{\tau_n}) \rightarrow \interp{\tau}$.

The indexed comonad structure provides a notion of composition
for computations with different contextual requirements.
%%
\begin{definition}
Given a monoid $(S, \cseq, \cunit)$ with binary operator $\cseq$ and
unit $\cunit$, an \emph{indexed comonad} over a category $\ccat$
comprises a family of object mappings $\iftor r$ where for all $r \in S$ and $A \in \obj{\ccat}$ then 
$\iftor r A \in \obj{\ccat}$ and:
%%
\begin{itemize}
\item a natural transformation $\counit_A : \iftor{\cunit} A \rightarrow A$, called the \emph{counit};
\item a family of mappings $\cobind{(-)}{r, s}$ from morphisms $\iftor
  r A \rightarrow B$ to \\ morphisms $\iftor{r \cseq{} s} A
  \rightarrow \iftor s B$ in $\ccat$, natural in $A,B$, called
  \emph{coextend};
\end{itemize}
%
\noindent
such that for all $f : \iftor r \tau_1 \rightarrow \tau_2$ and $g : \iftor s \tau_2 \rightarrow \tau_3$ 
the following equations hold:
%
\renewcommand{\arraycolsep}{1.5em}
\begin{align*}
\begin{array}{ccc}
\counit \circ \cobind{f}{r, \cunit} = f & 
\cobind{{(\counit)}}{\cunit, r} = \ident{id} & 
\cobind{(g \circ \cobind{f}{r, s})}{(r \cseq s), t} = \cobind{g}{s, t} \circ \cobind{f}{r, (s \cseq t)} \\
\end{array}
\end{align*}
\end{definition}
%
The \emph{coextend} operation gives rise to an associative composition operation for
computations with contextual requirements (with \emph{counit} as the identity):
%
\[
\hat{\circ} : (\iftor r \tau_1 \rightarrow \tau_2) \rightarrow (\iftor s \tau_2 \rightarrow \tau_3) 
  \rightarrow (\iftor{r \cseq s} \tau_1 \rightarrow \tau_3) \quad\quad\quad
g \, \hat{\circ} \, f = g \circ f^\dagger_{r,s}\quad
\]
%
The composition $\hat{\circ}$ best expresses the intention
of indexed comonads: contextual requirements of the composed
functions are combined. The properties of
the composition follow from the indexed comonad laws and the 
monoid $(S, \oplus, \cunit)$.

\paragraph{Example}
Indexed comonad are analogous to comonads (in coKleisli form), but
with the additional monoidal structure on indices.  Indeed, comonads
are a special case of indexed comonads with a trivial singleton
monoid, \eg{}, $(\{1\}, \ast, 1)$ with $1 \ast 1 = 1$ where $\iftor 1$
is the underlying functor of the comonad and $\counit$ and
$\cobind{(-)}{1, 1}$ are the usual comonad operations.
However, as demonstrated next, not all indexed comonads are derived from ordinary comonads.

\paragraph{Example}
The \emph{indexed partiality comonad} encodes free-variable contexts
of a computation which are either \emph{live} or \emph{dead} (\ie{}, have
\emph{liveness} coeffects) with the monoid $(\{\ident{D}, \ident{L}\},
\sqcap, \ident{L})$, where $\iftor{\ident L} A = A$ encodes live
contexts and $\iftor{\ident D} A = 1$ encodes dead contexts,
where $1$ is the unit type inhabited by a single value $()$.
The \emph{counit} operation $\counit{} : \iftor{\ident{L}} A \rightarrow A$
is defined $\counit\ x = x$ and \emph{coextend},
for all $f : \iftor r A \rightarrow B$, and thus
$\cobind{f}{r, s} : \; \iftor{r \sqcap s} A \rightarrow \iftor s B$,
is defined:
%
\begin{align*}
\begin{array}{llll}
\cobind{f}{\ident{D}, \ident{D}} x = () \qquad\qquad & 
\cobind{f}{\ident{D}, \ident{L}} x = f () \qquad\qquad &
\cobind{f}{\ident{L}, \ident{D}} x = () \qquad\qquad &
\cobind{f}{\ident{L}, \ident{L}} x = f~x 
\end{array}
\end{align*}
%
The indexed family $C^r$ here is analogous to the non-indexed \textsf{Maybe} (or \emph{option})
data type $\mathsf{Maybe}\ A = A + 1$.  This
type does not permit a comonad structure since
$\varepsilon : \mathsf{Maybe}\ A \rightarrow A$ is undefined at $(\textsf{inr} \, ())$. 
For the indexed comonad, $\counit$ need only be defined
 for $\iftor{\ident{L}} A = A$. Thus, indexed comonads capture a broader range of
 contextual notions of computation than comonads.

 Moreover, indexed comonads are not restricted by the \emph{shape
   preservation} property of comonads~\cite{orchard12codo}: that
 a coextended function cannot change the \emph{shape} of the
 context. For example, in the second case above $f^\dagger_{\ident{D},
   \ident{L}} : \iftor{\ident{D}} A \rightarrow \iftor{\ident{L}} B$
 where the shape changes from $1$ (empty context) to $B$ (available
 context). 

\vspace{-1em}
\subsection{Monoidal indexed comonads.}
Indexed comonads provide a semantics to sequential composition, but
additional structure is needed for the semantics of the full coeffect calculus.
Uustalu and Vene~\cite{comonads-notions} additionally require a (\emph{lax semi-}) \emph{monoidal comonad} 
structure, which provides a monoidal operation $\mathsf{m} : C A
\times C B \rightarrow C (A \times B)$ for merging contexts (used in
the semantics of abstraction).

The semantics of the coeffect calculus requires an indexed
lax semi-monoidal structure for combining contexts \emph{as well as} an indexed
\emph{colax} monoidal structure for \emph{splitting} contexts. These are provided
by two families of morphisms (given a coeffect algebra with $\vee$ and $\wedge$):
%
\begin{itemize}
\item $\cmerge_{r, s} : \iftor r A \times \iftor s B \rightarrow \iftor{(r \wedge s)}(A \times B)$ natural
in $A, B$;
\item $\csplit_{r, s} : \iftor{(r \vee s)}(A \times B) \rightarrow \iftor r A \times \iftor s B$ natural
in $A, B$;
\end{itemize}
%
\noindent
The $\cmerge_{r, s}$ operation merges contextual computations with
tags combined by $\wedge$ (greatest lower-bound), elucidating 
the behaviour of $\cmerge_{r, s}$: that merging may result in 
the loss of some parts of the contexts $r$ and $s$.

The $\csplit_{r, s}$ operation splits context-dependent computations
and thus the contextual requirements. To obtain coeffects $r$ and
$s$, the input needs to provide \emph{at least} $r$ and $s$, so the
tags are combined using the $\vee$ (least upper-bound).

For the sake of brevity, we elide the indexed versions of the laws required by Uustalu and Vene
(\eg~most importantly, merging two contexts and then adding the third is
equivalent to merging the last two and then adding the first; similar rule holds is required
for splitting).

\paragraph{Example}
For the indexed partiality comonad, given the liveness coeffect
algebra $(\{\ident{D}, \ident{L}\}, \sqcap, \sqcup, \sqcap, \ident{L})$,
the additional lax/colax monoidal operations are:
%%
\begin{align*}
\begin{array}{lll}
\cmerge_{\ident{L}, \ident{L}} (x, y) = (x, y) 
  \quad\quad& \csplit_{\ident{D}, \ident{D}} \;\; () \;\;\; = ((), ())
  \quad\quad& \csplit_{\ident{D}, \ident{L}} (x, y) = ((), y) \\
\cmerge_{\ident{r}, \ident{s}} \;\,(x, y) = () 
  & \csplit_{\ident{L}, \ident{D}} (x, y) = (x, ())
  & \csplit_{\ident{L}, \ident{L}} (x, y) = (x, y)
\end{array}
\end{align*}

\paragraph{Example}
Uustalu and Vene model causal dataflow computations using the
non-empty list comonad $\ident{NEList}~A = A \times (1 +
\ident{NEList}~A)$~\cite{comonads-notions}.  Whilst this comonad
implies a trivial indexed comonad, we define an indexed comonad with
integer indices for the number of past values demanded of the context.

We define $\ctyp{n}{A} = A \times (A \times \ldots \times A)$ where the first $A$ is the current
(always available) value, followed by a finite product of $n$ past values. The definition of the
operations is a straightforward extension of the work of Uustalu and Vene.

%\begin{example}
%The semantics of the coeffect calculus for
% dynamically-scoped implicit parameters, with coeffect
%algebra $(\mathcal{P}(\ident{Id}), \cup, \cup, \cup, \emptyset)$, 
%is provided by the indexed comonad $\iftor rA = A \times (r \rightarrow \tau)$
%where $r \in \mathcal{P}(\ident{Id})$ with operations:\dnote{The type here is wrong,
%do we need to store the types too? Maybe should just be a product.}
%%
%\vspace{-1.0em}
%\begin{equation*}
%\begin{array}{l}
%\cobind{f}{r, s} \; : \; \iftor{r \cup s} A \rightarrow \iftor s B\\
%\cobind{f}{r, s} (a, g) = (f(a, g|_r), g|_s)
%\\[1em]
%\counit{} (a, g) = a\\
%%\iota_{r, s} \; : \: \iftor r A \rightarrow \iftor s A\\
%\iota_{r, s}(a, g) = (a, g|_s)\quad(\textnormal{if}~\leq r)
%\end{array}
%\quad\begin{array}{l}
%\cmerge_{r, s} : \iftor r A \times \iftor s B \rightarrow \iftor{(r \cup s)}(A \times B)\\
%\cmerge_{r, s} ((a_1, g_1), (a_2, g_2)) = ((a_1, a_2), g_1|_{r \setminus s} \cup g_2 )
%\\[1em]
%\csplit_{r, s} : \iftor{(r \cup s)}(A \times B) \rightarrow \iftor r A \times \iftor s B \\
%\csplit_{r, s} ((a_1, a_2), g) = ((a_1, g|_r), (a_1, g|_s))
%\end{array}
%\end{equation*}
%\end{example}

%The function created using \emph{coextend} expects a function $g$ that is defined for
%resource names $r \cup s$. We use function restriction $g|_r$ and $g|_s$ to get functions that are 
%defined on resources required by $f$ and the result of coextend, respectively.

%The operation $\cmerge_{r, s}$ pairs the values and combines the resources available in both contexts. 
%It combines a function $g_1|_{r\setminus s}$ (defined for resources in $r$ excluding those in $s$) and 
%function $g_2$ (defined for resources $s$). This definition is not symmetric as it prefers resources 
%defined in the second context. As a result, the caller of a function can rebind resources defined
%at the declaration site. 

%Resources show that indexed comonads describe the structure of context more precisely
%than comonads. A comonad would have to use $TA = A \times (\Omega \rightharpoonup R)$ 
%with a \emph{partial} function on all resource names. Using indexed comonads, we can ensure that the function
%is defined on all resources tracked statically in the tag.\dnote{Needs tweaking}

\vspace{-1.5em}
\subsection{Categorical Semantics. }
\label{sec:comonads-semantics}

\newcommand{\llangle}{\langle\hspace{-0.25em}\langle}
\newcommand{\rrangle}{\rangle\hspace{-0.25em}\rangle}

\begin{figure*}[t]
\vspace{-1em}
\newcommand{\uu}[1]{\overline{#1}}
% \begin{equation*} 
% \cosem{\ctyp{r}{(x_1 : \tau_1 \times \ldots \times x_n : \tau_n)} \vdash e : \tau} : 
%   \ctyp{r}{(\tau_1 \times \ldots \times \tau_n)} \rightarrow \tau
% \end{equation*}
% \vspace{-0.4em}
\begin{equation*}
\begin{array}{rcll}
\cosem{\ctyp{r}{\Gamma} \vdash \lambda x.e : \ctyp{s}{\tau_1} \rightarrow \tau_2} &=& 
    \emph{curry} \; (\cosem{\ctyp{r \wedge s}{(\Gamma, x:\tau_1)} \vdash e : \tau_2} \circ \cmerge_{r, s})    %&$(1)$
\\[0.1em]
\cosem{\ctyp{r \vee (s \cseq t)}{\Gamma} \vdash e_1~e_2 : \tau} &=& 
    (\emph{uncurry} \;  \cosem{\ctyp{r}{\Gamma} \vdash e_1 : \ctyp{s}{\tau_1} \rightarrow \tau_2}) \, \circ \\
 & & \quad\; (id \times \cobind{\cosem{\ctyp{t}{\Gamma}\vdash e_2 : \tau_1}}{t,s})
    \circ \csplit_{r, s \cseq t} \circ \iftor{r \vee (s \cseq t)}\Delta
\\[0.1em]
\cosem{\ctyp{\cunit}{\Gamma} \vdash x_i : \tau_i} &=&
    \pi_i \circ \counit                                                                  % &$(3)$
%\\[0.1em]
%\cosem{\ctyp{r}{\Gamma} \vdash e : \tau} &=&
%    \cosem{\ctyp{s}{\Gamma} \vdash e : \tau} \circ \iota_{r, s}                              %   &%$(4)$
%\\[0.1em]
%\cosem{\ctyp{r\vee (r \cseq s)}{\Gamma} \vdash \kvd{let}~x=e_1~\kvd{in}~e_2 : \tau_2} &=&
%    \cosem{\ctyp{r}{(\Gamma, x:\tau_1)} \vdash e_2 : \tau_2} \circ
% ((\varepsilon \times \cosem{ \ctyp{s}{\Gamma} \vdash e_1 : \tau_1 }) \circ 
%\iftorhat{r \vee (r \cseq t)}\Delta
\end{array}
\end{equation*}
\vspace{-1.5em}
\caption{Categorical semantics for the coeffect calculus}
\label{fig:semantics}
\vspace{-1.0em}
\end{figure*}

Figure~\ref{fig:semantics} shows the
categorical semantics of the coeffect calculus
using additional operations 
$\pi_i$ for projection of the \emph{i}$^{th}$ element of a 
product, usual
\emph{curry} and \emph{uncurry} operations, and
 $\Delta : A \rightarrow A \times A$ duplicating a
value. While $\iftor{r}$ is a family of object mappings,
it is promoted to a family of functors with the derived morphism mapping 
$\iftor{r}(f) = \cobind{ (f \circ \counit) }{\cunit, r}$.

The semantics of variable access and abstraction are the same as in
Uustalu and Vene's semantics, modulo coeffects. Abstraction uses $\cmerge_{r, s}$ to merge the outer
context with the argument context for the context of the function body.
The indices of $\cunit$ for
$\counit$ and $r,s$ for $\cmerge_{r, s}$ match the coeffects
of the terms.
The semantics of application is more complex. It first duplicates the
free-variable values inside the context and then splits this context
using $\csplit_{r, {s \oplus t}}$. The two contexts (with
different coeffects) are passed to the two sub-expressions,
where the argument subexpression, passed a context $(s \oplus t)$,
is coextended to produce a context $s$ which is passed into
the parameter of the function subexpression (\emph{cf.} given $f : A \rightarrow (B \rightarrow C)$,
 $g : A \rightarrow B$, then $\emph{uncurry} \, f \, \circ \, (id \times g) \circ \Delta : A \rightarrow C$).

A semantics for sub-coeffecting is omitted, but may be provided
by an operation 
$\iota_{r, s} : \iftor r A \rightarrow \iftor s A$ natural in $A$, for all $r, s \in S$ where $s \leq r$,
which transforms a value $C^r A$ to $C^s A$ by
ignoring some of the encoded context.

% ==========================================================================================

\section{Syntax-based equational theory}
\label{sec:syntactic}

Operational semantics of every context-dependent language differs as the notion of context 
is always different. However, for coeffect calculi satisfying certain conditions we can 
define a universal equational theory. This suggests a pathway to an operational semantics for 
two out of our three examples (the notion of context for data-flow is more complex).

In a pure $\lambda$-calculus, $\beta$ and $\eta$ equality for
functions (also called \emph{local soundness} and \emph{completeness}
respectively~\cite{logic-modal-reconstruction})
describe how pairs of abstraction and application can be eliminated:
$(\lambda x . e_2) e_1 \equiv_\beta \subst{e_1}{x}{e_2}$ and $(\lambda x . e \, x) 
\equiv_\eta e$. The $\beta$ equality rule, using the usual Barendregt convention of 
syntactic substitution, implies a \emph{reduction},
giving part of an operational semantics for the calculus.

The call-by-name evaluation strategy modelled by $\beta$-reduction is
not suitable for impure calculi therefore a restricted $\beta$ rule,
corresponding to call-by-value, is used, \ie~$(\lambda x . e_2) v
\equiv \subst{e_2}{x}{v}$. Such reduction can be encoded by a
\emph{let}-binding term, $\kvd{let}~x=e_1~\kvd{in}~e_2$, which
corresponds to sequential composition of two computations, where the
resulting pure value of $e_1$ is substituted into
$e_2$~\cite{monads-inaction,monad-notions}.

%
% We consider here both a notion of \emph{let}-binding for the coeffect
% calculus, useful for a CBV evaluation, and a notion of substitution 
% for a CBV evaluation.
% 

For an equational theory of coeffects, consider first a notion 
of \emph{let}-binding equivalent to $(\lambda x . e_2)~e_1$, which
has the following type and coeffect rule:
%
\begin{equation}
\inference
  {\ctyp{s}{\Gamma} \vdash e_1 : \tau_1 &
   \ctyp{r_1 \wedge r_2}{(\Gamma, x : \tau_1)} \vdash e_2 : \tau_2}
  {\ctyp{r_1 \vee (r_2 \cseq s)}{\Gamma} \vdash \kvd{let}~x = e_1~\kvd{in}~e_2
: \tau_2 }
\label{eq:let1}
\end{equation}

\noindent
For our examples, $\wedge$ is idempotent (\ie{}, $r \wedge r = r$)
implying a simpler rule:

% For the three examples we consider, a simpler rule gives a more
% precise coeffect. Because $r \wedge r = r$ for all our examples, we
% can also a coeffect $r \vee (r \cseq s)$. Moreover,
%for our examples (but not necessarily for \emph{all} coeffect
%systems), $r \vee (r \cseq s) \leq r_1 \vee (r_2 \cseq s)$ meaning
%that the following gives more precise coeffects:
%
\begin{equation}
\inference
  {\ctyp{s}{\Gamma} \vdash e_1 : \tau_1 &
   \ctyp{r}{(\Gamma, x : \tau_1)} \vdash e_2 : \tau_2}
  {\ctyp{r \vee (r \cseq s)}{\Gamma} \vdash \kvd{let}~x = e_1~\kvd{in}~e_2 : \tau_2 }
\label{eq:let2}
\end{equation}
%%
For our examples (but not necessarily \emph{all} coeffect
systems), this defines a more ``precise'' coeffect with respect to $\leq$
where $r \vee (r \cseq s) \leq r_1 \vee (r_2 \cseq s)$.

This rule removes the non-principality of the first rule
(\ie~multiple possible typings).  However, using idempotency 
to split coeffects in abstraction would remove additional
flexibility needed by the implicit parameters example.

The coeffect $r \vee (r \cseq s)$ can
also be simplified for all our examples, leading to more intuitive
rules -- for implicit parameters $r \cup (r \cup s) = r \cup s$; for
liveness we get that $r \sqcup (r \sqcap s) = r$ and for dataflow we
obtain $\textit{max}(r, r+s) = r + s$.

Our calculus can be extended with \emph{let}-binding and \eqref{eq:let2}.
However, we also consider the cases when a
syntactic substitution $e_2[x \leftarrow e_1]$ has the coeffects
specified by the above rule \eqref{eq:let2} 
and prove \emph{subject reduction} theorem
for certain coeffect calculi.  We consider two common special cases
when the coeffect of variables $\cunit$ is the greatest ($\top$) or
least ($\bot$) element of the semi-lattice $(S, \vee)$ and derive
additional conditions that have to hold about the coeffect algebra:

\begin{lemma}[Substitution]
\label{thm:subst}
Given $C^r (\Gamma, x : \tau_2) \vdash e_1 : \tau_1$ and $C^s \Gamma \vdash e_2 : \tau_2$
then $C^{r \vee (r \oplus s)} \Gamma \vdash \subst{e_2}{x}{e_1} : \tau_1$ if 
the coeffect algebra satisfies the conditions that 
$\cunit$ is either the greatest or least element of the semi-lattice,
$\oplus = \wedge$, and $\oplus$ distributes over $\vee$,
\ie{}, $X \oplus (Y \vee Z) = (X \oplus Y) \vee (X \oplus Z)$.
\end{lemma}

\begin{proof}
By induction over $\vdash$, using the laws (\S\ref{sec:calculus}) and additional assumptions.
\end{proof}

Assuming $\rightarrow_\beta$ is the usual call-by-name reduction, the
following theorem models the evaluation of coeffect calculi with
coeffect algebra that satisfies the above requirements. We do not
consider \emph{call-by-value}, because our calculus does not have a
notion of \emph{value}, unless explicitly provided by
\emph{let}-binding (even a function ``value'' $\lambda x.e$ may have
immediate contextual requirements).

\begin{theorem}[Subject reduction]
\label{thm:reduction}
For a coeffect calculus, satisfying the conditions of Lemma~\ref{thm:subst}, if
$\ctyp{r}{\Gamma} \vdash e : \tau$ and $e \rightarrow_\beta e'$ then 
$\ctyp{r}{\Gamma} \vdash e' : \tau$.
\end{theorem}
\begin{proof}
A direct consequence of Lemma~\ref{thm:subst}. 
\end{proof}

The above theorem holds for both the liveness and resources examples,
but not for dataflow.  In the case of liveness, $\cunit$ is the
greatest element ($r \vee \cunit = \cunit$); in the case of
resources, $\cunit$ is the \emph{least} element ($r \vee \cunit =
r$) and the proof relies on the fact that additional
context-requirements can be placed at the context $\ctyp{r}{\Gamma}$
(without affecting the type of function when substituted under
$\lambda$ abstraction).

However, the coeffect calculus also captures context-dependence in
languages with more complex evaluation strategies than
\emph{call-by-name} reduction based on syntactic substitution.  In
particular, syntactic substitution does not provide a suitable evaluation
for dataflow (because a substituted expression needs to capture the
context of the original scope).

Nevertheless, the above results show that -- unlike effects --
context-dependent properties can be integrated with
\emph{call-by-name} languages. Our work also provides a model of
existing work, namely Haskell implicit parameters
\cite{app-implicit-parameters}.

% ==================================================================================================

\section{Related and further work}
\label{sec:related}

This paper follows the approaches of effect systems \cite{effects-gifford,effects-talpin-et-al,monads-effects-marriage}
and categorical semantics based on monads and comonads \cite{monad-notions,comonads-notions}. Syntactically,
\emph{coeffects} differ from \emph{effects} in that they model systems where $\lambda$-abstraction 
may split contextual requirements between the declaration-site and call-site.

Our \emph{indexed (monoidal) comonads} (\S\ref{sec:comonads}) fill the gap between (non-indexed)
\emph{(monoidal) comonads} of Uustalu and Vene \cite{comonads-notions}
and indexed monads of Atkey~\cite{monads-parameterised-notions}, Wadler and Thiemann
\cite{monads-effects-marriage}. Interestingly, \emph{indexed} comonads are \emph{more
general} than comonads, capturing more notions of context-dependence (\S\ref{sec:motivation}).

% --------------------------------------------------------------------------------------------------

\vspace{-1em}
\paragraph{Comonads and modal logics.}

Bierman and de Paiva \cite{logic-intuitionistic-modal} model the
$\square$ modality of an intuitionistic S4 modal logic using monoidal
comonads, which links our calculus to modal logics.  This link can be
materialized in two ways.

Pfenning et al. and Nanevski et al.  derive term languages using the Curry-Howard
correspondence~\cite{logic-modal-reconstruction,logic-intuitionistic-modal,logic-cmtt},
building a \emph{metalanguage} (akin to Moggi's monadic metalanguage
\cite{monad-notions}) that includes $\square$ as a type
constructor. For example, in \cite{logic-modal-reconstruction}, the
modal type $\Box \tau$ represents closed terms.
In contrast, the \emph{semantic} approach uses monads or comonads
\emph{only} as a semantics.  This has been employed by Uustalu and
Vene and (again) Moggi \cite{monad-notions,comonads-notions}.  We
follow the semantic approach.

Nanevski et al. extend an S4 term language to a \emph{contextual}
modal type theory (CMTT)~\cite{logic-cmtt}.
The \emph{context} is a set of variables required by a computation, which
makes CMTT useful for meta-programming and staged computations. Our contextual types are
indexed by a coeffect algebra, which is more general and can capture
variable contexts, but also integers, two-point lattices, \emph{etc.}.

The work on CMTT suggests two extensions to coeffects. The first is
developing the logical foundations. We briefly considered special cases
of our system that permits local soundness in \S\ref{sec:syntactic} and
local completeness can be treated similarly. The second problem is 
developing the coeffects \emph{metalanguage}. The use of coeffect algebras
would provide an additional flexibility over CMTT, allowing a wider range 
of applications.

% --------------------------------------------------------------------------------------------------

\vspace{-1em}
\paragraph{Relating effects and coeffects.} 
The difference between effects and coeffects is mainly in the (\emph{abs}) rule. While the 
semantic model (monads vs. comonads) is very different, we can consider extending the two to 
obtain equivalent syntactic rules. To allow splitting of implicit parameters in lambda abstraction, 
the reader monad needs an operation that eagerly performs some effects of a function: 
$(\tau_1 \rightarrow \mtyp{r \oplus s}{\tau_2}) \rightarrow \mtyp{r}{(\tau_1 \rightarrow \mtyp{s}{\tau_2})}$.
To obtain a pure lambda abstraction
for coeffects, we need to restrict the $\cmerge_{r, s}$ 
operation of indexed comonads, so that the first parameter is annotated with $\cunit$ (meaning
no effects): $\iftor \cunit A \times \iftor r B \rightarrow \iftor{r}(A \times B)$.

\newcommand{\cprd}{\times}
\newcommand{\cvop}{\oplus}

\vspace{-1em}
\paragraph{Structural coeffects.} To make the liveness analysis practical, we need to associate
information with individual variables (rather than the entire context). We can generalize the 
calculus from this paper by adding a product operation $\times$ to the coeffect algebra.
A variable context $x:\tau_1, y:\tau_2, z:\tau_3$ is then annotated with
$r\times s \times t$ where each component of the tag corresponds to a single variable. The system
then needs to be extended with structural rules such as:
%
\begin{equation*}
\inference[(\emph{abs})]
  {\ctyp{r \cprd s}{(\Gamma, x:\tau_1)} \vdash e : \tau_2}
  {\ctyp{r}{\Gamma} \vdash \lambda x.e : \ctyp{s}{\tau_1} \rightarrow \tau_2 }
\quad
\inference[(\emph{contr})]
  {\ctyp{r \cprd s}{(x:\tau_1, y:\tau_1)} \vdash e : \tau_2}
  {\ctyp{r \cvop s }{(z:\tau_1)} \vdash \subst{\subst{e}{x}{z}}{y}{z} : \tau_2 }
\end{equation*}
%
The context-requirements associated with function are exactly those linked to the specific
variable of the lambda abstraction. Rules such as contraction manipulate variables and perform
a corresponding operation on the indices.

The structural coeffect system is related to bunched typing \cite{types-bunched} (but generalizes
it by adding indices). We are currently investigating how to use structural coeffects to capture 
fine-grained context-dependence properties such as secure information flow \cite{app-secure-flow}
or, more generally, those captured by dependency core calculus \cite{types-dcc}.

% ==================================================================================================

\section{Conclusions}

We examined three simple calculi with associated
static analyses (liveness analysis, implicit parameters, and dataflow
analysis). These were unified in the \emph{coeffect calculus},
providing a general coeffect system parameterised by an
algebraic structure describing the propagation of context
requirements throughout a program.

We model the semantics of coeffect calculus using \emph{indexed comonad} -- a novel structure, which
is more powerful than (monoidal) comonads. Indices of the indexed comonad operations manifest the 
semantic propagation of context such that the propagation of information in the general coeffect
type system corresponds exactly to the semantic propagation of context in our categorical model.

We consider the analysis of context to be essential, not least for the examples here but 
also given increasingly rich and diverse distributed systems.
