\chapter{Context-aware systems}
\label{ch:applications}

Software developers as well as programming language researchers choose abstractions based not
just on how appropriate they are. Other factors include social aspects -- how well is the
abstraction known, how well is it documented and whether it is a standard tool of the
\emph{research programme}\footnote{A research programme, as introduced by Lakatos \cite{philosophy-lakatos},
is a network of scientists sharing the same basic assumptions and techniques.} that the researcher
unconsciously subscribes to.

For tracking of effects, such \emph{standard tools} are well known. When faced with an effectful
computation, programming language designers immediately pick monads. For context-aware computations,
there are no standard tools. Thus contextual properties may, at first, appear as a set of disconnected
examples. Existing systems that capture contextual properties use a wide range of methods including
special-purpose type systems, approaches arising from modal logic S4, as well as techniques based
on abstractions designed for other purpose, most frequently monads.

This chapter reviews some of the existing context-aware programming abstractions and presents them
in a uniform way. We start with disconnected examples, but at the end, we will see that they
share a common pattern\footnote{The different properties captured by monads may appear similarly
disconnected at first!}.

\paragraph{Chapter structure and contributions}
\begin{itemize}
\item We characterize contextual properties -- the Section~\ref{sec:applications-structure}
  explains what is a \emph{coeffect} and contrasts it with a better known notion of
  \emph{effect}. It explains what is the nature of properties that can be tracked using
  coeffect systems presented in this thesis.

\item We describe a number of simple calculi for tracking a wide range of contextual properties.
  The systems are adapted from diverse sources (type systems, static analyses, logics) and apply to
  various domains (cross-compilation, liveness, distributed computing, dataflow, security), but
  share a common structure.

\item The uniform presentation of the systems is the key contribution of this chapter. We distinguish
  between \emph{flat coeffect} systems (Section~\ref{sec:applications-flat}) and \emph{structural coeffect}
  systems (Section~\ref{sec:applications-structural}). This common structure is precisely
  captured by the two \emph{coeffect calculi} in the upcoming chapters.

\item In addition, the coeffect systems for tracking the number of accessed past values in
  dataflow languages (Sections~\ref{sec:applications-flat-dataflow} and \ref{sec:applications-structural-dataflow})
  presents novel results and can be used to optimize dataflow programs.
\end{itemize}



% ===================================================================================================
%
% 	  ###    #                           #
% 	 #   #   #                           #
% 	 #      ####   # ##   #   #   ###   ####   #   #  # ##    ###
% 	  ###    #     ##  #  #   #  #   #   #     #   #  ##  #  #   #
% 	     #   #     #      #   #  #       #     #   #  #      #####
% 	 #   #   #  #  #      #  ##  #   #   #  #  #  ##  #      #
% 	  ###     ##   #       ## #   ###     ##    ## #  #       ###
%
% ===================================================================================================

\section{Structure of coeffect systems}
\label{sec:applications-structure}

When introducing coeffect systems in Section~\ref{sec:path-effects-coeff}, we related coeffect systems
with effect systems. Effect systems track how a program affects the environment, or, in other words
capture some \emph{output impurity}. In contrast, coeffect systems track what a program requires from
the execution envionment, or \emph{input impurity}.

Effect systems generally use judgements of the form $\Gamma \vdash e : \tau \;\&\; \cclrd{\sigma}$,
associating effects $\sigma$ with the output type. We write coeffect
systems using judgements of the form $\coctx{\Gamma}{\cclrd{\sigma}} \vdash e : \tau$, associating
the context requirements with $\Gamma$. Thus, we extend the traditional notion of free-variable
context $\Gamma$ with richer notions of context. This notation emphasizes the right intuition,
but there are more important differences between effects and coeffects.

% --------------------------------------------------------------------------------------------------

\subsection{Effectful lambda abstraction}
\label{sec:applications-structure-lam}

The difference between effects and coeffects becomes apparent when we consider lambda abstraction.
The typical lambda abstraction rule for effect systems looks as (\emph{effect}) in
Figure~\ref{fig:applications-abs}. Wadler and Thiemann~\cite{monads-effects-marriage} explain how
the effect analysis works as follows:
%
\begin{quote}
\emph{In the rule for abstraction, the effect is empty because evaluation immediately
returns the function, with no side effects. The effect on the function arrow
is the same as the effect for the function body, because applying the function will
have the same side effects as evaluating the~body.}
\end{quote}
%
This is the key property of \emph{output impurity}. The effects are only produced when the
function is evaluated and so the effects of the body are attached to the function. A recent
work by Tate~\cite{effects-producer-semantics} uses the term \emph{producer} effect systems
for such standard systems and characterises them as follows:
%
\begin{quote}
\emph{Indeed, we will define an effect as a producer effect if all computations with that
effect can be thunked as ``pure'' computations for a domain-specific notion of purity.}
\end{quote}
%
The thunking is typically performed by a lambda abstraction -- given an effectful expression
$e$, the function $\lambda x.e$ is an effect free value (thunk) that delays all effects.
As shown in the next section, contextual properties do not follow this pattern.

% --------------------------------------------------------------------------------------------------

\begin{figure}
\begin{equation*}
\tyrule{pure}
  { \Gamma, x\!:\!\tau_1 \vdash e : \tau_2}
  { \Gamma \vdash \lambda x.e : \tau_1 \rightarrow \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{effect}
  { \Gamma, x\!:\!\tau_1 \vdash e : \tau_2 \,\&\, \cclrd{\sigma} }
  { \Gamma \vdash \lambda x.e : \tau_1 \xrightarrow{\cclrd{\sigma}} \tau_2 \,\&\, \cclrd{\emptyset} }
\end{equation*}

\figcaption{Lambda abstraction for pure and effectful computations}
\label{fig:applications-abs}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsection{Notions of context}

We look at three notions of context. The first is the standard free-variable context in
$\lambda$-calculus. This is well understood and we use it to demonstrate how contextual
properties behave. Then we consider two notions of context introduced in this thesis --
\emph{flat coeffects} refer to overall properties of the environment and \emph{structural coeffects}
refer to properties attached to individual variables. We could track properties associated
with values in data structures (\eg~fields of a tuple), but this is left as future work.

\paragraph{Variable coeffects.}

As discussed in Section~\ref{sec:path-binding}, variable access can be seen as a basic form
of context requirement in $\lambda$-calculus. The expression $x$ is typeable only in a context
that contains $x:\tau$ for some type $\tau$.

In lexically scoped languages, lambda abstraction (\emph{pure}), as shown in
Figure~\ref{fig:applications-abs}, splits the free-variable context of an expression into two parts.
At runtime, the value of the parameter has to be provided by the \emph{call site} (dynamic scope)
and the remaining values are provided by the \emph{declaration site} (lexical scope). In the type
checking, the splitting is determined syntactically. The notation $\lambda x.e$ \emph{names} the
variable whose value comes from the call site.

Flat and structural coeffects also split context-requirements between the declaration site and
the call site. The flat and structural coeffects capture two different ways of doing this.

\paragraph{Flat coeffects.}

In Section~\ref{sec:intro-context-example}, we used \emph{resources} in a distributed system as an
example of flat coeffects. These could be, for example, a database, GPS sensor or access to the current
time. We also outlined that such context requirements can be tracked as part of the typing assumption,
for example, say we have an expression $e$ that requires GPS coordinates and the current time.
The variable context of such expression will be annotated with a set of required resources,
\ie~$\coctx{\Gamma}{ \cclrd{\ident{\{ gps, time \}}} }$.

The interesting case is when we construct a lambda function $\lambda x.e$, marshall it and
send it to another node. In systems such as Acute \cite{app-distributed-acute}, the context
requirements can be satisfied in a number of ways. When the same resource is available at the target
machine (\eg~current time), we can transfer the function with a context requirement and \emph{rebind}
the resource. However, if the resource is not available (\eg.~GPS on the server), we need to a
capture \emph{remote reference}.

In the example discussed here, $\lambda x.e$ would require GPS sensor from the declaration
site (lexical scope) where the function is declared, which is attached to the current context
as $\coctx{\Gamma}{ \cclrd{\ident{\{ gps \}}} }$. The current time is required from the caller
of the function. So, the context requirement on the call site (dynamic scope) will be
$\cclrd{r}=\cclrd{\footnotesize\ident{\{ time \}}}$. In coeffect systems, we attach this information
to the function, writing $\tau_1 \xrightarrow{ \cclrd{r} } \tau_2$.

We look at resources in distributed programming in more details in Section~\ref{sec:applications-flat-distr}.
The important point here is that in flat coeffect systems, contextual requirements are
\emph{split} between the call site and declaration site. Furthermore, there is no syntactic
structure that determines how the requirements are split. As mentioned in Section~\ref{sec:path-binding-amb},
we decouple the definition of semantics from the domain-specific choice that determines how
context requirements are satisfied. We capture the choice in the type and give semantics over a
\emph{typing derivation}. A domain-specific algorithm then chooses the desirable typing -- for
example, by preferring resources available on the client over resources available on the server.

\paragraph{Structural coeffects.}
On the one hand, variable context provides a \emph{fine-grained tracking} mechanism of how context
(variables) are used. On the other hand, flat coeffects let us track \emph{additional information} about
the context. The purpose of \emph{structural coeffects} is to reconcile the two and to provide a way
for fine-grained tracking of additional information linked to variables in programs. Structural
coeffects follow the lexical scoping structure determined by the typing rules.

In Section~\ref{sec:intro-why-array}, we used an example of tracking array access patterns. For every
variable, the additional coeffect annotation keeps a range of indices that may be accessed relatively
to the current cursor. For example, consider an expression
$x[\kvd{cursor}] = y[\kvd{cursor}-1] + y[\kvd{cursor}+1]$.

Here, the variable context $\Gamma$ contains two variables, both of type \ident{Arr}. This means
$\Gamma = x\!:\!\ident{Arr},\, y\!:\!\ident{Arr}$. For simplicity, we treat \kvd{cursor} as a
language primitive. The coeffect annotations will be $(0,0)$ for $x$ and $(-1,1)$ for $y$,
denoting that we access only the current value in $x$, but we need access to both left and right
neighbours in the $y$ array. In order to unify the flat and structural notions, we attach this information
as a \emph{vector} of annotations associated with a \emph{vector} of variable and write:
$\coctx{x\!:\!\ident{Arr},\, y\!:\!\ident{Arr}}{ \aclrd{\alift{ (0,0), (-1,1) }} }$.
The unification is outlined in Section~\ref{sec:further-unified}.

In structural systems, the splitting of context is determined by the name (variable) binding.
For example, consider a function that takes $y$ and contains the above body:
$\lambda y.x[\kvd{cursor}] = y[\kvd{cursor}-1] + y[\kvd{cursor}+1]$. Here, the declaration site
contains $x$ and needs to provide access at least within a range $(0,0)$. The call site provides
a value for $y$, which needs to be accessible at least within $(-1, 1)$. In this way, structural
coeffects remove the ambiguity arising from the splitting of requirements in flat coeffect systems.

Before looking at concrete flat and structural systems, we briefly overview
some notation used in this thesis. Structural coeffects keep annotations as \emph{vectors} and
use a number of operations related to scalars and vectors.

% --------------------------------------------------------------------------------------------------

\subsection{Scalars and vectors}
\label{sec:applications-strucutre-vec}

The $\lambda$-calculus is asymmetric. It maps a context with \emph{multiple} variables to a
\emph{single} result. An expression with $n$ free variables of types $\tau_i$ can be modelled by a function
$\tau_1 \times \ldots \times \tau_n \rightarrow \tau$ with a product on the left, but a single value
on the right. In both effect systems and coeffect systems, we write the annotation as part of
the function arrow. However, in the underlying categorical model, effects are attached to the result
$\tau$, while coeffects are attached to the context $\tau_1 \times \ldots \times \tau_n$.

Structural coeffects have one annotation per each variable. Thus, the annotation consists
of multiple values -- one belonging to each variable. To distinguish between the overall annotation
and individual (per-variable) annotations, we call the overall coeffect a \emph{vector} consisting of
\emph{scalar} coeffects. This asymmetry also explains why coeffects are not trivially dual to
effects.

It is useful to clarify how vectors are used in this thesis. Suppose we have a set $\C$ of
\emph{scalars} ranged over by $\cclrd{r},\cclrd{s},\cclrd{t}$. A vector $\aclrd{R}$
over $\C$ is a tuple $\alift{ \cclrd{r_1}, \ldots, \cclrd{r_n} }$ of scalars.
We use bold face letters like $\aclrd{\textbf{r}}, \aclrd{\textbf{s}}, \aclrd{\textbf{t}}$ for
vectors and normal face $\cclrd{r},\cclrd{s},\cclrd{t}$ for scalars. We also say that a
\emph{shape} of a vector $\slen{\aclrd{\textbf{r}}}$ (or more generally any container)
determines the set of \emph{positions} in a vector. So, a vector of a shape (length) $n$ has positions
$\{ 1, 2, \ldots, n \}$. We discuss containers and shapes further in Section~\ref{sec:further-unified} and also
discuss how our use relates to containers of Abbott, Altenkirch and Ghani \cite{types-containers}.

Just as in the usual pointwise multiplication of a vector by a scalar, we lift any binary operation on scalars into a
scalar-vector one. For a binary operation on scalars $\circ : \C \times \C \rightarrow \C$, we define
 $\cclrd{s} \circ \aclrd{\textbf{r}} = \alift{ \cclrd{s}\circ\cclrd{r_1}, \ldots, \cclrd{s}\circ\cclrd{r_n}}$.
Relations on scalars can be also lifted to vectors. Given two vectors $\aclrd{\textbf{r}}, \aclrd{\textbf{s}}$ of the
same shape with positions $\{ 1, \ldots, n \}$ and a relation $\varpropto\, \subseteq \C \times \C$ we define
$\aclrd{\textbf{r}} \varpropto \aclrd{\textbf{s}} \Leftrightarrow (\cclrd{r_1} \varpropto \cclrd{s_1}) \wedge \ldots \wedge (\cclrd{r_n} \varpropto \cclrd{s_n}) $
Finally, we often concatenate vectors, for example, when joining two variable contexts.
Given vectors $\aclrd{\textbf{r}}, \aclrd{\textbf{s}}$ with (possibly different) shapes $\{ 1, \ldots, n \}$ and
$\{ 1, \ldots, m \}$, the associative operation for concatenation $\times$ is defined as
$\aclrd{\textbf{r}}\times\aclrd{\textbf{s}} = \alift{\cclrd{r_1},\ldots,\cclrd{r_n},\cclrd{s_1},\ldots,\cclrd{s_m}}$.

We note that an environment $\Gamma$ containing $n$ uniquely named, typed variables is also a vector,
but we continue to write `$,$' for the product, so $\Gamma_1, x\!:\!\tau, \Gamma_2$ should
be seen as $\Gamma_1 \times \langle x\!:\!\tau\rangle \times \Gamma_2$.




% ===================================================================================================
%
% 	 #####   ##            #
% 	 #        #            #
% 	 #        #     ###   ####
% 	 ####     #        #   #
% 	 #        #     ####   #
% 	 #        #    #   #   #  #
% 	 #       ###    ####    ##
%
% ===================================================================================================

\section{Flat coeffect systems}
\label{sec:applications-flat}

In flat coeffect systems, the additional contextual information are independent of lexically scoped
variables. As such, flat coeffects capture properties where the execution environment provides some
additional data, resources or information about the execution context.

As mentioned in the introduction, coeffect systems in this chapter may appear as a disconnected
set of examples at first. Indeed, this section covers a diverse set of calculi including
Haskell's implicit parameters (Section~\ref{sec:applications-flat-impl}), distributed computing and
cross-compilation (Section~\ref{sec:applications-flat-distr}), liveness analysis
(Section~\ref{sec:applications-flat-live}) and dataflow (Section~\ref{sec:applications-flat-dataflow}).

For three of the examples, we present a type system and a simple semantics (given inductively over
the typing derivation). We informally discuss how preferred typing derivation is chosen (to resolve
the inherent ambiguity), but leave details to later chapters. Although the examples
are not new, our novel presentation of the systems (and the fact that they appear side-by-side)
makes it possible to see that they share a common structure. The structure is captured by
a unified \emph{flat coeffect calculus} in Chapter~\ref{ch:flat}.

%---------------------------------------------------------------------------------------------------

\subsection{Implicit parameters and type classes}
\label{sec:applications-flat-impl}

Haskell provides two examples of flat coeffects -- type class constraints and implicit parameter
constraints \cite{app-type-classes,app-implicit-parameters}. Both of the features introduce additional
\emph{constraints} on the context requiring that the environment provides certain operations for
a type (type classes) or that it provides values for named implicit parameters.
In the Haskell type system, constraints $C$ are attached to the types of top-level declarations,
such as let-bound functions. The Haskell notation $\Gamma \vdash e : C \Rightarrow \tau$
corresponds to our notation $\coctx{\Gamma}{C} \vdash e : \tau$.

In this section, we present a type system for implicit parameters in terms of the coeffect typing
judgement. We briefly consider type classes, but do not give a full type system.

\paragraph{Implicit parameters.}
As discussed in Section~\ref{sec:path-binding-impl}, implicit parameters are a special kind of
variables that support dynamic scoping. They make it possible to parameterise a computation
(involving a long chain of function calls) without passing parameters explicitly as additional
arguments of all involved functions.

The dynamic scoping means that if a function uses a parameter $\ident{?param}$ then the caller of the
function must set a value of $\ident{?param}$ before calling the function. However, implicit
parameters also support lexical scoping. If the parameter $\ident{?param}$ is available in the
lexical scope where a function is defined, then the function will not require a value from the caller.

A simple language with support for implicit parameters has an expression $\ident{?param}$ to read a
parameter and an expression\footnote{Haskell uses $\kvd{let}~\ident{?p} = e_1~\kvd{in}~e_2$, but we use a
different keyword to avoid confusion.} $\kvd{letdyn}~\ident{?param} = e_1~\kvd{in}~e_2$ that sets a
parameter $\ident{?param}$ to the value of $e_1$ and evaluates $e_2$ in a context containing
$\ident{?param}$.

The fact that implicit parameters support both lexical and dynamic scoping becomes interesting
when we consider nested functions. The following function does some pre-processing and then returns a
function that builds a formatted string based on two implicit parameters $\ident{?width}$ and
$\ident{?size}$:

\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{format} = \lambda \ident{str}~\rightarrow \\[-0.25em]
\quad \kvd{let}~\ident{lines} = \ident{formatLines}~\ident{str}~\ident{?width}~\kvd{in}\\[-0.25em]
\quad (\lambda \ident{rest}~\rightarrow~\ident{append}~
         \ident{lines}~\ident{rest}~\ident{?width}~\ident{?size})
\end{array}
\end{equation*}
%
The body of the outer function accesses the parameter $\ident{?width}$, so it certainly requires a context
$\{ \ident{?width} \}$. The nested function (returned as a result) uses the parameter
$\ident{?width}$, but in addition also uses $\ident{?size}$. Where should the parameters used by the
nested function come from?

To keep examples in this chapter uniform, we do not use the Haskell notation and instead
write $\tau_1 \xrightarrow{r} \tau_2$ for a function that requires implicit parameters specified by $r$.
We also assume that are implicit parameters are of type $\ident{num}$, so the annotation can be a
simple set of names (rather than mapping from names to types). In a purely dynamically scoped system,
implicit parameters would have to be defined when the user invokes the nested function.
However, implicit parameters behave as a combination of lexical and dynamic scoping. This means
that the nested function can capture the value of $\ident{?width}$ and require just $\ident{?size}$.
The following shows the two options:
%
\begin{equation}
\tag{\emph{dynamic}}
\ident{string} \xrightarrow{ \{ \ident{?width} \} }
  (\ident{string} \xrightarrow{ \{ \ident{?width}, \ident{?size} \} } \ident{string})
\end{equation}
\vspace{-1em}
\begin{equation}
\tag{\emph{mixed}}
\ident{string} \xrightarrow{ \{ \ident{?width} \} }
  (\ident{string} \xrightarrow{ \{ \ident{?size} \} } \ident{string})
\end{equation}
%
This is not a complete list of possible typings, but it demonstrates the options. The (\emph{dynamic})
case requires the parameter \ident{?width} twice (the caller may provide different value, in which
case, the semantics needs to specify which value is preferred). In the (\emph{mixed}) case, the
nested function captures the \ident{?width} parameter available from the declaration site. Using
the latter typing, the function can be called as follows:
%
\begin{equation*}
\begin{array}{l}
 \kvd{let}~\ident{formatHello} = (~\kvd{letdyn}~\ident{?width}=5~\kvd{in}~\ident{format}~\texttt{"Hello"})\\[-0.25em]
 \kvd{in}\,(~\kvd{letdyn}~\ident{?size} = 10~\kvd{in}~\ident{formatHello}~\texttt{"world"}~)
\end{array}
\end{equation*}
%
For different typings of \ident{format}, different ways of calling it are valid. This illustrates
the point made in Section~\ref{sec:applications-structure-lam} -- flat coeffect programs have
multiple typing derivations and the semantics depends on the domain-specific choice of preferred
typing. The following section shows how this looks in the type system for implicit parameters.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}
  {x : \tau \in \Gamma}
  {\coctx{\Gamma}{\cclrd{\emptyset}} \vdash x : \tau }
\end{equation*}
\begin{equation*}
\tyrule{param}
  {}
  {\coctx{\Gamma}{\cclrd{ \{\ident{?param}:\tau \} }} \vdash \ident{?param} : \tau }
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\cclrd{r'}} \vdash e : \tau }
  {\coctx{\Gamma}{\cclrd{r}} \vdash e : \tau }\quad\quad(\cclrd{r'} \subseteq \cclrd{r})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2 &
   \coctx{\Gamma}{\cclrd{s}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\cclrd{r} \cup \cclrd{s} \cup \cclrd{t}} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 &
    \coctx{\Gamma, x:\tau_1}{\cclrd{s}} \vdash e_2 : \tau_2}
  {\coctx{\Gamma}{\cclrd{r \cup s}} \vdash \kvd{let}~x=e_1~\kvd{in}~e_2 : \tau_2 }
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\cclrd{r} \cup \cclrd{s}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\cclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2 }
\end{equation*}
\begin{equation*}
\tyrule{letdyn}
  { \coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 &
    \coctx{\Gamma}{\cclrd{s}} \vdash e_2 : \tau_2}
  {\coctx{\Gamma}{\cclrd{r \cup (s \setminus \{ \ident{?p}:\tau_1 \})}} \vdash \kvd{letdyn}~\ident{?p}=e_1~\kvd{in}~e_2 : \tau_2 }
\end{equation*}

\figcaption{Coeffect rules for tracking implicit parameters}
\label{fig:applications-flat-impl}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type system.}

Figure~\ref{fig:applications-flat-impl} shows a type system that tracks the set of expression's
implicit parameters. The type system uses judgements of the form $\coctx{\Gamma}{\cclrd{r}} \vdash e : \tau$
meaning that an expression $e$ has a type $\tau$ in a free-variable context $\Gamma$ with a set
of implicit parameters specified by $\cclrd{r}$. The annotations $\cclrd{r},\cclrd{s},\cclrd{t}$ are
finite partial functions mapping implicit parameter names to types, \ie~$\cclrd{r},\cclrd{s},\cclrd{t} \subseteq
\ident{Names}$. The expressions include \ident{?param} to read implicit
parameter and \kvd{letdyn} to bind an implicit parameter. The types are standard, but functions are
annotated with the set of implicit parameters that must be available on the call site, \ie~
$\tau_1 \xrightarrow{\cclrd{s}} \tau_2$.

Accessing an ordinary variable (\emph{var}) does not require any implicit parameters. The rule that
introduces primitive context requirements is (\emph{param}). Accessing a parameter \ident{?param}
requires it to be available in the context. The context may provide more (unused)
implicit parameters thanks to the subcoeffecting rule (\emph{sub}).

When we read the rules from the top to the bottom, application (\emph{app}) and let binding
(\emph{let}) simply union the context requirements of the sub-expressions. However, lambda abstraction
(\emph{abs}) is where the example differs from effect systems. The implicit parameters required by
the body $\cclrd{r} \cup \cclrd{s}$ can be freely split between the declaration site ($\coctx{\Gamma}{\cclrd{r}}$)
and the call site ($\tau_1 \xrightarrow{\cclrd{s}} \tau_2$) and thus an expression may have multiple
valid typing derivations. Finally, (\emph{letdyn}) removes the bound parameter from the set of requirements.

The union operation $\cup$ is not a disjoint union, which means that the values for implicit
parameters can also be provided by both sites. For example, consider a function with a body
$\ident{?a} + \ident{?b}$. Assuming that the function takes and returns $\ident{int}$, the following
list shows 4 out of 9 possible valid typing. Full typing derivations can be found in Appendix~\ref{sec:appendixa-implicit}:
%
\label{pg:applications-flat-paramsex}
\begin{equation*}
\begin{array}{rcllllr}
\coctx{\Gamma}{\cclrd{ \{ \ident{?a}:\ident{int} \} }} &\vdash& \lambda x.\ident{?a} + \ident{?b} &:&
  \ident{int} \xrightarrow{\cclrd{ \{ \ident{?b}:\ident{int} \} }} \ident{int} &\qquad\qquad&(1) \\
\coctx{\Gamma}{\cclrd{ \{ \ident{?b}:\ident{int} \} }} &\vdash& \lambda x.\ident{?a} + \ident{?b} &:&
  \ident{int} \xrightarrow{\cclrd{ \{ \ident{?a}:\ident{int} \} }} \ident{int} &&(2)\\
\coctx{\Gamma}{\cclrd{ \{\ident{?a}:\ident{int} \} }} &\vdash& \lambda x.\ident{?a} + \ident{?b} &:&
  \ident{int} \xrightarrow{\cclrd{ \{\ident{?a}:\ident{int}, \ident{?b}:\ident{int} \} }} \ident{int} &&(3)\\
\coctx{\Gamma}{\cclrd{ \emptyset }} &\vdash& \lambda x.\ident{?a} + \ident{?b} &:&
  \ident{int} \xrightarrow{\cclrd{ \{\ident{?a}:\ident{int}, \ident{?b}:\ident{int} \} }} \ident{int} &&(4)
\end{array}
\end{equation*}
%
The first two examples demonstrate that the system does not have the principal typing property.
Both ($1$) and ($2$) are valid typings and they may both be desirable in certain contexts where
the function is used.

The next typing derivation ($3$) requires the parameter \ident{?a} from both the declaration site and
the call site. This means that, at runtime, two values will be available. Our semantics for the
system describes \emph{dynamic rebinding}, meaning that when the caller provides a value for a
parameter that is already specified by the declaration site, the new value hides the old one. This
means that only the value from the call site is actually used. This ($4$) gives a more precise
typing for this situation.

%---------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\hspace{0em}
\begin{array}{ll}
\hspace{4.5em}\semdef
  {\coctx{\Gamma}{\cclrd{r}} \vdash x_i : \tau_i}
  {\lambda ((x_1, \ldots, x_n), \_) . x_i}
& (\emph{var})
\\[0.0em]
\hspace{3.5em}\semdef
  {\coctx{\Gamma}{\cclrd{r}} \vdash \ident{?p} : \ident{num}}
  {\lambda (\_, f) . f~\ident{?p}}
& (\emph{param})
\\[1.5em]
\hspace{5em}\semdeff
  {\coctx{\Gamma}{\cclrd{r'}} \vdash e : \tau}
  {\coctx{\Gamma}{\cclrd{r}} \vdash e : \tau}
  {f}
  {\lambda (x, g) . f~(x, \restr{g}{\cclrd{r'}})}
& (\emph{sub})
\\[1.5em]
\hspace{0em}\emdeff
  {\coctx{\Gamma,y:\tau_1}{\cclrd{r}\cup\cclrd{s}} \vdash e : \tau_2}
  {\begin{array}{l}\sem{\coctx{\Gamma}{\cclrd{r}} \vdash \lambda y. e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2}\\[-0.25em]~\end{array}}
  {f}
  {\hspace{-0.5em}\begin{array}{l}
  \lambda ((x_1, \ldots, x_n), g_1) . \lambda (y, g_2) .\\[-0.25em]
  \quad f~((x_1, \ldots, x_n, y), g_1 \uplus g_2)
  \end{array}\hspace{-1em}~}
& (\emph{abs})
\\[1.5em]
\hspace{-0.8em}\emdefff
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2}
  {\coctx{\Gamma}{\cclrd{s}} \vdash e_2 : \tau_1}
  {\begin{array}{l}\sem{\coctx{\Gamma}{\cclrd{r}\cup\cclrd{s}\cup\cclrd{t}} \vdash e_1~e_2 : \tau_2}\\[-0.25em]~\end{array}}
  {f_1}
  {f_2}
  {\hspace{-0.5em}\begin{array}{l}
  \lambda (x, g) . \\[-0.25em]
  \quad(f_1~(x, \restr{g}{\cclrd{r}}))~(f_2~(x, \restr{g}{\cclrd{s}} ), \restr{g}{\cclrd{t}})
  \end{array}\hspace{-2em}~}
& (\emph{app})
\\[1.5em]
\hspace{-3.3em}\emdefff
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \ident{num}}
  {\coctx{\Gamma}{\cclrd{s}} \vdash e_2 : \tau_2}
  {\begin{array}{l}\sem{\coctx{\Gamma}{\cclrd{r \cup (s \setminus \{ \ident{?p} \})}} \vdash\\[-0.25em]
    \qquad\kvd{letdyn}~\ident{?p}=e_1~\kvd{in}~e_2 : \tau_2}\end{array}}
  {f_1}
  {f_2}
  {\hspace{-0.5em}\begin{array}{l}
  \lambda (x, g) . f_2~(x, \restr{g}{\cclrd{s} \setminus \cclrd{\{ \ident{?p} \}}} \,\uplus \\[-0.25em]
    \qquad \{ \ident{?p} \mapsto (f_1~(x, \restr{g}{\cclrd{r}})) \} )
  \end{array}\hspace{-1em}~}
& (\emph{letdyn})
\end{array}
\end{equation*}

\vspace{1em}
Assuming the following auxiliary definitions:
\begin{equation*}
\begin{array}{rcl}
 \restr{f}{\cclrd{r}} &=& \{ (p,v) \;|\; (p,v) \in f, \;p \in \cclrd{r} \}\\[-0.25em]
 f \uplus g &=& \restr{f}{\, \textit{dom}(f) \setminus \textit{dom}(g)} \cup g
\end{array}
\end{equation*}

\figcaption{Semantics of a language with implicit parameters}
\label{fig:applications-flat-implsem}
\vspace{-0.5em}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Semantics.}
Implicit parameters can be implemented by passing around a hidden dictionary that provides values
to the implicit parameters. Accessing a parameter then becomes a lookup in the dictionary and
the new \kvd{letdyn} construct extends the dictionary. To elucidate how such hidden dictionaries
are propagated through the program when using lambda abstractions and applications, we present a
simple semantics for implicit parameters. The goal here is not to prove properties of the language,
but simply to provide a better explanation. A detailed semantics in terms of indexed comonads is
shown in Chapter~\ref{ch:semantics}.

Given an expression $e$ of type $\tau$ that requires free variables $\Gamma$ and implicit parameters
$\cclrd{r}$, the semantics is a function that takes a product of variables from $\Gamma$ together
with a dictionary of implicit parameters and returns $\tau$:
%
\begin{equation*}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \cclrd{r} } \vdash e : \tau}
  ~:~ (\tau_1 \times \ldots \times \tau_n) \times (\cclrd{r} \rightarrow \ident{num}) \rightarrow \tau
\end{equation*}
%
The dictionary is represented as a function from $\cclrd{r}$ to $\ident{num}$. This means that it
provides a $\ident{num}$ value for all implicit parameters that are required according to the typing.
Note that the domain of the function is not the set of all possible implicit parameter names, but
only the finite subset of names that are required according to the typing.

The dictionary is also attached to the inputs of all functions. That is, a function $\tau_1 \xrightarrow{\cclrd{s}} \tau_2$
is interpreted by a function that takes $\tau_1$ together with a dictionary that defines values for
implicit parameters in $\cclrd{s}$:
%
\begin{equation*}
\begin{array}{l}
 \sem{\tau_1 \xrightarrow{\cclrd{s}} \tau_2} = \tau_1 \times (\cclrd{s} \rightarrow \ident{num}) \rightarrow \tau_2
\end{array}
\end{equation*}
%
The definition of the semantics is shown in Figure~\ref{fig:applications-flat-implsem}. We use a
notation that emphasizes the fact that the semantics is given over a typing derivation. On the
left-hand side of $=$, we show the applied typing rule. The right-hand side of $=$ then shows the
semantic functions assigned to the individual assumptions and the resulting semantics for the
consequent.

The (\emph{var}) and (\emph{param}) rules are simple -- they project the appropriate variable and
implicit parameter, respectively. When an expression requires implicit parameters $\cclrd{r}$, the
semantics always provides a dictionary defined \emph{exactly} on $\cclrd{r}$. To achieve this, the
(\emph{sub}) rule restricts the function to $\cclrd{r'}$ (which is valid because $\cclrd{r'} \subseteq \cclrd{r}$).

The most interesting rules are (\emph{abs}) and (\emph{app}). In abstraction, we get two dictionaries
$g_1$ and $g_2$ (from the declaration site and call site, respectively), which are combined and passed
to the body of the function. The semantics prefers values from the call site, which is captured by
the $\uplus$ operation. In application, we first evaluate the expression $e_1$, then $e_2$ and finally
call the returned function. The three calls use (possibly overlapping) restrictions of the dictionary
as required by the static types.

Finally, the (\emph{letdyn}) rule specifies the semantics of the \kvd{letdyn} construct, which
assigns a value to an implicit parameter. This is similar to (\emph{app}), because it needs to
evaluate the sub-expression first. After evaluating $e_1$, the result is added to the dictionary
using $\uplus$. The semantics of ordinary let binding is omitted, because let binding can be
treated as a syntactic sugar for $(\lambda x.e_2)~e_1$.

Without providing a proof here, we note that the semantics is sounds with respect to the type
system -- when evaluating an expression, it provides it with a dictionary that is guaranteed to
contain values for all implicit parameters that may be accessed. This can be easily checked by
examining the semantic rules (and noting that the restriction and union always provide the
expected set of parameters). This idea is captured more formally by the soundness proof for the
operational semantics given in Chapter~\ref{ch:semantics}.

\paragraph{Monadic semantics.}
Implicit parameters are related to the \emph{reader monad}. The type
$\tau_1 \times (\cclrd{r} \rightarrow \ident{num}) \rightarrow \tau_2$ is equivalent to
$\tau_1 \rightarrow ((\cclrd{r} \rightarrow \ident{num}) \rightarrow \tau_2)$ through currying. Thus, we can
express the function as $\tau_1 \rightarrow M\tau_2$ for $M\tau = (\cclrd{r} \rightarrow \ident{num}) \rightarrow \tau$.
Indeed, the reader monad can be used to model dynamic scoping. However, there is an important distinction
from implicit parameters. The usual monadic semantics models fully dynamic scoping, while implicit
parameters combine lexical and dynamic scoping.

When using the usual monadic semantics based on the reader monad, the semantics of the (\emph{abs})
rule would be modified as follows:
%
\begin{equation*}
\emdeff
  {\coctx{\Gamma,y:\tau_1}{\cclrd{r}} \vdash e : \tau_2}
  {\begin{array}{l}\sem{\coctx{\Gamma}{\cclrd{\emptyset}} \vdash \lambda y. e : \tau_1 \xrightarrow{\cclrd{t}} \tau_2}\\[-0.25em]~\end{array}}
  {f}
  {\hspace{-0.5em}\begin{array}{l}
  \lambda ((x_1, \ldots, x_n), \_) . \lambda (y, g) .\\[-0.25em]
  \quad f~((x_1, \ldots, x_n, y), g)
  \end{array}\hspace{-1em}~}
\end{equation*}
%
Note that the declaration site dictionary
is ignored and the body is called with only the dictionary provided by the call site. This is
a consequence of the fact that monadic functions are always pure values created using monadic
\emph{unit}, which turns a function $\tau_1 \rightarrow \mtyp{\cclrd{r}}{\tau_2}$ into a monadic
computation with no side-effects $\mtyp{\cclrd{\emptyset}}{\tau_1 \rightarrow \mtyp{\cclrd{r}}{\tau_2}}$.

As we discuss later in Section~\ref{sec:semantics-related-monads}, the reader monad can be extended
to model rebinding. However, later examples in this chapter, such as liveness in
Section~\ref{sec:applications-flat-live} show that other context-aware computations
cannot be captured by \emph{any} monad.

%---------------------------------------------------------------------------------------------------

\paragraph{Type classes.}
Another type of constraints in Haskell that is closely related to implicit parameters are
\emph{type class} constraints \cite{app-type-classes}. They provide a principled form of ad-hoc
polymorphism (overloading). When code uses an overloaded operation (\eg~comparison or numeric
operators) a constraint is placed on the context in which the operation is used. For example:
%
\begin{equation*}
\begin{array}{l}
 \ident{twoTimes}~::~\ident{Num}~\alpha \Rightarrow \alpha \rightarrow \alpha \\[-0.25em]
 \ident{twoTimes}~x=x+x
\end{array}
\end{equation*}
%
The constraint $\ident{Num}~\alpha$ on the function type arises from the use of the $+$ operator.
Similarly to implicit parameters, type classes can be implemented using a hidden dictionary. In
the above case, the function \ident{twoTimes} takes an additional dictionary that provides an operation
$+$ of type $\alpha \times \alpha \rightarrow \alpha$.

Type classes could be modelled as a coeffect system. The type system would annotate the context
with a set of required type classes. The typing of the body of \ident{twoTimes} would look as
follows:
%
\begin{equation*}
\coctx{x\!:\!\alpha}{ \cclrd{\{ \ident{Num}_\alpha \}} } \vdash x + x : \alpha
\end{equation*}
%
Similarly, the semantics of a language with type class constraints can be defined in a way
similar to implicit parameters. The interpretation of the body is a function that takes $\alpha$
together with a hidden dictionary of operations: $\alpha \times \ident{Num}_\alpha \rightarrow \alpha$.

Type classes and implicit parameters show two important points about flat coeffect systems.
First, the context requirements are associated with some \emph{scope}, such as the body
of a function. Second, they are associated with the input. To call a function that takes an
implicit parameter or has a type-class constraint, the caller needs to pass a (hidden) parameter
together with the function inputs.

\paragraph{Summary.}
Implicit parameters are the simplest example of a system where function abstraction does not
delay all impurities of the body. Here, the term ``delay'' refers to the fact that some
implicit parameters may be captured (from the declaration site) at the time when the function is
defined, but before it is executed. As discussed in Section~\ref{sec:applications-structure-lam},
this is the defining feature of \emph{coeffect} systems.

In this section, we have seen how this affects both the type system and the semantics of the
language. In the type system, the (\emph{abs}) rule places context-requirements on both the
declaration site and the call site. For implicit parameters, this rule introduces non-determinism
in the type-inference, because the parameters can be split arbitrarily. However, as we show in the
next section, this is not always the case. Semantically, lambda abstraction \emph{merges} two
parts of context (implicit parameter dictionaries) that are provided by the call site and
declaration site.

%----------------------------------------------------------------------------------------------------

\subsection{Distributed computing}
\label{sec:applications-flat-distr}

Distributed programming was used as one of the motivating examples for coeffects in
Chapter~\ref{ch:intro}. This section explores the use case. We look at rebindable resources and
cross-compilation. The structure of both is very similar to implicit parameters and type
class constraints, but they demonstrate that there is a broader use for coeffect systems.

% --------------------------------------------------------------------------------------------------

\paragraph{Rebindable resources.}

The need for parameters that support dynamic scoping also arises in distributed computing.
To quote an example discussed by Bierman et al. \cite{app-distributed-rebinding}: \emph{``Dynamic
binding is required in various guises, for example when a marshalled value is received from the
network, containing identifiers that must be rebound to local resources.''}

Rebindable parameters are identifiers that refer to some specific resource. When a function value
is marshalled and sent to another machine, rebindable resources can be handled in two ways.
If the resource is available on the target machine, the parameter may be \emph{rebound} to
the resource on the new machine. This is captured by the dynamic scoping rule. If the
resource is not available on the target machine, the resource is either marshalled or a \emph{remote
reference} is created. This is captured by the lexical scoping rule.

A practical language that supports rebindable resources is for example Acute \cite{app-distributed-acute}.
In the following example, we use the construct $\kvd{access}~\ident{Res}$ to represent
access to a rebindable resource named $\ident{Res}$. The following simple function accesses
a database together with a current date; then it filters from the database based on the date:
%
\begin{equation*}
\begin{array}{l}
 \kvd{let}~\ident{recentNews} = \lambda () \rightarrow\\[-0.25em]
 \quad\kvd{let}~\ident{db} = \kvd{access}~\ident{News}~\kvd{in}\\[-0.25em]
 \quad\ident{query}~\ident{db}~\str{SELECT * WHERE Date > \%1}~(\kvd{access}~\ident{Clock})
\end{array}
\end{equation*}
%
When \ident{recentNews} is created on the server and sent to the client, a remote reference to
the database (available only on the server) must be captured. If the client device supports a
clock, then \ident{Clock} can be locally \emph{rebound}, \eg, to accommodate time-zone changes.
Otherwise, the date and time needs to be obtained from the server too.

~

The type system and semantics for rebindable resources are essentially the same as those for
implicit parameters. Primitive requirements are introduced by the $\kvd{access}$ keyword.
Lambda abstraction splits the requirements between declaration site (capturing remote reference)
and call site (representing rebinding). For this reason, we do not discuss the system in details
and instead look at other uses.

%---------------------------------------------------------------------------------------------------

\begin{figure}
\begin{equation*}
\begin{array}{l}
\cmt{// Checks that input is valid; can run on both server and client}\\[-0.25em]
\kvd{let}~\ident{validateInput} = \lambda \ident{name} \rightarrow\\[-0.25em]
\quad\ident{name} \neq \str{} ~~\&\&~~ \ident{forall~isLetter~name}
\\[0.5em]
\cmt{// Searches database for a product; must run on the server-side}\\[-0.25em]
\kvd{let}~\ident{retrieveProduct} = \lambda \ident{name} \rightarrow\\[-0.25em]
\quad\kvd{if}~\ident{validateInput name}~\kvd{then}~\ident{Some}(\ident{queryProductDb~name})\\[-0.25em]
\quad\kvd{else}~\ident{None}
\\[0.5em]
\cmt{// Client-side function to show price or error (for invalid inputs)}\\[-0.25em]
\kvd{let}~\ident{showPrice} = \lambda \ident{name} \rightarrow\\[-0.25em]
\quad\kvd{if}~\ident{validateInput name}~\kvd{then}\\[-0.25em]
\quad\quad\kvd{match}~(\kvd{remote}~\ident{retrieveProduct}())~\kvd{with}\\[-0.25em]
\quad\quad|~\ident{Some}~\ident{p} \rightarrow \ident{showPrice}~(\ident{getPrice}~\ident{p})\\[-0.25em]
\quad\quad|~\ident{None}~\rightarrow \ident{showError}~\str{Invalid input on the server}\\[-0.25em]
\quad\kvd{else}~\ident{showError}~\str{Invalid input on the client}
\end{array}
\end{equation*}

\figcaption{Sample client-server application with input validation}
\label{fig:applications-flat-distr}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Cross-compilation.}
A related issue with distributed programming is the need to target increasing number of diverse
platforms. Modern applications often need to run on multiple platforms (iOS, Android, Windows or
as JavaScript) or multiple versions of the same platform. Many programming languages are capable
of targeting multiple different platforms. For example, functional languages that can be compiled
to native code and JavaScript include, among others, F\#, Haskell and OCaml \cite{app-ocaml-js}.

Links \cite{app-distributed-links}, F\# WebTools and WebSharper \cite{app-fsharp-webapps,app-fsharp-webtools},
ML5 and QWeSST \cite{app-distributed-ml5, app-distributed-qwesst} and Hop \cite{app-hop-lang} go
further and allow including code for multiple distinct platforms in a single source file.
A single program is then automatically split and compiled to multiple target runtimes. This
posses additional challenges -- it is necessary to check where each part of the program can run
and statically guarantee that it will be possible to compile code to the required target
platform (safe \emph{multi-targetting}).

We demonstrate the problem by looking at input validation. In applications that communicate over
an unsecured HTTP channel, user input needs to be validated interactively on the client-side (to
provide immediate response) and then again on the server-side (to guarantee safety).

Consider the client-server example in Figure~\ref{fig:applications-flat-distr}. The
\ident{retrieveProduct} function represents the server-side, while \ident{showPrice} is called
on the client-side and performs a remote call to the server-side function (how this is implemented
is not our concern here). To ensure that the input is valid \emph{both} functions call
\ident{validateInput} -- however, this is fine, because \ident{validateInput} uses only basic
functions and language features that can be cross-compiled to both client-side and server-side.

In Links \cite{app-distributed-links}, functions can be annotated as client-side, server-side
and database-side. F\# WebTools \cite{app-fsharp-webtools} supports cross-compiled (mixed-side)
functions similar to \ident{validateInput}. However, these are single-purpose language features
and they are not extensible. A practical implementation needs to be able to capture multiple
different patterns -- sets of environments (client, server, mobile) for distributed computing,
but also Android API level \cite{app-android-multitarget} to cross-compile for multiple versions
of the same platform.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]

a.) Set-based type system for cross-compilation, inspired by Links \cite{app-distributed-links}

\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\cclrd{r'}} \vdash e : \tau }
  {\coctx{\Gamma}{\cclrd{r}} \vdash e : \tau }\quad\quad(\cclrd{r'} \supseteq \cclrd{r})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2 &
   \coctx{\Gamma}{\cclrd{s}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\cclrd{r} \cap \cclrd{s} \cap \cclrd{t}} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\cclrd{r} \cup \cclrd{s}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\cclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2 }
\end{equation*}
\vspace{0.5em}

b.) Version-based type system, inspired by Android API level \cite{app-android-multitarget}

\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\cclrd{r'}} \vdash e : \tau }
  {\coctx{\Gamma}{\cclrd{r}} \vdash e : \tau }\quad\quad(\cclrd{r'} \leq \cclrd{r})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2 &
   \coctx{\Gamma}{\cclrd{s}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\ident{max} \{\cclrd{r}, \cclrd{s}, \cclrd{t} \}} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\cclrd{r}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\cclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\cclrd{r}} \tau_2 }
\end{equation*}

\figcaption{Two variants of coeffect typing rules for cross-compilation}
\label{fig:applications-flat-cross}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type systems.}

Cross-compilation is similar to resource tracking (and thus to the tracking of implicit
parameters), but it demonstrates a couple of new ideas that are important for flat coeffect
systems. Unlike with implicit parameters, we will not give a full type system in this
section, but we briefly look at two examples that explore the range of possibilities.

In the first system, shown in Figure~\ref{fig:applications-flat-cross} (a), the coeffect annotations
are sets of execution environments, \ie~$\cclrd{r}, \cclrd{s}, \cclrd{t} \subseteq \{ \ident{client},
\ident{server}, \ident{database} \}$. Subcoeffecting (\emph{sub}) lets us ignore some of the supported
execution environments; application (\emph{app}) can be only executed in the \emph{intersection} of the
environments required by the two expressions and the function value.

Subcoeffecting and application are trivially dual to the rules for implicit parameters. We just track
supported environments using intersection as opposed to tracking required parameters using union.
However, this symmetry does not hold for lambda abstraction (\emph{abs}), which still uses \emph{union}.
This models the case when there are two ways of executing the function:
%
\begin{itemize}
\item The function is represented as executable code for an call site environment
  and is executed there, possibly after it is marshalled and transferred to another machine.
\vspace{-0.5em}
\item The function body is compiled for the declaration site environment; the value
  that is returned is a remote reference to the code and function calls are performed as remote invocations.
\end{itemize}
%
This example ignores important considerations -- for example, it is likely desirable to make this
difference explicit (\eg~using explicit wrapping of unevaluated expressions) and the implementation
also needs to be clarified. For a system that does this, see \eg~ML5 \cite{app-distributed-ml5}).
The key point of our brief example is that the algebraic structure of coeffect annotations may be more
complex and use, for example, $\cap$ for application and $\cup$ for abstraction.

The second system, shown in Figure~\ref{fig:applications-flat-cross} (b) is inspired by the API
level requirements in Android. Coeffect annotations are simply numbers representing the level
($\cclrd{r}, \cclrd{s}, \cclrd{t} \in \mathbb{N}$). Levels are ordered increasingly, so we can
always require higher level (\emph{sub}). The requirement on function application (\emph{app}) is
the highest level of the levels required by the sub-expressions and the function. The system uses
yet another variant of lambda abstraction (\emph{abs}). The requirements of the body are duplicated
and placed on \emph{both} the declaration site and the call site.

The ML5 language \cite{app-distributed-ml5} mentioned above served as an inspiration for our example.
It tracks execution environments using modalities of modal S4 to represent the environment -- this
approach is similar to coeffects, both from the practical perspective, but also through deeper
theoretical links. However, it is based on the \emph{meta-language} style of embedding modalities
rather than on the \emph{language-semantics} style (see~Section~\ref{sec:path-sem-langs}). We
return to this topic in Section~\ref{sec:further-meta}.

% --------------------------------------------------------------------------------------------------

\subsection{Liveness analysis}
\label{sec:applications-flat-live}
Our next example shows the idea of coeffects from a different perspective. Rather than
keeping additional information independent of the variable context, we track properties about how
variables are used. Nevertheless, we still look at the left-hand side of $\vdash$ and the structure
of the typing rules and semantics will be very similar.

~

\emph{Live variable analysis} (LVA) \cite{app-modern-compiler} is a standard technique in compiler
theory. It detects whether a free variable of an expression may be used by a program during its
evaluation (it is \emph{live}) or whether it is definitely not needed (it is \emph{dead}). As an
optimization, compiler can remove bindings to dead variables as they are never accessed. Wadler
\cite{app-strictness-absecnce} describes the property of a variable that is dead as the
\emph{absence} of a variable.

\paragraph{Flat liveness analysis.}
In this section, we discuss a restricted form of liveness analysis. We do not track liveness of
\emph{individual} variables, but of the \emph{entire} variable context. This is not practically
useful, but it provides an interesting insight into how flat coeffects work. A per-variable liveness
analysis can be captured using structural coeffects and is discussed in Section~\ref{sec:applications-struct-live}.
Consider the following two examples:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{constant42} = \lambda \ident{x} \rightarrow 42\\
\kvd{let}~\ident{constant} = \lambda \ident{value} \rightarrow \lambda \ident{x} \rightarrow \ident{value}
\end{array}
\end{equation*}
%
The body of the first function is just a constant $42$ and so the context of the body is marked
as \emph{dead}. The parameter (call site) of the function is not used and can also be marked as dead.
Similarly, no variables from the declaration site are used and so they are also marked as dead.

In contrast, the body of the second function accesses a variable \ident{value} and so the body
of the function is marked as \emph{live}. In the flat system, we do not track \emph{which}
variable was used and so we have to mark both the call site and the declaration site as live (this will
be refined in a structural version).

\paragraph{Forward vs. backward \& may vs. must.}
Static analyses can be classified as either \emph{forward} or \emph{backward} (depending on how they
propagate information) and as either \emph{must} or \emph{may} (depending on what properties they
guarantee). Liveness is a \emph{backward} analysis -- the requirements are propagated from variables
to their declarations. The distinction between \emph{must} and \emph{may} is apparent when we look
at an example with conditionals:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{defaultArg}~= \lambda \ident{cond} \rightarrow \lambda \ident{input} \rightarrow\\[-0.25em]
\quad\kvd{if}~\ident{cond}~\kvd{then}~42~\kvd{else}~\ident{input}
\end{array}
\end{equation*}
%
Liveness analysis is a \emph{may} analysis meaning that it marks variable as live when it
\emph{may} be used and as dead if it is \emph{definitely} not used. This means that the variable
\ident{input} is \emph{live} in the example above. A \emph{must} analysis would mark the variable
only if it was used in both of the branches (this is sometimes called \emph{neededness} or
\emph{very busy} variable/expression).

The distinction between \emph{may} and \emph{must} analyses demonstrates the importance of
interaction between contextual properties and certain language constructs such as conditionals.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}
  {x : \tau \in \Gamma}
  {\coctx{\Gamma}{\cclrd{\cclrd{\ident{L}} }} \vdash x : \tau }
\end{equation*}
\begin{equation*}
\tyrule{num}
  {~}
  {\coctx{\Gamma}{ \cclrd{\cclrd{\ident{D}}} } \vdash n : \ident{num} }
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\cclrd{r'}} \vdash e : \tau }
  {\coctx{\Gamma}{\cclrd{r}} \vdash e : \tau }\quad\quad(\cclrd{r'} \,\cclrd{\sqsubseteq}\, \cclrd{r})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2 &
   \coctx{\Gamma}{\cclrd{s}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\cclrd{r} \,\cclrd{\sqcup}\, (\cclrd{s} \,\cclrd{\sqcap}\, \cclrd{t})} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 &
    \coctx{\Gamma, x:\tau_1}{\cclrd{s}} \vdash e_2 : \tau_2}
  {\coctx{\Gamma}{\cclrd{s}} \vdash \kvd{let}~x=e_1~\kvd{in}~e_2 : \tau_2 }
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\cclrd{r}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\cclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\cclrd{r}} \tau_2 }
\end{equation*}
\vspace{-0.9em}

\figcaption{Coeffect rules for tracking whole-context liveness}
\label{fig:applications-flat-liveness}
\vspace{-1.2em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type system.}
A type system that captures whole-context liveness annotates the context with value of a
two-point lattice $\mathcal{L} = \{ \cclrd{\ident{L}}, \cclrd{\ident{D}} \}$. The annotation \cclrd{\ident{L}} marks
the context as \emph{live} and \cclrd{\ident{D}} stands for a \emph{dead} context.
Figure~\ref{fig:applications-flat-livealg} (a) defines the ordering $\cclrd{\sqsubseteq}$, meet $\cclrd{\sqcup}$ and join
operations $\cclrd{\sqcap}$ of the lattice.

The typing rules for tracking whole-context liveness are shown in Figure~\ref{fig:applications-flat-liveness}.
The language now includes numerical constants $n$. Accessing a constant (\emph{num}) annotates
the context as dead using \cclrd{\ident{D}}. This contrasts with variable access (\emph{var}), which marks the
context as live using \cclrd{\ident{L}}. A dead context (definitely not needed) can be treated as live context
using the (\emph{sub}) rule. This captures the \emph{may} nature of the analysis.

The (\emph{app}) rule is best understood by discussing its semantics. The semantics uses
\emph{sequential composition} to compose the semantics of $e_2$ with the function obtained
as the result of $e_1$. However, we need more than just sequential composition. The same input
context is passed to the expression $e_1$ (in order to get the function value) and to a function
obtained by sequential composition (first evaluate the argument $e_2$ and pass the result to the
function value). This is captured by \emph{pointwise composition}.

Consider first \emph{sequential composition} of (semantic) functions $f, g$ annotated with
$\cclrd{r}, \cclrd{s}$. The composed function $g \circ f$ is annotated with $\cclrd{r} \cclrd{\sqcup} \cclrd{s}$
as shown in Figure~\ref{fig:applications-flat-livealg} (b).
The argument of the function $g \circ f$ is live only when the arguments of both $f$ and $g$ are
live ($1$). When the argument of $f$ is dead, but $g$ requires $\tau_2$ ($2$), we can evaluate
$f$ without any input and obtain $\tau_2$, which is then passed to $g$. When $g$ does not require
its argument ($3, 4$), we can just evaluate $g$, without evaluating $f$. Here, the semantics
\emph{implements} the dead code elimination optimization.

Secondly, a \emph{pointwise composition} passes the same argument to $f$ and $h$. The parameter
is live if either the parameter of $f$ or $h$ is live. The pointwise composition is written as
$\langle f, h \rangle$ and it combines annotations using $\cclrd{\sqcap}$ as shown in Figure~\ref{fig:applications-flat-livealg} (c).
Here, the argument is not needed only when both $f$ and $h$ do not need it ($1$). In all other cases,
the parameter is needed and is then used either once ($2,3$) or twice ($4$). The rule for function
application (\emph{app}) combines the two operations. The context $\Gamma$ is live if it is needed by
$e_1$ (which always needs to be evaluated) \emph{or} when it is needed by the function value \emph{and}
by $e_2$.

The (\emph{abs}) rule duplicates the annotation of the body, similarly to the cross-compilation
example in Figure~\ref{fig:applications-flat-cross}. When the body accesses any variables, it
requires both the argument and the variables from declaration site. When it does not use any variables,
it marks both as dead. Finally, the (\emph{let}) rule annotates the composed expression with the
liveness of the expression $e_2$ -- if the context of $e_2$ is live, then it also requires variables
from $\Gamma$; if it is dead, then it does not require $\Gamma$ or $x$.
The (\emph{let}) rule is again just a syntactic sugar for
$(\lambda x.e_2)~e_1$. This follows from the simple observation that
$\cclrd{r} \;\cclrd{\sqcup}\; (\cclrd{s} \;\cclrd{\sqcap}\; \cclrd{r}) = \cclrd{r}$.

% --------------------------------------------------------------------------------------------------

\begin{figure}
a.) The operations of a two-point lattice $\mathcal{L} = \{\cclrd{\ident{L}}, \cclrd{\ident{D}}\}$
where $\cclrd{\ident{D}} \,\cclrd{\sqsubseteq}\, \cclrd{\ident{L}}$ are:
%
\begin{equation*}
\begin{array}{rcl}
\cclrd{\ident{L}} \,\cclrd{\sqcup}\, \cclrd{\ident{L}} &=& \cclrd{\ident{L}}\\
\cclrd{\ident{D}} \,\cclrd{\sqcup}\, \cclrd{\ident{L}} &=& \cclrd{\ident{D}}\\
\end{array}
\qquad
\begin{array}{rcl}
\cclrd{\ident{L}} \,\cclrd{\sqcup}\, \cclrd{\ident{D}} &=& \cclrd{\ident{D}}\\
\cclrd{\ident{D}} \,\cclrd{\sqcup}\, \cclrd{\ident{D}} &=& \cclrd{\ident{D}}
\end{array}
\qquad
\begin{array}{rcl}
\cclrd{\ident{L}} \,\cclrd{\sqcap}\, \cclrd{\ident{L}} &=& \cclrd{\ident{L}}\\
\cclrd{\ident{D}} \,\cclrd{\sqcap}\, \cclrd{\ident{L}} &=& \cclrd{\ident{L}}\\
\end{array}
\qquad
\begin{array}{rcl}
\cclrd{\ident{L}} \,\cclrd{\sqcap}\, \cclrd{\ident{D}} &=& \cclrd{\ident{L}}\\
\cclrd{\ident{D}} \,\cclrd{\sqcap}\, \cclrd{\ident{D}} &=& \cclrd{\ident{D}}
\end{array}
\end{equation*}

\vspace{0.5em}
b.) Sequential composition composes annotations using $\cclrd{\sqcup}$:
\begin{equation*}
\begin{array}{llll}
f : \tau_1 \xrightarrow{\cclrd{r}} \tau_2 \qquad\qquad&
g : \tau_2 \xrightarrow{\cclrd{s}} \tau_3 \qquad\qquad&
g \circ f : \tau_1 \xrightarrow{\cclrd{r} \cclrd{\sqcup} \cclrd{s}} \tau_3 \qquad\qquad& ~
\\[0.75em]
f : \tau_1 \xrightarrow{\cclrd{\cclrd{\ident{L}}}} \tau_2 &
g : \tau_2 \xrightarrow{\cclrd{\cclrd{\ident{L}}}} \tau_3 &
g \circ f : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{L}} }} \tau_3 & (1)
\\[-0.10em]
f : \tau_1 \xrightarrow{\cclrd{\cclrd{\ident{D}}}} \tau_2 &
g : \tau_2 \xrightarrow{\cclrd{\cclrd{\ident{L}}}} \tau_3 &
g \circ f : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{D}} }} \tau_3 & (2)
\\[-0.10em]
f : \tau_1 \xrightarrow{\cclrd{\cclrd{\ident{L}}}} \tau_2 &
g : \tau_2 \xrightarrow{\cclrd{\cclrd{\ident{D}}}} \tau_3 &
g \circ f : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{D}} }} \tau_3 & (3)
\\[-0.10em]
f : \tau_1 \xrightarrow{\cclrd{\cclrd{\ident{D}}}} \tau_2 &
g : \tau_2 \xrightarrow{\cclrd{\cclrd{\ident{D}}}} \tau_3 &
g \circ f : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{D}} }} \tau_3 & (4)
\end{array}
\end{equation*}

\vspace{0.5em}
c.) Pointwise composition composes annotations using $\cclrd{\sqcap}$:
\begin{equation*}
\begin{array}{llll}
f : \tau_1 \xrightarrow{\cclrd{r}} \tau_2 \qquad\qquad&
h : \tau_1 \xrightarrow{\cclrd{s}} \tau_3 \qquad\qquad&
\langle f, h \rangle : \tau_1 \xrightarrow{\cclrd{r} \cclrd{\sqcap} \cclrd{s}} \tau_2 \times \tau_3 \qquad&~
\\[0.75em]
f : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{D}} }} \tau_2 &
h : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{D}} }} \tau_3 &
\langle f, h \rangle : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{D}} }} \tau_2 \times \tau_3 & (1)
\\[-0.10em]
f : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{D}} }} \tau_2 &
h : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{L}} }} \tau_3 &
\langle f, h \rangle : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{L}} }} \tau_2 \times \tau_3 & (2)
\\[-0.10em]
f : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{L}} }} \tau_2 &
h : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{D}} }} \tau_3 &
\langle f, h \rangle : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{L}} }} \tau_2 \times \tau_3 & (3)
\\[-0.10em]
f : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{L}} }} \tau_2 &
h : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{L}} }} \tau_3 &
\langle f, h \rangle : \tau_1 \xrightarrow{\cclrd{ \cclrd{\ident{L}} }} \tau_2 \times \tau_3 & (4)
\end{array}
\end{equation*}

\figcaption{Liveness annotations with sequential and pointwise composition}
\label{fig:applications-flat-livealg}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Examples.}
Before looking at the semantics, we consider a number of simple examples to demonstrate the
key aspects of the system. Full typing derivations are shown in Appendix~\ref{sec:appendixa-liveness}:
%
\begin{equation*}
\begin{array}{lll}
(\lambda x . 42)~y &~\hspace{1em}~&(1)\\
\ident{twoTimes}~42          &&(2)\\
(\lambda x . x)~42 &&(3)\\
\end{array}
\end{equation*}
%
In the first case ($1$), the context is dead. The function's parameter is dead and so the
overall context is dead, even though the argument uses a variable $y$ -- the semantics evaluates
the function without passing it an actual argument. In the second case ($2$), the function is
a variable that needs to be obtained and so the context is live. In the last case ($3$), the
function accesses a variable and so its declaration site is marked as requiring the context
(\emph{abs}). This is where structural coeffect analysis would be more precise -- the system shown
here cannot capture the fact that $x$ is a bound variable.

%---------------------------------------------------------------------------------------------------

\paragraph{Semantics.}
As showed in the examples, the type system for the liveness coeffect calculus marks the context
of an expression $(\lambda x.42)~y$ as dead. This means that the semantics of the above expression
must not evaluate the argument $y$. In other words, the type system is only sound if the semantics
includes dead code elimination.

To capture dead code elimination in the semantics, we add a special empty value and pass it as an
argument to a function whose argument is not needed, so $(\lambda x.42)$ will be called with
an empty value as argument (because it does not need its argument).

We can represent such empty values using the option type (known as \ident{Maybe} in Haskell).
We use the notation $\tau + 1$ to denote option types. Given a context with variables $x_i$ of
type $\tau_i$, the semantics is a function taking $(\tau_1 \times \ldots \times \tau_n) + 1$.
When the context is live, it will be called with the left value (product of variable assignments);
when the context is dead, it will be called with the right value (containing no information).

However, ordinary option type is not sufficient. We need to capture the fact that the
representation depends on the annotation -- in other words, the type is \emph{indexed} by
the coeffect annotation. The indexing is discussed in details in Section~\ref{sec:semantics-flat-idx}.
For now, it suffices to define the semantics using two separate rules:
%
\begin{equation*}
\begin{array}{rlrcl}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \cclrd{\cclrd{\ident{L}}} } \vdash e : \tau}
  &:& (\tau_1 \times \ldots \times \tau_n) &\narrow{\rightarrow}& \tau\\
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \cclrd{\cclrd{\ident{D}}} } \vdash e : \tau}
  &:& 1 &\narrow{\rightarrow}& \tau
\end{array}
\end{equation*}
%
The semantics of functions is defined similarly. When the argument of a function is live, the function
takes the input value; when the argument is dead, the semantic function takes a unit as its argument:
%
\begin{equation*}
\begin{array}{l}
\sem{\tau_1 \xrightarrow{\cclrd{\cclrd{\ident{L}}}} \tau_2} = \tau_1 \rightarrow \tau_2\\
\sem{\tau_1 \xrightarrow{\cclrd{\cclrd{\ident{D}}}} \tau_2} = 1 \rightarrow \tau_2
\end{array}
\end{equation*}
%
Unlike with implicit parameters, the coeffect system for liveness tracking cannot be modelled
using monads. Any monadic semantics would express functions as $\tau_1 \rightarrow M\, \tau_2$.
Unless laziness is already built-in, there is no way to call such function without
first obtaining a value $\tau_1$. The above semantics makes this possible by taking a unit $1$ when
the argument is not live.

In Figure~\ref{fig:applications-flat-livsem}, we define the semantics directly. We write $()$ for
the only value of type $1$. This appears, for example, in (\emph{const}) which takes $()$ as the
input and returns a constant using a global dictionary $\delta$. In (\emph{var}), the context is live
and so the semantics performs a projection. Subcoeffecting is captured by two rules. A dead context
can be treated as live using (\emph{abs-1}); in other cases, the annotation is not changed (\emph{abs-2}).

Lambda abstraction can be annotated in just two ways. When the body requires context (\emph{abs-1}),
the value of a bound variable $y$ is added to the context $\Gamma$ before passing it to the body.
When the body does not require context (\emph{abs-2}), it is called with $()$ as the input.

For application, there are 8 possible combinations of annotations. The semantics of some of them
is the same, so we only need to show 3 cases. The rules should be read as ML-style pattern matching,
where the last rule handles all cases not covered by the first two. In (\emph{app-1}), we handle the
case when the function $f_2$ does not require its argument -- $x$ is not used and instead, the function
is called with $()$ as the argument. The case (\emph{app-2}) covers the case when the expression
$e_1$ does not require a context, but $e_1$ does. Finally, in (\emph{app-3}), the same input
(which may be either tuple of variables or unit) is propagated uniformly to both $e_1$ and $e_2$.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\hspace{0em}
\begin{array}{ll}
\hspace{3.5em}\semdef
  {\coctx{\Gamma}{\cclrd{\ident{L}}} \vdash x_i : \tau_i}
  {\lambda (x_1, \ldots, x_n) . x_i}
& (\emph{var})
\\[-0.75em]
\hspace{2.75em}\semdef
  {\coctx{\Gamma}{\cclrd{\ident{D}}} \vdash n : \ident{num}}
  {\lambda () . n}
& (\emph{num})
\\[2em]
\hspace{4.25em}\semdeff
  {\coctx{\Gamma}{\cclrd{\ident{D}}} \vdash e : \tau}
  {\coctx{\Gamma}{\cclrd{\ident{L}}} \vdash e : \tau}
  {f}
  {\lambda x . f~()}
& (\emph{sub-1})
\\[1em]
\hspace{4.5em}\semdeff
  {\coctx{\Gamma}{\cclrd{r}} \vdash e : \tau}
  {\coctx{\Gamma}{\cclrd{r}} \vdash e : \tau}
  {f}
  {\lambda x . f~x}
& (\emph{sub-2})
\\[2.5em]
\hspace{-0.55em}\emdeff
  {\coctx{\Gamma,y:\tau_1}{\cclrd{\ident{L}}} \vdash e : \tau_2}
  {\begin{array}{l}\sem{\coctx{\Gamma}{\cclrd{\ident{L}}} \vdash \lambda y. e : \tau_1 \xrightarrow{\cclrd{\ident{L}}} \tau_2}\\[-0.25em]~\end{array}\hspace{-0.5em}~}
  {f}
  {\hspace{-0.5em}\begin{array}{l}\lambda (x_1, \ldots, x_n) . \lambda y .\\[-0.25em]
    \quad f~(x_1, \ldots, x_n, y)\end{array}~~}
& (\emph{abs-1})
\\[1em]
\hspace{-0.5em}\semdeff
  {\coctx{\Gamma,y:\tau_1}{\cclrd{\ident{D}}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\cclrd{\ident{D}}} \vdash \lambda y. e : \tau_1 \xrightarrow{\cclrd{\ident{D}}} \tau_2}
  {f}
  {\lambda () . \lambda () . f~()}
& (\emph{abs-2})
\\[2.5em]
\hspace{0.75em}\semdefff
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{\ident{D}}} \tau_2}
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_2 : \tau_1}
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_1~e_2 : \tau_2}
  {f}
  {\_}
  {\lambda x . (f~x)~()}
& (\emph{app-1})
\\[2em]
\hspace{0.75em}\semdefff
  {\coctx{\Gamma}{\cclrd{\ident{L}}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{\ident{L}}} \tau_2}
  {\coctx{\Gamma}{\cclrd{\ident{D}}} \vdash e_2 : \tau_1}
  {\coctx{\Gamma}{\cclrd{\ident{L}}} \vdash e_1~e_2 : \tau_2}
  {f_1}
  {f_2}
  {\lambda x . (f_1~x)~(f_2~())}
& (\emph{app-2})
\\[2em]
\hspace{-1.6em}\semdefff
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2}
  {\coctx{\Gamma}{\cclrd{s}} \vdash e_2 : \tau_1}
  {\coctx{\Gamma}{\cclrd{r} \;\cclrd{\sqcup}\; (\cclrd{s} \,\cclrd{\sqcap}\, \cclrd{t})} \vdash e_1~e_2 : \tau_2}
  {f_1}
  {f_2}
  {\lambda x . (f_1~x)~(f_2~x)}
& (\emph{app-3})
\end{array}
\end{equation*}

\figcaption{Semantics that implements dead code elimination for $\lambda$-calculus}
\label{fig:applications-flat-livsem}
\vspace{0.5em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Summary.}
Unlike with implicit parameters, lambda abstraction for liveness analysis does not introduce
non-determinism. It simply duplicates the context requirements. However, this still matches the
property of coeffects that impurities cannot be delayed or thunked and attached just to the
function arrow -- we place requirements on both call site and declaration site.

The semantics of liveness reveals three interesting properties. Firstly, the coeffect calculus for
liveness cannot be modelled as a monadic computation of the form $\tau_1 \rightarrow \mtyp{}{\tau_2}$.
Secondly, the system would not work without the coeffect annotations.
The shape of the semantic function depends on the annotation (the input is either $1$ or $\tau$) and
is \emph{indexed} by the annotation.

Finally, we discussed how the semantics of application arises from \emph{sequential} and
\emph{pointwise} composition. This is an important aspect of coeffect systems -- categorical
semantics typically builds on \emph{sequential} composition, but to model full $\lambda$ calculus
it needs more. For coeffects, we need \emph{pointwise} composition where the same context
is shared by multiple sub-expressions.

% --------------------------------------------------------------------------------------------------

\subsection{Dataflow languages}
\label{sec:applications-flat-dataflow}

We used implicit parameters as our first example, because they show the simplest form of coeffects.
Liveness requires a richer coeffect annotation structure, but the flat version is not practical.
In this section, we look at a system with a structure similar to liveness that is not a toy example.

The Section~\ref{sec:intro-why-array} briefly demonstrated that we can treat array access as an
operation that accesses a context. In case of arrays, the context is neighbourhood of a current
location in the array specified by a cursor. In this section, we make the example more concrete,
using a simpler and better studied programming model, dataflow languages.

Lucid \cite{app-lucid} is a declarative dataflow language designed by Wadge and Ashcroft. In Lucid,
variables represent streams and programs are written as transformations over streams. A function
application $\ident{square}(x)$ represents a stream of squares calculated from the stream of values $x$.

The dataflow approach has been successfully used in domains such as development of real-time embedded
application where many \emph{synchronous languages} \cite{app-synchronous-lang} build on the dataflow
paradigm. The following example is inspired by the Lustre \cite{app-synchronous-lustre} language
and implements a program to count the number of edges on a Boolean stream:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{edge} = \ident{false}~\kvd{fby}~(\ident{input}~\&\&~\ident{not}~(\kvd{prev}~\ident{input}))
\\[0.5em]
\kvd{let}~\ident{edgeCount} = \\[-0.25em]
\quad 0~\kvd{fby}~ (~\kvd{if}~\ident{edge}~\kvd{then}~1 + (\kvd{prev}~\ident{edgeCount})\\[-0.25em]
\quad\quad\quad~~~\, \kvd{else}~\kvd{prev}~\ident{edgeCount} ~)
\end{array}
\end{equation*}
%
The construct $\kvd{prev}~x$ returns a stream consisting of previous values of the stream
$x$. The second value of $\kvd{prev}~x$ is first value of $x$ (and the first
value is undefined). The construct $y~\kvd{fby}~x$ returns a stream whose first element is the
first element of $y$ and the remaining elements are values of $x$. Note that in Lucid, the constants
such as \ident{false} and $0$ are constant streams.

Formally, the constructs are defined as follows (writing $x_n$ for $n$-th element of a stream $x$):
%
\[
(\kvd{prev}~x)_n = \left\{
  \begin{array}{ll}
    \ident{nil}     & \; \text{if $n=0$}\\
    x_{n-1} & \; \text{if $n>0$}
  \end{array} \right.
\quad
(y~\kvd{fby}~x)_n = \left\{
  \begin{array}{ll}
    y_0     & \; \text{if $n=0$}\\
    x_n     & \; \text{if $n>0$}
  \end{array} \right.
\]
%
When reading dataflow programs, we do not need to think about variables in terms of streams --
we can see them as simple values. Most of the operations perform calculation just on the
\emph{current} value of the stream. However, the operation \kvd{fby} and \kvd{prev} are different.
They require additional \emph{context} which provides past values of variables
(for \kvd{prev}) and information about the current location in the stream (for \kvd{fby}).

The semantics of Lucid-like languages can be captured using a number of mathematical
structures. Wadge \cite{app-lucid-monads} originally defined a monadic semantics, while Uustalu
and Vene later used comonads \cite{app-dataflow-essence}. In Chapter~\ref{ch:flat}, we extend
the latter approach. The present chapter presents a sketch of a concrete dataflow semantics
defined directly on streams.

In the introductory example with array access patterns, we used coeffects to track the range
of values accessed. In this section, we look at a simpler example -- we only consider the
\kvd{prev} operation and track the maximal number of \emph{past values} needed. This is an
important information for efficient implementation of dataflow languages. When we can guarantee
that at most $x$ past values are accessed, the values can be stored in a pre-allocated buffer
rather than using \eg~on-demand computed lazy streams.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}
  {x : \tau \in \Gamma}
  {\coctx{\Gamma}{\cclrd{ 0 }} \vdash x : \tau }
\end{equation*}
\begin{equation*}
\tyrule{prev}
  {\coctx{\Gamma}{ \cclrd{n} } \vdash e : \tau}
  {\coctx{\Gamma}{ \cclrd{n}+1} \vdash \kvd{prev}~e : \tau}
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\cclrd{n'}} \vdash e : \tau }
  {\coctx{\Gamma}{\cclrd{n}} \vdash e : \tau }\quad\quad(\cclrd{n'} \leq \cclrd{n})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\cclrd{m}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{p}} \tau_2 &
   \coctx{\Gamma}{\cclrd{n}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\cclrd{\textnormal{max}}(\cclrd{m}, \cclrd{n+p})} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma}{\cclrd{m}} \vdash e_1 : \tau_1 &
    \coctx{\Gamma, x:\tau_1}{\cclrd{n}} \vdash e_2 : \tau_2}
  {\coctx{\Gamma}{\cclrd{n+m}} \vdash \kvd{let}~x=e_1~\kvd{in}~e_2 : \tau_2 }
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\cclrd{n}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\cclrd{n}} \vdash \lambda x.e : \tau_1 \xrightarrow{\cclrd{n}} \tau_2 }
\end{equation*}

\figcaption{Coeffect rules for tracking context-usage in dataflow language}
\label{fig:applications-flat-dataflow}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type system.}
We can use a coeffect type system to track the maximal number of accessed past values. Here,
the context is annotated with a single integer. The current value is always present, so $0$ means
that no past values are needed, but the current value is still available. The typing rules of
the system are shown in Figure~\ref{fig:applications-flat-dataflow}.

Variable access (\emph{var}) annotates the context with $0$; subcoeffecting (\emph{sub}) allows
us to require more values than is actually needed. Primitive context-requirements are introduced
in (\emph{prev}), which increments the number of past values by one. Thus, for example,
$\kvd{prev}~(\kvd{prev}~x)$ requires 2 past values.

The (\emph{app}) rule follows the same intuition as for liveness. It combines \emph{sequential}
and \emph{pointwise} composition of semantic functions. In case of dataflow, the operations
combine annotations using $+$ and \emph{max} operations:
%
\begin{equation*}
\begin{array}{lll}
f : \tau_1 \xrightarrow{\cclrd{m}} \tau_2 \qquad\qquad&
g : \tau_2 \xrightarrow{\cclrd{n}} \tau_3 \qquad\qquad&
g \circ f : \tau_1 \xrightarrow{\cclrd{m+n}} \tau_3 \qquad\qquad
\\
f : \tau_1 \xrightarrow{\cclrd{m}} \tau_2 \qquad\qquad&
h : \tau_1 \xrightarrow{\cclrd{n}} \tau_3 \qquad\qquad&
\langle f, h \rangle : \tau_1 \xrightarrow{\cclrd{\textnormal{max}}(\cclrd{m}, \cclrd{s})} (\tau_2 \times \tau_3) \qquad
\end{array}
\end{equation*}
%
Sequential composition adds the annotations. The function $f$ needs $\cclrd{m}$ past values to
produce a single $\tau_2$ value. To produce two $\tau_2$ values, we thus need $\cclrd{m}+1$ past
values of $\tau_1$; to produce three $\tau_2$ values, we need $\cclrd{m}+2$ past values of $\tau_1$,
and so on. To produce $\ident{n}$ past values that are required as the input of $g$, we need
$\cclrd{m+n}$ past values of type $\tau_1$. The pointwise composition is simpler. It uses
the same stream to evaluate functions requiring $\cclrd{m}$ and $\cclrd{n}$ past values, and so it
needs maximum of the two at most.

In summary, function application (\emph{app}) requires maximum of the values needed to evaluate
$e_1$ and the number of values needed to evaluate the argument $e_2$, sequentially composed with
the function.

In function abstraction (\emph{abs}), the requirements of the body are duplicated on the declaration site
and the call site as in liveness analysis. If the body requires $\cclrd{n}$ past values, it may access
$\cclrd{n}$ values of any variables -- including those available in $\Gamma$, as well as the parameter
$x$. Finally, the (\emph{let}) rule simply adds the two requirements. This corresponds to the sequential
composition operation, but it is also a rule that we obtain by treating let-binding as a syntactic
sugar for $(\lambda x.e_2)~e_1$.

% --------------------------------------------------------------------------------------------------

\paragraph{Example.}
As with the liveness example, the application rule might require more explanation. The following
example is somewhat arbitrary, but it demonstrates the rule well. We assume that \ident{counter}
is a stream of positive integers (starting from zero) and \ident{tick} flips between $0$ and $1$.
The full typing derivation is shown in Appendix~\ref{sec:appendixa-dataflow}:
%
\begin{equation*}
\begin{array}{l}
(\,   \kvd{if}~~(\kvd{prev}~\ident{tick})=0\\[-0.25em]
\,\,\, \kvd{then}~(\lambda x \rightarrow \kvd{prev}~x)\\[-0.25em]
\,\,\, \kvd{else}~(\lambda x \rightarrow x) \,)\quad(\kvd{prev}~\ident{counter})
\end{array}
\end{equation*}
%
The left-hand side of the application returns a function depending on the \emph{previous}
value of \ident{tick}. The resulting stream of functions flips between a function returning
a current value and a function returning the previous value. If the current \ident{tick} is 0, and
the function is applied to a stream $\langle{\ldots,4,3,2,1}\rangle$
(where $1$ is the current value), it yields the stream $\langle{\ldots,4,4,2,2}\rangle$.

To obtain the function, we need one past value from the context (for $\kvd{prev}~\ident{tick}$). The
returned function needs either none or one past value (thus a subtyping rule is required to type
it as requiring one past value). So, the annotations for (\emph{app}) are $\cclrd{m}=1, \cclrd{p}=1$.
The function is called with $\kvd{prev}~\ident{counter}$ as an argument, meaning that the result
is either the first or second past element. Given
$\ident{counter}\hspace{-0.1em}=\hspace{-0.1em}\langle{\ldots,5,4,3,2,1}\rangle$, the argument
is $\langle{\ldots,5,4,3,2}\rangle$ and so the overall result is a stream $\langle{\ldots,5,5,3,3}\rangle$.
From the argument, we get the requirement $\cclrd{n}=1$.

Using the (\emph{app}) rule, we get that the overall number of past elements needed is
$\mathit{max}(1, 1+1) = 2$. This should match the intuition about the code -- when the first function
is applied to the argument, the computation will first access $\kvd{prev}~\ident{tick}$ (using one
past value) and then $\kvd{prev}~(\kvd{prev}~\ident{counter}))$ (using two past values).


\paragraph{Semantics.}
The language discussed in this section is a \emph{causal} dataflow language. This means that
a computation can access \emph{past} values of the stream (but not future values). In the semantics,
we again need richer structure over the input.

Uustalu and Vene \cite{comonads-notions} model causal dataflow computations using a non-empty list
$\ident{NeList}~\tau = \tau \times (\ident{NeList}~\tau + 1)$ over the input. A function $\tau_1 \rightarrow \tau_2$
is thus modelled as $\ident{NeList}~\tau_1 \rightarrow \tau_2$. This model is difficult to implement
efficiently, as it creates unbounded lists of past elements.

The coeffect system tracks maximal number of past values and so we can define the semantics using
a list of fixed length. As with liveness, this is a data structure \emph{indexed} by the coeffect
annotation. We write $\tau^{\cclrd{n}}$ for a list containing $\cclrd{n}$ elements, which can be
also viewed as an $\cclrd{n}$-element product $\tau \times \ldots \times \tau$.

As with the previous examples, our semantics interprets a judgement using a (semantic) function;
functions in the language are modelled as functions taking a list of inputs:
%
\begin{equation*}
\begin{array}{rcl}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \cclrd{n} } \vdash e : \tau}
  &:& (\tau_1 \times \ldots \times \tau_n)^{\cclrd{n}+1} \rightarrow \tau\\
\sem{\tau_1 \xrightarrow{\cclrd{n}} \tau_2} &:& \tau_1^{\cclrd{n}+1} \rightarrow \tau_2
\end{array}
\end{equation*}
%
Note that the semantics requires one more value than is the number of past values. This is because
the first value is the current value and has to be always available, even when the annotation is
zero as in (\emph{var}).


%---------------------------------------------------------------------------------------------------

\begin{figure}[t]

\begin{equation*}
\begin{array}{ll}
\hspace{3em}\semdef
  {\coctx{\Gamma}{\cclrd{0}} \vdash x_i : \tau_i}
  {\lambda \langle(x_1, \ldots, x_n)\rangle . x_i}
& (\emph{var})
\\[1.5em]
\hspace{-0.75em}\emdeff
  {\coctx{\Gamma}{\cclrd{n}} \vdash e : \tau}
  {\begin{array}{l}\sem{\coctx{\Gamma}{\cclrd{n}+1} \vdash \kvd{prev}~e : \tau}\\[-0.25em]~\end{array}\hspace{-0.5em}~}
  {f}
  {\hspace{-0.5em}\begin{array}{l}\lambda \langle \mathbf{v}_0, \ldots, \mathbf{v}_{\cclrd{n}+1} \rangle .\\[-0.25em]
    \qquad f~\langle \mathbf{v}_1, \ldots, \mathbf{v}_{ \cclrd{n}+1 }\rangle\end{array}\hspace{-1em}~}
& (\emph{prev})
\\[1.5em]
\hspace{3.25em}\emdeff
  {\coctx{\Gamma}{\cclrd{n'}} \vdash e : \tau}
  {\begin{array}{l}\sem{\coctx{\Gamma}{\cclrd{n}} \vdash e : \tau}\\[-0.25em]~\end{array}\hspace{-0.5em}~}
  {f}
  {\hspace{-0.5em}\begin{array}{l}\lambda \langle \mathbf{v}_0, \ldots, \mathbf{v}_{\cclrd{n}} \rangle .\\[-0.25em]
    \qquad f~\langle \mathbf{v}_0, \ldots, \mathbf{v}_{ \cclrd{n'} }\rangle\end{array}\hspace{-1em}~}
& (\emph{sub})
\\[1.5em]
\hspace{-1.5em}\emdeff
  {\coctx{\Gamma,y:\tau_1}{\cclrd{n}} \vdash e : \tau_2}
  {\begin{array}{l}\sem{\coctx{\Gamma}{\cclrd{n}} \vdash \lambda y. e : \tau_1 \xrightarrow{\cclrd{n}} \tau_2}\\[-0.25em]~\end{array}\hspace{-0.5em}~}
  {f}
  {\hspace{-0.5em}\begin{array}{l}
  \lambda \langle \mathbf{v}_0, \ldots \mathbf{v}_{\cclrd{n}} \rangle . \lambda \langle y_0, \ldots, y_{\cclrd{n}}\rangle .\\[-0.25em]
  \quad f~\langle (\mathbf{v}_0, y_0), \ldots, (\mathbf{v}_{ \cclrd{n}  }, y_{ \cclrd{n} } ) \rangle
  \end{array}\hspace{-1em}~}
& (\emph{abs})
\\[1.5em]
\hspace{0.25em}\emdefff
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2}
  {\coctx{\Gamma}{\cclrd{s}} \vdash e_2 : \tau_1}
  {\begin{array}{l}\coctx{\Gamma}{\cclrd{\textnormal{max}}(\cclrd{m}, \cclrd{n+p})} \\[-0.25em]\qquad \vdash e_1~e_2 : \tau_2\\[-0.25em]~\\[-0.25em]~\end{array}}
  {f_1}
  {f_2}
  {\hspace{-0.5em}\begin{array}{l}
  \lambda \langle\mathbf{v}_0, \ldots, \mathbf{v}_{ \textnormal{max}(\cclrd{m}, \cclrd{n}+\cclrd{p})} \rangle . \\[-0.1em]
  \quad (f_1~\langle\mathbf{v}_0, \ldots, \mathbf{v}_{ \cclrd{m} }\rangle)\\[-0.1em]
  ~~\qquad\langle\; f_2~\langle\mathbf{v}_0, \ldots, \mathbf{v}_{ \cclrd{n} }\rangle,\ldots,\\[-0.25em]
  ~~\qquad~\;\, f_2~\langle\mathbf{v}_{ \cclrd{p} }, \ldots, \mathbf{v}_{ \cclrd{n}+\cclrd{p} }\rangle~\rangle
  \end{array}\hspace{-0.5em}~}
& (\emph{app})
\\[1.5em]
\end{array}
\end{equation*}

\figcaption{Semantics showing how past values are accessed in a dataflow language}
\label{fig:applications-flat-dfsem}
\end{figure}

%---------------------------------------------------------------------------------------------------

The rules defining the semantics are shown in Figure~\ref{fig:applications-flat-dfsem}. The
semantics of the context is a \emph{list of products}. To make the rules easier to follow, we write
$\langle \mathbf{v}_1, \ldots, \mathbf{v}_n \rangle$ for an $n$-element list containing products.
Products that model the entire context such as $\mathbf{v}_1$ are written in bold. When we access
individual variables, we write $\mathbf{v} = (x_1, \ldots, x_m)$ where $x_i$ denote individual
variables of the context.

In (\emph{var}), the context is a singleton-list containing a product of variables, from which
we project the right one. In (\emph{prev}) and (\emph{sub}), we drop some of the elements from
the history (from the front and end, respectively) and then evaluate the original expression.

Lambda abstractions (\emph{abs}) receives two lists of the same size -- one containing values of
the variables (list of products) from the declaration site $\langle \mathbf{v}_0, \ldots, \mathbf{v}_{\cclrd{n}} \rangle$
and one containing the argument (list of values) provided by the call site $\langle y_0, \ldots, y_{\cclrd{n}} \rangle$.
The semantics applies the well-known \emph{zip} operation on the lists and passes the result to the
body.

Finally, application (\emph{app}) uses the input context in two ways, which gives rise to the
two requirements combined using \emph{max}. First, it evaluates the expression $e_1$ which is
called with the past $\cclrd{m}$ values. The resulting function $g$ is then sequentially composed
with the semantics of $e_2$. To call the function, we need to evaluate $e_2$ repeatedly -- namely,
$\cclrd{p}+1$ times, which results in the overall requirement for $\cclrd{n}+\cclrd{p}$ past values.

\paragraph{Summary.}
Type systems have been used in the context of dataflow languages, for example to check
initialization properties \cite{app-dataflow-init}, but to our knowledge, not for checking
the maximal number of required past values. Thus this section serves not just as an example,
but also shows how coeffects can lead to novel results.

The most interesting point about the dataflow system is that it is remarkably similar to our
earlier liveness example. In the type system, abstraction (\emph{abs}) duplicates the context
requirements and application (\emph{abs}) arises from sequential and pointwise composition.
We capture this striking similarity in Chapter~\ref{ch:flat}. Before doing that, we look at one
more example and then explore the \emph{structural} class of systems.

% --------------------------------------------------------------------------------------------------

\subsection{Permissions and safe locking}
In the implicit parameters and dataflow examples, the context provides additional resources or
values that may be accessed at runtime. However, coeffects can also track \emph{permissions} or
\emph{capabilities} to perform some operation. We can invert the intuition behind liveness and
use it as a trivial example. When the context is live, it contains a \emph{permission} to access
variables. In this section, we briefly consider a system for safe locking of Flanagan and
Abadi~\cite{app-safe-locking} as one, more advanced example. Calculus of capabilities of
Cray et al.~\cite{app-capabilities} is discussed later in Section~\ref{sec:applications-active-ccc}.

\paragraph{Safe locking.}
The system for safe locking prevents race conditions (by only allowing access to mutable state
under a lock) and avoids deadlocks (by imposing strict partial order on locks). The following
program uses a mutable state under a lock:
%
\begin{equation*}
\begin{array}{l}
\kvd{newlock}~l:\rho~\kvd{in}\\[-0.25em]
\kvd{let}~\ident{state}~=~\ident{ref}_\rho~10~\kvd{in}\\[-0.25em]
\kvd{sync}~l~(!\ident{state})
\end{array}
\end{equation*}
%
The declaration \kvd{newlock} creates a lock $l$ protecting memory region $\rho$. We can than
allocate mutable variables in that memory region (second line). An access to one or more mutable
variables is only allowed in scope that is protected by a lock. This is done using the \kvd{sync} keyword,
which locks a lock and evaluates an expression in a context that contains permission to access
memory region of the lock ($\rho$ in the above example).

The type system for safe locking associates a list of acquired locks with the context.
Interestingly, the original presentation of the system by Flanagan and Abadi \cite{app-safe-locking}
uses a coeffect-style judgements of a form $\Gamma; p \vdash e : \tau$ where $p$ is a list of
accessible regions (protected by an acquired lock). Using our notation, the rule for \kvd{sync}
looks as follows:

\noindent
\vspace{-0.5em}
\begin{equation*}
\tyrule{sync}
  { \coctx{\Gamma}{\cclrd{p}} \vdash e_1 : m&
    \coctx{\Gamma}{\cclrd{p} \cup \{m\} } \vdash e_2 : \tau }
  { \coctx{\Gamma}{\cclrd{p}} \vdash \kvd{sync}~e_1~e_2 : \tau }
\end{equation*}
\vspace{-0.5em}

\noindent
The rule requires that $e_1$ yields a value of a singleton type $m$. The type is added as an
indicator of the locked region to the context $\cclrd{p}\cup \{m\}$ which is then used to evaluate
the expression $e_2$.

\paragraph{Summary.}
Despite attaching annotations to the variable context, the system for safe locking uses
effect-style lambda abstraction. Lambda abstraction associates all requirements with the
call site -- a lambda function created under a lock cannot access protected memory available at
the time of creation. It will be executed later and can only access the memory available then.
This suggests that safe locking is better seen as an effect system.

Another interesting aspect is the extension to avoid deadlocks. In that case, the type system
needs to reject programs that acquire locks in an invalid order. One way to model this is to
replace $\cclrd{p} \cup \{m\}$ with a \emph{partial} operation $\cclrd{p} \uplus \{m\}$ which
is only defined when the lock $m$ can be added to the set $\cclrd{p}$. Supporting partial
operations on coeffect annotations is an interesting future extension for coeffect systems.



% ==================================================================================================
%
% 	  ###    #                           #                           ##
% 	 #   #   #                           #                            #
% 	 #      ####   # ##   #   #   ###   ####   #   #  # ##    ###     #
% 	  ###    #     ##  #  #   #  #   #   #     #   #  ##  #      #    #
% 	     #   #     #      #   #  #       #     #   #  #       ####    #
% 	 #   #   #  #  #      #  ##  #   #   #  #  #  ##  #      #   #    #
% 	  ###     ##   #       ## #   ###     ##    ## #  #       ####   ###
%
% ==================================================================================================

\section{Structural coeffect systems}
\label{sec:applications-structural}

In structural coeffect systems, the additional information is associated with individual variables.
This is very often information about how the variables are used, or, in which contexts they are used.
In Chapter~\ref{ch:intro}, we introduced the idea using an example that tracks array access patterns.
Each variable is annotated with a range specifying which elements of the corresponding array
may be accessed.

In this section, we look at three examples in detail -- we revisit liveness and show a practically
useful structural version of the system; we consider an example inspired by linear logic; finally,
we revisit dataflow to get a more precise analysis. Although quite different, the common pattern
among these three examples is somewhat easier to see, because they all track information about
variable usage. We finish the section with a brief outline of several other applications.

%---------------------------------------------------------------------------------------------------

\subsection{Liveness analysis revisited}
\label{sec:applications-struct-live}

The flat system for liveness analysis presented in Section~\ref{sec:applications-flat-live} is
interesting from a theoretical perspective, but it is not practically useful. Here, we
revisit the problem and define a structural system that tracks liveness per-variable.

\paragraph{Structural liveness.}
Recall two examples discussed earlier where the flat liveness analysis marked the whole context
as (syntactically) live, despite the fact part of it was (semantically) dead:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{constant} = \lambda y \rightarrow \lambda x \rightarrow y\\[-0.25em]
\kvd{let}~\ident{answer} = (\lambda x \rightarrow x)~42
\end{array}
\end{equation*}
%
In the first case, the variable $x$ is dead, but was marked as live. In the second example, the
declaration site of the \ident{answer} value is dead, but was marked as live. This is because in
both of the expressions, \emph{some} variable is accessed. However, the (\emph{abs}) rule of flat
liveness has no way of determining \emph{which} variables are used by the body -- and, in particular,
whether the accessed variable is the \emph{bound} variable or some of the \emph{free} variables.

As discussed earlier, we can resolve this by attaching a \emph{vector} of liveness annotations to
a \emph{vector} of variables. In the first example, the available variables are $y$ and $x$, so
the variable context $\Gamma$ is a vector $\langle y\!:\!\tau, x\!:\!\tau \rangle$. Only the variable $y$
is used and so the annotated context is: $\coctx{y\!:\!\tau, x\!:\!\tau}{ \alift{\cclrd{\cclrd{\ident{L}}}, \cclrd{\cclrd{\ident{D}}}} }$.
When writing the contexts, we omit angle brackets around variables, but it should still be viewed
as a vector. There are two important points:

\begin{itemize}
\item The fact that variables are now a vector means that we cannot freely re-order them. This
  guarantees that $\coctx{x\!:\!\tau, y\!:\!\tau}{\alift{\cclrd{\cclrd{\ident{L}}}, \cclrd{\cclrd{\ident{D}}}}}$
  can not be confused with $\coctx{y\!:\!\tau, x\!:\!\tau}{\alift{\cclrd{\cclrd{\ident{L}}}, \cclrd{\cclrd{\ident{D}}}}}$.
  We need to define the type system in a way that is similar to substructural systems
  (discussed in Section~\ref{sec:path-logic}) and add explicit rules for manipulating
  the context.

\item We choose to attach a vector of annotations to a vector of variables, rather than attaching
  individual annotations to individual variables. This lets us unify and combine flat and
  structural systems as discussed in Section~\ref{sec:further-unified}, but the alternative is briefly
  explored in Section~\ref{sec:further-meta}.
\end{itemize}

\paragraph{Type system.}
The structural system for liveness uses the same two-point lattice of annotations
$\mathcal{L}=\{ \cclrd{\cclrd{\ident{L}}}, \cclrd{\cclrd{\ident{D}}} \}$ that was used by the flat system. We also use the
$\cclrd{\sqcup}, \cclrd{\sqcap}$ and $\cclrd{\sqsubseteq}$ operators that are defined in Figure~\ref{fig:applications-flat-livealg}.

The rules of the system are split into two groups. Figure~\ref{fig:applications-struct-live} (a) shows
the standard syntax-driven rules plus subcoeffecting. In (\emph{var}), the context contains just the
single accessed variable, which is annotated as live. Unused variables can be introduced using weakening.
A constant (\emph{const}) is accessed in an empty context, which also carries no annotations. The
subcoeffecting rule (\emph{sub}) uses a pointwise extension of the $\cclrd{\sqsubseteq}$ relation over two
vectors as defined in Section~\ref{sec:applications-strucutre-vec}.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
a.) Ordinary, syntax-driven rules along with subcoeffecting

\begin{equation*}
\tyrule{var}{}
  {\coctx{x \!:\! \tau}{\alift{\cclrd{\ident L}}} \vdash x : \tau}
\end{equation*}
\begin{equation*}
\tyrule{const}
  {c:\tau \in \Delta}
  {\coctx{()}{\alift{}} \vdash c : \tau}
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x \!:\! \tau_1}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s}}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{\textbf{r}}} \vdash \lambda x . e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{app}
  { \coctx{\Gamma_1}{\aclrd{\textbf{r}}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2 \quad
    \coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}
  { \coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \cons (\cclrd{t} \;\cclrd{\sqcup}\; \aclrd{\textbf{s}})} \vdash e_1 \, e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma_1, x \!:\! \tau_1}{\aclrd{\textbf{r}} \times \langle{\cclrd{t}}\rangle} \vdash e_1 : \tau_2 \quad
    \coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}
  {\coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \times (\cclrd{t} \;\cclrd{\sqcup}\; \aclrd{\textbf{s}})} \vdash \kvd{let}~x=e_2~\kvd{in}~e_1 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{\textbf{r}}} \vdash e : \tau}
  {\coctx{\Gamma}{\aclrd{\textbf{r'}}} \vdash e : \tau}~\aclrd{\textbf{r}} \;\cclrd{\sqsubseteq}\; \aclrd{\textbf{r'}}
\end{equation*}
\vspace{1em}

b.) Structural rules for context manipulation

\begin{equation*}
\tyrule{weak}
  {\coctx{\Gamma}{ \aclrd{\textbf{r}} } \vdash e : \sigma}
  {\coctx{\Gamma,x \!:\! \tau}{\aclrd{\textbf{r}} \cons \alift{ \cclrd{\cclrd{\ident{D}}} }} \vdash e : \sigma}
\end{equation*}
\begin{equation*}
\tyrule{exch}
  {\coctx{\Gamma_1,x\!:\!\tau',y\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons\alift{\cclrd{s},\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
  {\coctx{\Gamma_1,y\!:\!\tau,x\!:\!\tau',\Gamma_2}{\aclrd{\textbf{r}} \cons\alift{\cclrd{t},\cclrd{s}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
\quad
\begin{array}{l}
\slen{\Gamma_1} = \slen{\aclrd{\textbf{r}}}\\[-0.25em]
\slen{\Gamma_2} = \slen{\aclrd{\textbf{s}}}
\end{array}
\end{equation*}
\begin{equation*}
\tyrule{contr}
  {\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s},\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
  {\coctx{\Gamma_1,x\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s}\cclrd{\sqcap}\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash \subst{\subst{e}{z}{x}}{y}{x} : \sigma}
~
\begin{array}{l}
\slen{\Gamma_1} = \slen{\aclrd{\textbf{r}}}\\[-0.25em]
\slen{\Gamma_2} = \slen{\aclrd{\textbf{s}}}
\end{array}
\end{equation*}

\figcaption{Structural coeffect liveness analysis}
\label{fig:applications-struct-live}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

In the (\emph{abs}) rule, the variable context of the body $\Gamma, x\!:\!\tau_1$ is annotated with
a vector $\mathbf{\aclrd{r}}\cons\alift{\cclrd{s}}$, where the vector $\mathbf{\aclrd{r}}$ corresponds
to $\Gamma$ and the singleton annotation $\cclrd{s}$ corresponds to the variable $x$. Thus, the
function is annotated with $\cclrd{s}$. Note that the free-variable context is annotated with vectors,
but functions take only a single input and so are annotated with primitive annotations.

The (\emph{app}) rule is similar to function applications in flat systems, but there is an important
difference. In structural systems, the two sub-expressions have separate variable contexts
$\Gamma_1$ and $\Gamma_2$. Therefore, the composed expression just concatenates the variables
and their corresponding annotations. (We can still use the same variable in both sub-expressions
thanks to the structural contraction rule.)

The context $\Gamma_1$ is used to evaluate $e_1$ and is thus annotated with $\aclrd{\mathbf{r}}$.
The annotation for $\Gamma_2$ is more interesting. It is a result of sequential composition of two
semantic functions -- the first one takes the (multi-variable) context $\Gamma_2$ and evaluates
$e_2$; the second takes the result of type $\tau_1$ and passes it to the function $\tau_1 \xrightarrow{\cclrd{t}} \tau_2$.
The composition is defined as follows:
%
\begin{equation*}
g : \tau_1 \times \ldots \times \tau_n \xrightarrow{\aclrd{\mathbf{s}}} \sigma
\qquad
f : \sigma \xrightarrow{\cclrd{t}} \tau
\qquad
f \circ g : \tau_1 \times \ldots \times \tau_n \xrightarrow{\cclrd{t} \,\cclrd{\sqcup}\, \aclrd{\mathbf{s}}} \tau
\end{equation*}
%
This definition is only for illustration and is revised in Chapter~\ref{ch:structural}. The function
$g$ takes a product of multiple variables (and is annotated with a vector). The function $f$ takes
just a single value and is annotated with the scalar. As in the flat system, sequential composition
is modelled using $\cclrd{\sqcup}$, but here we use a scalar-vector extension of the operation. Finally,
the (\emph{let}) rule follows similar reasoning (and also corresponds to the typing of $(\lambda x.e_2)~e_1$).

\paragraph{Structural typing rules.}
The structural typing rules are shown in Figure~\ref{fig:applications-struct-live} (b). They mirror
the rules know from substructural type systems (Section~\ref{sec:path-logic}). Weakening (\emph{weak})
extends the context with a single unused variable $x$ and adds the $\cclrd{\ident{D}}$ annotation to the
vector of coeffects.

The variable is always added to the end as in the (\emph{abs}) rule. However, the exchange rule
(\emph{exch}) lets us arbitrarily reorder variables. It flips the variables $x$ and $x'$ and their
corresponding coeffect annotations in the vector. This is done by requiring that the lengths of the
remaining, unchanged, parts of the vectors match.

Finally, contraction (\emph{contr}) makes it possible to use a single variable multiple times.
Given a judgement that contains variables $y$ and $z$, we can derive a judgement for an expression
where both $z$ and $y$ are replaced by a single variable $x$. Their annotations $\cclrd{s}, \cclrd{t}$
are combined into $\cclrd{s} \;\cclrd{\sqcap}\; \cclrd{t}$, which means that $x$ is live if either $z$ or $y$
were live in the original expression.

\paragraph{Example.} To demonstrate how the system works, we consider the expression
$(\lambda x . v)~y$. This is similar to an example where flat liveness mistakenly marks
the entire context as live. Despite the fact that the variable $y$ is accessed (syntactically), it
is not live -- because the function that takes it as an argument always returns $v$.

The typing derivation for the body uses (\emph{var}) and (\emph{abs}). However, we also need (\emph{weak})
to add the unused variable $x$ to the context:
%
\begin{equation*}
\tyrule{weak}
{ \tyruler{var}
    {}
    { \coctx{v\!:\!\tau}{\alift{ \cclrd{\cclrd{\ident{L}}} }} \vdash v : \tau } }
{ \tyruler{abs}
    { \coctx{v\!:\!\tau, x\!:\!\tau}{\alift{ \cclrd{\cclrd{\ident{L}}},\cclrd{\cclrd{\ident{D}}} }} \vdash v : \tau }
    { \coctx{v\!:\!\tau}{\alift{ \cclrd{\cclrd{\ident{L}}} }} \vdash (\lambda x . v) : \tau \xrightarrow{\cclrd{\cclrd{\ident{D}}}} \tau }}
\end{equation*}
%
The interesting part is the use of the (\emph{app}) rule in the next step. Although the variable $y$ is live in the expression $y$,
it is marked as dead in the overall expression, because the function is annotated with $\ident{\cclrd{D}}$:
%
\begin{equation*}
\hspace{-2em}
\tyrule{app}
  {
    \begin{array}{l}
    \vspace{-1.2em}
    \coctx{v\!:\!\tau}{\alift{ \cclrd{\cclrd{\ident{L}}} }} \vdash (\lambda x . v) : \tau \xrightarrow{\cclrd{\cclrd{\ident{D}}}} \tau
    \end{array} &
    \tyruler{var}{}{\coctx{y\!:\!\tau}{\alift{ \cclrd{\cclrd{\ident{L}}} }} \vdash y : \tau}
  }
  {
  \inference
  	{ \coctx{v\!:\!\tau, y\!:\!\tau}{\alift{ \cclrd{\cclrd{\ident{L}}} } \cons\, ({ \cclrd{\cclrd{\ident{D}}} \,\cclrd{\sqcup}\, \alift{\cclrd{\cclrd{\ident{L}}}} })}
  	     \vdash (\lambda x . v)~y : \tau }
  	{ \coctx{v\!:\!\tau, y\!:\!\tau}{\alift{ \cclrd{\cclrd{\ident{L}}}, \cclrd{\cclrd{\ident{D}}} }} \vdash (\lambda x . v)~y : \tau }
  }
\end{equation*}
%
The application is written in two steps -- the first one directly applies the (\emph{app}) rule
and the second one simplifies the coeffect annotation. The key part is the use of the scalar-vector
operator $\cclrd{\cclrd{\ident{D}}} \;\cclrd{\sqcup}\; \alift{\cclrd{\cclrd{\ident{L}}}}$. Using the definition of the scalar-vector
extension, this equals $\alift{\cclrd{\cclrd{\ident{D}}} \;\cclrd{\sqcup}\; \cclrd{\cclrd{\ident{L}}}}$ which is
$\alift{\cclrd{\cclrd{\ident{D}}}}$.

% --------------------------------------------------------------------------------------------------

\paragraph{Semantics.}
When defining the semantics of flat liveness calculus, we used an indexed form of the option type
$1 + \tau$ (which is $1$ for dead contexts and $\tau$ for live contexts). In the semantics of
expressions, the type constructor was applied to the entire context, \ie~$1+(\tau_1 \times \ldots \times \tau_n)$.
In the structural version, the semantics applies the option type constructor to individual elements
of the free-variable context pair: $(1+\tau_1) \times \ldots \times (1+ \tau_n)$. For each variable,
the type is indexed by the corresponding annotation:

\begin{equation*}
\begin{array}{r}
\\[-0.5em]
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \alift{\cclrd{r_1}, \ldots, \cclrd{r_n}} } \vdash e : \tau}
  ~:~ (\tau'_1 \times \ldots \times \tau'_n) \rightarrow \tau\\[0.5em]
\textnormal{where}~\tau'_i = \begin{cases}
\tau_i & (\cclrd{r_i} = \cclrd{\cclrd{\ident{L}}})\\
1      & (\cclrd{r_i} = \cclrd{\cclrd{\ident{D}}})
\end{cases}
\end{array}
\end{equation*}
\vspace{0.5em}

\noindent
Note that the product of the free variables is not an ordinary tuple of our language, but a special
construction (we return to this topic in Section~\ref{sec:struct-semantics}). This follows from the
asymmetry of $\lambda$-calculus, as discussed in Section~\ref{sec:applications-strucutre-vec}. Functions
take just a single input and so they are interpreted in the same way as in flat calculus:

\vspace{-0.5em}
\begin{equation*}
\sem{\tau_1 \xrightarrow{\aclrd{\cclrd{\ident{L}}}} \tau_2} = \tau_1 \rightarrow \tau_2 \qquad\qquad
\sem{\tau_1 \xrightarrow{\aclrd{\cclrd{\ident{D}}}} \tau_2} = 1 \rightarrow \tau_2
\end{equation*}
\vspace{-0.5em}

\noindent
The rules that define the semantics are shown in Figure~\ref{fig:applications-struct-livesem}.
To make the definition simpler, we are somewhat vague when working with products. We write
variables of product type such as $\mathbf{v}$ in bold-face and individual values like $x$ in
normal face. We freely re-associate products and so $(\mathbf{v}, x)$ should not be seen as a
nested product, but simply as a product containing all variables from the product $\mathbf{v}$
together with one additional variable $x$ at the end. We shall be more precise in
Chapter~\ref{ch:structural}.

In (\emph{var}), the context contains just a single variable and so we do not even need to apply
projection; (\emph{cosnt}) receives no variables and uses global constant lookup function $\delta$.
In (\emph{abs}), we obtain two parts of the context and combine them into $(\mathbf{v}, x)$. This
works the same way regardless of whether the variables are live or dead. For simplicity, we omit
subcoeffecting, which just turns some of the available values $v_i$ to unit values $()$.

As dictated by the semantics, the application again needs to ``implement'' dead code elimination
(otherwise the type system would be unsound). When the input parameter of the function $f_1$ is live
(\emph{app-1}), we first evaluate $e_2$ and then pass the result to $f_1$. When the parameter is
dead (\emph{app-2}), we do not need to evaluate $e_2$ and so all values in $\mathbf{v_2}$ can be
dead, \ie~$()$.

In the structural rules, (\emph{weak}) receives context containing a dead variable as the last one.
It drops the $()$ value and evaluates the expression in a context $\mathbf{v}$. Exchange (\emph{exch})
simply swaps two variables. In contraction, we duplicate the value (no matter whether it is dead
or live) and we use an auxiliary definition $\restr{x}{\cclrd{r}}$ to replace a live value with
$()$ when only one of the contracted variables is live.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
a.) Semantics of ordinary expressions
\begin{equation*}
\hspace{-1em}
\begin{array}{ll}
\\[-2.5em]
\hspace{4.75em}\semdef
  {\coctx{x \!:\! \tau}{\alift{\cclrd{\ident L}}} \vdash x : \tau}
  {\lambda (x). x}
& (\emph{var})
\\[-0.5em]
\hspace{4.5em}\semdef
  {\coctx{()}{\alift{}} \vdash n : \ident{num}}
  {\lambda (). n}
& (\emph{num})
\\[1.5em]
\hspace{1.75em}\semdeff
  {\coctx{\Gamma, y \!:\! \tau_1}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s}}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{\textbf{r}}} \vdash \lambda y . e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2}
  {f}
  {\lambda \textbf{v} . \lambda y . f~(\textbf{v}, y)}
& (\emph{abs})
\\[1.5em]
\hspace{-0.75em}\semdefff
  {\coctx{\Gamma_1}{\aclrd{\textbf{r}}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{\cclrd{\ident{L}}}} \tau_2}
  {\coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}
  {\coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \cons (\cclrd{\cclrd{\ident{L}}} \,\cclrd{\sqcup}\, \aclrd{\textbf{s}})} \vdash e_1 \, e_2 : \tau_2}
  {f_1}
  {f_2}
  {\lambda (\mathbf{v_1}, \mathbf{v_2}) . (f_1\;\mathbf{v_1})~(f_2\;\mathbf{v_2})}
& (\emph{app-1})
\\[2.5em]
\hspace{-0.75em}\semdefff
  {\coctx{\Gamma_1}{\aclrd{\textbf{r}}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{\cclrd{\ident{D}}}} \tau_2}
  {\coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}
  {\coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \cons (\cclrd{\cclrd{\ident{D}}} \,\cclrd{\sqcup}\, \aclrd{\textbf{s}})} \vdash e_1 \, e_2 : \tau_2}
  {f_1}
  {\_}
  {\lambda (\mathbf{v_1}, \mathbf{v_2}) . (f_1~\mathbf{v_1})~()}
& (\emph{app-2})
\end{array}
\end{equation*}
\vspace{1em}

b.) Semantics of structural context manipulation\\
Using the auxiliary definition $\restr{x}{\cclrd{\ident{L}}} = x$ and $\restr{x}{\cclrd{\ident{D}}} = ()$:

\begin{equation*}
\begin{array}{ll}
\hspace{2em}\semdeff
  {\coctx{\Gamma}{ \aclrd{\textbf{r}} } \vdash e : \sigma}
  {\coctx{\Gamma,x \!:\! \tau}{\aclrd{\textbf{r}} \cons \alift{ \cclrd{\cclrd{\ident{D}}} }} \vdash e : \sigma}
  {f}
  {\lambda(\textbf{v}, ()) . f~\textbf{v} }
& (\emph{weak})
\\[1.5em]
\hspace{0em}\mdeff
  {\begin{array}{l}\sem{\coctx{\Gamma_1,x\!:\!\tau_1,y\!:\!\tau_2,\Gamma_2\\[-0.25em]\qquad}
     {\aclrd{\textbf{r}} \atimes \alift{\cclrd{s},\cclrd{t}} \atimes \aclrd{\textbf{q}}} \vdash e : \tau}\end{array}}
  {\begin{array}{l}\sem{\coctx{\Gamma_1,y\!:\!\tau_2,x\!:\!\tau_1,\Gamma_2\\[-0.25em]\qquad}{\aclrd{\textbf{r}}
          \atimes \alift{\cclrd{t},\cclrd{s}} \atimes \aclrd{\textbf{q}}} \vdash e : \tau}\end{array}}
  {\begin{array}{l}~\\[-0.25em]\hspace{-0.5em}f\end{array}}
  {\hspace{-0.5em}\begin{array}{l}
  \lambda(\mathbf{v_1}, y, x, \mathbf{v_2}) .\\[-0.25em]
    \quad f~(\mathbf{v_1}, x, y, \mathbf{v_2})\end{array} }
& (\emph{exch})
\\[1.5em]
\hspace{-0.5em}\mdeff
  {\begin{array}{l}\sem{\coctx{\Gamma_1,y\!:\!\tau_1,z\!:\!\tau_1,\Gamma_2\\[-0.25em]\qquad}
      {\aclrd{\textbf{r}} \atimes \alift{\cclrd{s},\cclrd{t}} \atimes \aclrd{\textbf{q}}} \vdash e : \tau}\end{array}}
  {\begin{array}{l}\sem{\coctx{\Gamma_1,x\!:\!\tau_1,\Gamma_2}{\aclrd{\textbf{r}}
          \atimes \alift{\cclrd{s} \,\cpar\, \cclrd{t}} \atimes \aclrd{\textbf{q}}} \\[-0.25em] \qquad\vdash \subst{e}{z,y}{x} : \tau}\end{array}}
  {\begin{array}{l}~\\[-0.25em]\hspace{-0.5em}f\end{array}}
  {\hspace{-0.5em}\begin{array}{l}\lambda(\mathbf{v_1}, x, \mathbf{v_2}) .\\[-0.25em]
  \quad f~(\mathbf{v_1}, \restr{x}{\cclrd{s}}, \restr{x}{\cclrd{t}}, \mathbf{v_2})\end{array}\hspace{-0.5em}~}
& (\emph{contr})
\end{array}
\end{equation*}

\vspace{-0.5em}
\figcaption{Semantics of structural liveness}
\label{fig:applications-struct-livesem}
\end{figure}
\vspace{-0.5em}

% --------------------------------------------------------------------------------------------------

\paragraph{Summary.}
The structural liveness calculus is a typical example of a system that tracks per-variable
annotations. In a number of ways, the system is simpler than the flat coeffect calculi. In
lambda abstraction, we simply annotate function with the annotation of a matching variable
(this rule is the same for all upcoming systems). In application, the \emph{pointwise} composition
is no longer needed, because the sub-expressions use separate contexts. On the other hand,
we had to add weakening, contraction and exchange rules to let us manipulate contexts.

The semantics of weakening demonstrates an important point about coeffects that may be quite
confusing. When we read the \emph{typing rule} from top to bottom, weakening adds a variable
to the context. When we read the \emph{semantic rule}, weakening drops a variable value from the
context! This duality is caused by the fact that coeffects talk about context -- they describe
how to build the context required by the sub-expressions and so the semantics implements
transformation from the context in the (typing) conclusion to the (typing) assumption. How
should coeffects be understood, in general, is discussed further in Section~\ref{sec:flat-calculus-understanding}.

The structural systems discussed in the upcoming sections are remarkably similar to the one
shown here. We discuss two more examples to explore the design space, but omit details shared with
the system in this section.

%---------------------------------------------------------------------------------------------------

\subsection{Bounded variable use}
\label{sec:applications-struct-bll}

Liveness analysis checks whether a variable is used or unused. With structural coeffects, we can go
further and track how many times is the variable accessed. Girard et al. \cite{logic-bounded} coined
this idea as \emph{bounded linear logic} and use it to restrict well-typed programs to
polynomial-time algorithms. We first introduce the system in our, coeffect, style and then
relate it with the original formulation.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
a.) Ordinary, syntax-driven rules along with subcoeffecting
\begin{equation*}
\tyrule{var}{}
  {\coctx{x \!:\! \tau}{\alift{\cclrd{1}}} \vdash x : \tau}
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x \!:\! \tau_1}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s}}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{\textbf{r}}} \vdash \lambda x . e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{app}
  { \coctx{\Gamma_1}{\aclrd{\textbf{r}}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2 \quad
    \coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}
  { \coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \cons (\cclrd{t} \ast \aclrd{\textbf{s}})} \vdash e_1 \, e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma_1, x \!:\! \tau_1}{\aclrd{\textbf{r}} \times \langle{\cclrd{t}}\rangle} \vdash e_1 : \tau_2 \quad
    \coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}
  {\coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \times (\cclrd{t} \ast \aclrd{\textbf{s}})} \vdash \kvd{let}~x=e_2~\kvd{in}~e_1 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{\textbf{r}}} \vdash e : \tau}
  {\coctx{\Gamma}{\aclrd{\textbf{r'}}} \vdash e : \tau}~\aclrd{\textbf{r}} \leq \aclrd{\textbf{r'}}
\end{equation*}
\vspace{0.5em}

b.) Structural rules for context manipulation
\begin{equation*}
\tyrule{weak}
  {\coctx{\Gamma}{ \aclrd{\textbf{r}} } \vdash e : \sigma}
  {\coctx{\Gamma,x \!:\! \tau}{\aclrd{\textbf{r}} \cons \alift{ \cclrd{0} }} \vdash e : \sigma}
\end{equation*}
\begin{equation*}
\tyrule{exch}
  {\coctx{\Gamma_1,x\!:\!\tau',y\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons\alift{\cclrd{s},\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
  {\coctx{\Gamma_1,y\!:\!\tau,x\!:\!\tau',\Gamma_2}{\aclrd{\textbf{r}} \cons\alift{\cclrd{t},\cclrd{s}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
\quad
\begin{array}{l}
\slen{\Gamma_1} = \slen{\aclrd{\textbf{r}}}\\[-0.25em]
\slen{\Gamma_2} = \slen{\aclrd{\textbf{s}}}
\end{array}
\end{equation*}
\begin{equation*}
\tyrule{contr}
  {\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s},\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
  {\coctx{\Gamma_1,x\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s}+\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash \subst{\subst{e}{z}{x}}{y}{x} : \sigma}
~
\begin{array}{l}
\slen{\Gamma_1} = \slen{\aclrd{\textbf{r}}}\\[-0.25em]
\slen{\Gamma_2} = \slen{\aclrd{\textbf{s}}}
\end{array}
\end{equation*}

\figcaption{Structural coeffect bounded reuse analysis}
\label{fig:applications-struct-bll}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Bounded variable use.}
The system discussed in this section tracks the number of times a variable is accessed in the
call-by-name evaluation. Although we look at an example that tracks \emph{variable usage}, the same
system could be used to track access to resources that are always passed as a reference (and behave
effectively as call-by-name) and so the system is relevant for call-by-value languages too.
To demonstrate the idea, consider the following term:
%
\begin{equation*}
(\lambda v.x + v + v)~(x+y)
\end{equation*}
%
When evaluated, the body of the function directly accesses $x$ once and then twice indirectly, via
the function argument. Similarly, $y$ is accessed twice indirectly. Thus, the overall expression uses
$x$ three times and $y$ twice.

As discussed in Chapter~\ref{ch:structural}, the system preserves type and coeffect annotations under
the $\beta$-reduction. Reducing the expression in this case gives $x + (x+y) + (x+y)$. This has the
same bounds as the original expression -- $x$ is used three times and $y$ twice.

% --------------------------------------------------------------------------------------------------

\paragraph{Type system.}
The type system in Figure~\ref{fig:applications-struct-bll} annotates contexts with vectors of integers.
The rules have the same structure as those of the system for liveness analysis. The only difference is
how annotations are combined. Here, we use integer multiplication ($\ast$) for sequential composition
and addition ($+$) for point-wise composition.

Variable access (\emph{var}) annotates a variable with $1$, meaning that it has been used once. An
unused variable (\emph{weak}) is annotated with $0$. Multiple occurrences of the same variable are
introduced by contraction (\emph{contr}), which adds the numbers of the two contracted variables.

As previously, application (\emph{app}) and let binding (\emph{let}) combine two separate contexts.
The second part applies a function that uses its parameter $\cclrd{t}$-times to an argument that uses
variables in $\Gamma_2$ at most $\aclrd{\mathbf{s}}$-times (here, $\aclrd{\mathbf{s}}$ is a vector of
integers with an annotations for each variable in $\Gamma_2$). The sequential composition (modelling
call-by-name) multiplies the uses, meaning that the total number of uses is $(\cclrd{t} \ast \aclrd{\mathbf{s}})$
(where $\ast$ is a point-wise multiplication of a vector by a scalar). This models the fact that
for each use of the function parameter, we replicate the variable uses in $e_2$.

Finally, the subcoeffecting rule (\emph{sub}) safely overapproximates the number of accesses using
the pointwise $\leq$ relation. We can view any variable as being used a greater
number of times than it actually is.

\paragraph{Example.} To type check the expression $(\lambda v.x+v+v)~(x+y)$ discussed earlier, we need
to use abstraction, application, but also the contraction rule. Assuming the type judgement for the body,
abstractions yields:
%
\begin{equation*}
\tyrule{abs}
 { \coctx{x\!:\!\mathbb{Z},v:\mathbb{Z}}{\alift{\cclrd{1},\cclrd{2}}} \vdash x+v+v : \mathbb{Z} }
 { \coctx{x\!:\!\mathbb{Z}}{\alift{\cclrd{1}}} \vdash (\lambda v.x+v+v) : \mathbb{Z} \xrightarrow{\cclrd{2}} \mathbb{Z} }
\end{equation*}
%
To type-check the application, the contexts of $e_1$ and $e_2$ need to contain disjoint variables.
For this reason, we $\alpha$-rename $x$ to $x'$ in the argument $(x+y)$ and later join $x$ and $x'$ using
the contraction rule. Assuming $(x'+y)$ is checked in a context that marks $x'$ and $y$ as used once, the
application rule yields a judgement that is simplified as follows:
%
\begin{equation*}
\inference
  { \coctx{x\!:\!\mathbb{Z},x'\!:\!\mathbb{Z},y\!:\!\mathbb{Z}}
          {\alift{\cclrd{1}} \cons (\cclrd{2} \ast \alift{\cclrd{1},\cclrd{1}}) } \vdash (\lambda v.x+v+v)~(x'+y) : \mathbb{Z} }
{\tyrule{contr}
  { \coctx{x\!:\!\mathbb{Z},x'\!:\!\mathbb{Z},y\!:\!\mathbb{Z}}{\alift{\cclrd{1}, \cclrd{2}, \cclrd{2}} } \vdash (\lambda v.x+v+v)~(x'+y) : \mathbb{Z} }
  { \coctx{x\!:\!\mathbb{Z},y\!:\!\mathbb{Z}}{\alift{\cclrd{3}, \cclrd{2}}} \vdash (\lambda v.x+v+v)~(x+y)  : \mathbb{Z}} }
\end{equation*}
%
The first step performs scalar multiplication, producing the vector
$\alift{\cclrd{1},\cclrd{2},\cclrd{2}}$. In the second step, we use contraction to join variables
$x$ and $x'$ from the function and argument terms respectively.

% --------------------------------------------------------------------------------------------------

\paragraph{Semantics.}
In the previous examples, we defined the semantics -- somewhat informally -- using a simple
$\lambda$-calculus language to encode the model. More formally, this could be a Cartesian-closed
category. In that model, we can reuse variables arbitrarily and so it is not
a good fit for modelling bounded reuse. Girard et al. \cite{logic-bounded} model their bounded
linear logic in an (ordinary) linear logic where variables can be used at most once.

Following the same approach, we could model a variable $\tau$, annotated with $\cclrd{r}$ as
a product containing $\cclrd{r}$ copies of $\tau$, that is $\tau^{\cclrd{r}}$:
%
\begin{equation*}
\begin{array}{r}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \alift{\cclrd{r_1}, \ldots, \cclrd{r_n}} } \vdash e : \tau}
  ~:~ (\tau^{\cclrd{r_1}}_1 \times \ldots \times \tau^{\cclrd{r_n}}_n) \rightarrow \tau\\[0.5em]
\textnormal{where}~\tau^{\cclrd{r_i}}_i = \underbrace{\tau_i \times \ldots \times \tau_i}_{\cclrd{r_i}-\text{times}}
\end{array}
\end{equation*}
%
The functions are interpreted similarly. A function $\tau_1 \xrightarrow{\cclrd{t}} \tau_2$ is modelled
as a function taking $\cclrd{t}$-element product of $\tau_1$ values: $\tau_1^{\cclrd{t}} \rightarrow \tau_2$.

The rules that define the semantics of bounded calculus are easy to adapt from the semantic rules
of liveness in Figure~\ref{fig:applications-struct-livesem}. The ones that differ are those that use
sequential composition (application and let binding) and the contraction rule, which represents
pointwise composition.

In the following, we use vector names $\mathbf{v}_i$ for contexts containing multiple variables
\ie~have a type $\tau_1^{\cclrd{r_1}}\times\ldots\times\tau_m^{\cclrd{r_m}}$. Each vector contains
multiple copies of each variable, to model the fact that variables are used in an affine way (at most
once). We do not explicitly write the sizes of these vectors (number of variables in a context; number
of instances of a variable) as these are clear from the coeffect annotations. We assume that $\Gamma_2$
contains $n$ variables and that $\aclrd{s}=\alift{\cclrd{s}_1, \ldots, \cclrd{s}_n}$. First, consider
the (\emph{contr}) rule:
%
\begin{equation*}
\hspace{-1em}
\begin{array}{l}
\mdeff
  {\begin{array}{l}\sem{\coctx{\Gamma_1,y\!:\!\tau_1,z\!:\!\tau_1,\Gamma_2\\[-0.25em]\qquad}
      {\aclrd{\textbf{r}} \atimes \alift{\cclrd{s},\cclrd{t}} \atimes \aclrd{\textbf{q}}} \vdash e : \tau}\end{array}}
  {\begin{array}{l}\sem{\coctx{\Gamma_1,x\!:\!\tau_1,\Gamma_2}{\aclrd{\textbf{r}}
          \atimes \alift{\cclrd{s} + \cclrd{t}} \atimes \aclrd{\textbf{q}}} \\[-0.25em] \qquad\vdash \subst{e}{z,y}{x} : \tau}\end{array}}
  {\begin{array}{l}~\\[-0.25em]\hspace{-0.5em}f\end{array}}
  {\hspace{-0.5em}\begin{array}{l}\lambda(\mathbf{v_1}, (x_1, \ldots, x_{\cclrd{s}+\cclrd{t}}), \mathbf{v_2}) .\\[-0.25em]
  \quad f~(\mathbf{v_1}, (x_1, \ldots, x_{\cclrd{s}}), (x_{\cclrd{s}+1}, \ldots, x_{\cclrd{s}+\cclrd{t}} ), \mathbf{v_2})\end{array}\hspace{-0.5em}~}
\end{array}
\end{equation*}
%
The semantic function is called with $\cclrd{s}+\cclrd{t}$ copies of
a value for the $x$ variable. The values are split between $\cclrd{s}$ and $\cclrd{t}$ separate
copies of variables $y$ and $z$, respectively. The (\emph{app}) rule is similar in that it needs to
split the input variable context. However, it needs to split values of multiple variabless:
%
\begin{equation*}
\hspace{-1em}
\begin{array}{l}
\emdefff
  {\coctx{\Gamma_1}{\aclrd{\textbf{r}}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2}
  {\coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}
  {\begin{array}{l}\sem{\coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \cons (\cclrd{t} \ast \aclrd{\textbf{s}})}\\[-0.25em]
    \qquad\vdash e_1 \, e_2 : \tau_2}\\[-0.25em]~\\[-0.25em]~\\[-0.25em]~\\[-0.25em]~\end{array}\hspace{-0.5em}~}
  {f_1}
  {f_2}
  {\hspace{-0.5em}\begin{array}{l}
  \lambda (\mathbf{v_1}, ((x_{1,1}, \ldots, x_{1,\cclrd{t}\ast\cclrd{s}_1}), \ldots, (x_{n,1}, \ldots, x_{n,\cclrd{t}\ast\cclrd{s}_n}) ) .\\[-0.25em]
  \quad(f_1~\textbf{v}_1)\\[-0.25em]
  \qquad (~f_2~((x_{1,1}, \ldots, x_{1,\cclrd{s}_1}), \ldots, \\[-0.25em]
  \hspace{4.0em}                                         ~(x_{n,1}, \ldots, x_{1,\cclrd{s}_n}) ~),\ldots,\\[-0.25em]
  \qquad \;~f_2~((x_{1,(\cclrd{t}-1)\ast\cclrd{s}_1 + 1}, \ldots, x_{1,\cclrd{t}\ast\cclrd{s}_1}), ~\ldots~, \\[-0.25em]
  \hspace{4.0em}                                         ~(x_{n,(\cclrd{t}-1)\ast\cclrd{s}_n + 1}, \ldots, x_{1,\cclrd{t}\ast\cclrd{s}_n})  ~)~)\\[-0.25em]
  \end{array}}}
\end{array}
\end{equation*}
\vspace{0.5em}

\noindent
In $x_{i,j}$, the index $i$ stands for an index of the variable while $j$ is an index of one of
multiple copies of the value. In the semantic function, the second
part of the context consists of $n$ variables where the multiplicity of each value is specified
by the annotation $\cclrd{s}_i$ multiplied by $\cclrd{t}$. The rule needs to evaluate the argument
$e_2$ $\cclrd{t}$-times and each call requires $\cclrd{s}_i$ copies of the $i^\textnormal{th}$
variable. To do this, we create contexts $\mathbf{y}_1$ to $\mathbf{y}_{\cclrd{t}}$, each containing
$\cclrd{s}_i$ copies of the variable (and so we require $\cclrd{s}_i\ast\cclrd{t}$ copies of each
variable). Note that the contexts are created such that each value is used exactly once.

It is worth noting that the (\emph{var}) rule requires exactly one copy of a variable and so
the system tracks precisely the number of uses. However, the (\emph{sub}) rule lets us
ignore additional copies of a value. Thus, permitting (\emph{sub}) rule is only possible if the
underlying model is \emph{affine} rather than \emph{linear}.

\paragraph{Bounded linear logic.}
The system presented in this section is based on the idea of bounded linear logic (BLL)
\cite{logic-bounded}, but it is adapted to follow the structure of other coeffect systems
discussed in this chapter. This elucidates the connection between BLL and coeffects.

The big difference, using the terminology from Section~\ref{sec:path-sem-contextdep}, is
that our system is written in \emph{language semantics} style, while BLL is written
in \emph{meta-language} style. We briefly consider the original BLL formulation.

The terms and types of our system are the terms and types of an ordinary $\lambda$-calculus,
with the only difference that functions carry coeffect annotations. In BLL, the language of
types is extended with a type constructor $!_k A$ (where $A$ is a proposition, corresponding
to a type $\tau$ in our system). The type denotes a value $A$ that can be used at most $k$ times.

As a result, BLL does not need to attach additional annotation to the variable context
as a whole. The requirements are attached to individual variables and so our context
$\coctx{\tau_1, ..., \tau_n}{\langle \cclrd{k_1}, ..., \cclrd{k_n}\rangle}$ corresponds
to a BLL assumption $!_{k_1} A_1, ..., !_{k_n} A_n$. Using the formulation of bounded logic
(and omitting the terms), the weakening and contraction rules are written as follows:

\[
\tyrule{weak}
  {\Gamma \vdash B}
  {\Gamma, !_0 A \vdash B}
\quad
\tyrule{contr}
  {\Gamma, !_n A, !_m A \vdash B}
  {\Gamma, !_{n+m} A \vdash B}
\]
%
The system captures the same idea as the structural coeffect system presented above.
Variable access in bounded linear logic is simply an operation that produces a value
$!_n A$ and so the system further introduces \emph{dereliction} rule which lets us
treat $!_1 A$ as a value $A$. We further explore difference between \emph{language
semantics} and \emph{meta-language} in Section~\ref{sec:further-meta}.

\paragraph{Summary.}
Comparing the structural coeffect calculus for tracking liveness and for bounded variable reuse
reveals which parts of the systems differ and which parts are shared. In particular, both systems
use the same vector operations ($\times$, $\alift{\cclrd{\textnormal{--}}}$) and also share the
lambda abstraction rule (\emph{abs}). They differ in the primitive values used to annotate used
and unused variables (\cclrd{L}, \cclrd{D} and $1$, $0$, respectively) and in the operators used
for sequential composition and contraction ($\cclrd{\sqcup}$, $\cclrd{\sqcap}$ and $\ast$, $+$, respectively).
The algebraic structure capturing these operators is developed in Chapter~\ref{ch:structural}.

The brief overview of bounded linear logic shows an alternative approach to tracking properties
related to individual variables -- we could attach annotations to the variables themselves
rather than attaching a \emph{vector} of annotations to the entire context. One benefit
of our approach is that it lets us unify flat and structural systems (Chapter~\ref{ch:further-unified}).

% --------------------------------------------------------------------------------------------------

\subsection{Dataflow languages revisited}
\label{sec:applications-structural-dataflow}

When discussing dataflow languages in an earlier section, we said that the context provides
past values of variables. In Section~\ref{sec:applications-flat-dataflow}, we tracked this as
a \emph{flat} property, which gives us a system that keeps the same number of past values for
all variables. However, dataflow can also be adapted to a structural system which keeps the number
of required past values individually for each variable. Consider the
following example:
%
\begin{equation*}
\kvd{let}~\ident{offsetAdd} = \ident{left} + \kvd{prev}~\ident{right}
\end{equation*}
%
The value \ident{offsetAdd} adds values of \ident{left} with previous values of \ident{right}.
To evaluate a current value of the stream, we need the current value of \ident{left} and one past
value of \ident{right}. Flat system is not able to capture this level-of-detail and simply
requires $1$ past values of both streams in the variable context.

Turning a flat dataflow system to a structural dataflow system is a change similar to the one
between flat ans structural liveness. In case of liveness analysis, we included the flat system
only as an illustration (it is not practically useful). For dataflow, the flat system is less
precise, but still practically useful (simplicity may outweigh precision).

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}{}
  {\coctx{x \!:\! \tau}{\alift{\cclrd{0}}} \vdash x : \tau}
\end{equation*}
\begin{equation*}
\tyrule{prev}
  {\coctx{\Gamma}{\aclrd{\textbf{r}}} \vdash e : \tau}
  {\coctx{\Gamma}{1 + \aclrd{\textbf{r}}} \vdash \kvd{prev}~e : \tau}
\end{equation*}
\begin{equation*}
\tyrule{app}
  { \coctx{\Gamma_1}{\aclrd{\textbf{r}}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2 \quad
    \coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}
  { \coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \cons (\cclrd{t} \,\cclrd{+}\, \aclrd{\textbf{s}})} \vdash e_1 \, e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{weak}
  {\coctx{\Gamma}{ \aclrd{\textbf{r}} } \vdash e : \sigma}
  {\coctx{\Gamma,x \!:\! \tau}{\aclrd{\textbf{r}} \cons \alift{ \cclrd{0} }} \vdash e : \sigma}
\end{equation*}
\begin{equation*}
\tyrule{contr}
  {\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s},\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
  {\coctx{\Gamma_1,x\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{\textnormal{max}}(\cclrd{s},\cclrd{t})} \cons \aclrd{\textbf{q}}} \vdash \subst{\subst{e}{z}{x}}{y}{x} : \sigma}
\end{equation*}

\figcaption{Structural coeffect bounded reuse analysis}
\label{fig:applications-struct-df}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type system.}
The type system in Figure~\ref{fig:applications-struct-df} annotates the variable context with a
vector of integers. This is similar as in the bounded reuse system, but the integers \emph{mean} a
different thing. Consequently, they are also calculated differently. We omit rules that are the
same for all structural coeffect systems (exchange, lambda abstraction).

In dataflow, we annotate both used variables (\emph{var}) and unused variables (\emph{weak}) with
$0$, meaning that no past values are required. This is the same as in flat dataflow, but different
from bounded reuse and liveness (where unused variables have a different coeffect). Primitive
requirements are introduced by the (\emph{prev}) rule, which increments the annotations of
all variables.

In flat dataflow, we identified sequential composition and pointwise composition as two primitive
operations that were used in the (flat) application. In the structural system, these are used in
(\emph{app}) and (\emph{contr}). Thus application combines coeffect annotations using $+$ and
contraction using \emph{max}. This contrasts with bounded reuse, which uses $\ast$ and $+$,
respectively.

\paragraph{Example.} As an example, consider a function $\lambda x.\kvd{prev}~(y+x)$ applied to an argument
$\kvd{prev}~(\kvd{prev}~y)$. The body of the function accesses the past value of two variables, one free
and one bound. The (\emph{abs}) rule splits the annotations between the declaration site and call site
of the function:
%
\begin{equation*}
\tyrule{abs}
  {\coctx{y\!:\!\mathbb{Z}, x\!:\!\mathbb{Z}}{\alift{1, 1}} \vdash \kvd{prev}~(y+x) : \mathbb{Z} }
  {\coctx{y\!:\!\mathbb{Z}}{\alift{1}} \vdash \lambda x . \kvd{prev}~(y+x) : \mathbb{Z} \xrightarrow{\cclrd{1}} \mathbb{Z} }
\end{equation*}
%
The expression always requires the previous value of $y$ and adds it to a previous value of the
parameter $x$. Evaluating the value of the argument $\kvd{prev}~(\kvd{prev}~y)$ requires two past
values of $y$ and so the overall requirement for the (free) variable $y$ is $3$ past values. In
order to use the contraction rule, we rename $y$ to $y'$ in the argument:
%
\begin{equation*}
\inference
  { \coctx{y\!:\!\mathbb{Z}}{\alift{1} } \vdash \lambda x.~(\ldots) : \mathbb{Z} \xrightarrow{\cclrd{1}} \mathbb{Z} &
    \coctx{x\!:\!\mathbb{Z}}{\alift{2}} \vdash (\kvd{prev}~(\kvd{prev}~y') : \mathbb{Z} }
{\inference
  { \coctx{y\!:\!\mathbb{Z}, y'\!:\!\mathbb{Z}}{\alift{1,3}} \vdash (\lambda x.\kvd{prev}~(y+x))~(\kvd{prev}~(\kvd{prev}~y')) : \mathbb{Z} }
  { \coctx{y\!:\!\mathbb{Z}}{\alift{3}} \vdash (\lambda x.\kvd{prev}~(y+x))~(\kvd{prev}~(\kvd{prev}~y)) : \mathbb{Z} } }
\end{equation*}
%
The derivation uses (\emph{app}) to get requirements $\alift{1,3}$ and then (\emph{contr}) to take
the maximum, showing three past values are sufficient.

Note that we get the same requirements when we perform $\beta$ reduction of the expression.
Substituting the argument for $x$ yields the expression $\kvd{prev}~(y+(\kvd{prev}~(\kvd{prev}~y)))$.
Semantically, this performs stream lookups $y[1]$ and $y[3]$ where the indices are the
number of enclosing $\kvd{prev}$ constructs.

\paragraph{Semantics.}
To define the semantics of our structural dataflow language, we can use the same approach as when
adapting flat liveness to structural liveness. Rather than wrapping the whole context in a type
constructor (list or option), we now wrap the individual components of the product representing
the variables in the context.

The result is similar as the structure used for bounded reuse. The only difference is that, given
a variable annotated with $\cclrd{r}$, we need $1+\cclrd{r}$ values. That is, we need the current
value, followed by $\cclrd{r}$ past values:
%
\begin{equation*}
\begin{array}{l}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \alift{\cclrd{r_1}, \ldots, \cclrd{r_n}} } \vdash e : \tau}
  ~:~ (\tau^{(\cclrd{r_1}+1)}_1 \times \ldots \times \tau^{(\cclrd{r_n}+1)}_n) \rightarrow \tau\\
\sem{\tau_1 \xrightarrow{\cclrd{s}} \tau_2} ~=~ \tau_1^{(\cclrd{s}+1)} \rightarrow \tau_2
\end{array}
\end{equation*}
%
Despite the similarity with the semantics for bounded reuse, the values here \emph{represent}
different things. Rather than providing multiple copies of a value (out of which each can be
used just once), the pair provides past values (that can be reused and freely accessed).
To illustrate the behaviour consider first the semantics of the \kvd{prev} expression:
%
\begin{equation*}
\hspace{-1em}
\begin{array}{l}
\emdeff
  {\coctx{\Gamma}{\alift{\cclrd{s}_1, \ldots, \cclrd{s}_n}} \vdash e : \tau}
  {\begin{array}{l}\sem{\coctx{\Gamma}{\alift{(\cclrd{s}_1 \hspace{-0.2em}+\hspace{-0.2em} 1), \ldots, (\cclrd{s}_n \hspace{-0.2em}+\hspace{-0.2em} 1)}}\\[-0.25em]
    \qquad\vdash \kvd{prev}~e : \tau}\end{array}\hspace{-0.5em}~}
  {f}
  {\hspace{-0.5em}\begin{array}{l}\lambda((x_{1,0}, \ldots, x_{1,{\cclrd{s}_1 + 1}}), \ldots, (x_{n,0}, \ldots, x_{n,{\cclrd{s}_n + 1}})).\\[-0.25em]
  \quad f~((x_{1,0}, \ldots, x_{1,\cclrd{s}_1}), \ldots, (x_{n,0}, \ldots, x_{n,\cclrd{s}_n}))\end{array}\hspace{-0.5em}~}
\end{array}
\end{equation*}
%
Here, the semantic function is called with an argument that stores values of $n$
variables, such that a variable $x_i$ has values ranging from $x_{i,0}$ to $x_{i,\cclrd{s}_i + 1}$.
Thus, there is one current value, followed by $\cclrd{s_i} + 1$ past values. The expression $e$
nested under $\kvd{prev}$ requires only $\cclrd{s_i}$ past values and so the semantics
drops the last value. The following shows the semantics of contraction:
%
\begin{equation*}
\hspace{-1em}
\begin{array}{l}
\mdeff
  {\begin{array}{l}\sem{\coctx{\Gamma_1,y\!:\!\tau_1,z\!:\!\tau_1,\Gamma_2\\[-0.25em]\qquad}
      {\aclrd{\textbf{r}} \atimes \alift{\cclrd{s},\cclrd{t}} \atimes \aclrd{\textbf{q}}} \vdash e : \tau}\end{array}}
  {\begin{array}{l}\sem{\coctx{\Gamma_1,x\!:\!\tau_1,\Gamma_2}{\aclrd{\textbf{r}}
          \atimes \alift{\cclrd{\textnormal{max}}(\cclrd{s}, \cclrd{t})} \atimes \aclrd{\textbf{q}}} \\[-0.25em] \qquad\vdash \subst{e}{z,y}{x} : \tau}\end{array}}
  {\begin{array}{l}~\\[-0.25em]\hspace{-0.5em}f\end{array}}
  {\hspace{-0.5em}\begin{array}{l}\lambda(\mathbf{v_1}, (x_0, x_1, \ldots, x_{ \textnormal{max}(\cclrd{s},\cclrd{t}) }), \mathbf{v_2}) .\\[-0.25em]
  \quad f~((\mathbf{v_1}, (x_0, \ldots, x_{\cclrd{s}}), (x_0, \ldots, x_{\cclrd{t}} ), \mathbf{v_2}))\end{array}\hspace{-0.5em}~}
\end{array}
\end{equation*}
%
The semantic function receives $\emph{max}(\cclrd{s}, \cclrd{t})$ values
of a specific variable $x$. It needs to produce values for two separate variables, $y$ and $z$ that
require $\cclrd{s}$ and $\cclrd{t}$ past values. Both of these numbers are certainly smaller than
(or equal to) the number of values available. Thus we simply take the first values. Unlike in the
contraction for BLL, the values are duplicated and the same values are used for both variables.

\paragraph{Summary.}
Two of the structural examples shown so far (liveness and dataflow) extend an earlier flat
version of a similar system. We discuss this relation in general later. However, a flat system
can generally be turned into a structural one -- although this only gives a useful system when
the flat version captures statically scoped properties, \ie~related to variables.

The dataflow example demonstrates that the a flat system can also be turned into structural
system. In general, this only works for systems where lambda abstraction duplicates context
requirements (as in Figure~\ref{fig:applications-flat-liveness}).

% --------------------------------------------------------------------------------------------------

\subsection{Security, tainting and provenance}
Tainting is a mechanism where variables coming from potentially untrusted sources are marked
(\emph{tainted}) and the use of such variables is disallowed in contexts where untrusted input
can cause security issues or other problems. Tainting can be done dynamically using a runtime mark
(\eg~in the Perl language) or using a static type system. Tainting can be viewed as a special
case of \emph{provenance tracking}, known from database systems \cite{app-provenance-db}, where
values are annotated with more detailed information about their source.

Static typed systems based on tainting have been use to prevent cross-site scripting attacks
\cite{app-tainting-xss} and SQL injection attacks \cite{app-tainting-sql,app-tainting-wasp}.
In the latter case, we want to check that SQL commands cannot be directly constructed from
unchecked inputs provided by the user. Consider the type checking of the following
expression in a context containing variables \ident{id} and \ident{msg}:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{name} = \ident{query}(\str{SELECT Name WHERE Id = \%1}, \ident{id})\\[-0.25em]
\ident{msg}~+~\ident{name}
\end{array}
\end{equation*}
%
In this example, \ident{id} must not come directly from a user input, because \ident{query} requires
untainted string. Otherwise, the attacker could specify values such as \str{1; DROP TABLE Users}.
The variable \ident{msg} may or may not be tainted, because it is not used in protected context
(i.e.~to construct an SQL query).

In runtime checking, all (string) values need to be wrapped in an object with a Boolean
flag (for tainting) or more complex data (for provenance). In static checking, the information
need to be associated with the variables in the variable context.

% --------------------------------------------------------------------------------------------------

\paragraph{Core dependency calculus.}
Taint checking is a special case of checking of the \emph{non-interference} property
in \emph{secure information flow}. There, the aim is to guarantee that sensitive information (such
as credit card number) cannot be leaked to contexts with low secrecy (\eg~sent via an unsecured
network channel). Volpano et al. \cite{app-secure-flow} provide the first (provably) sound type
system that guarantees non-inference and Sabelfeld et al. \cite{app-secure-information-flow} surveys
more recent work. Information flow checking has been also integrated (as a single-purpose
extension) in the FlowCaml \cite{app-security-flowcaml} language. Finally, Russo et al. and
Swamy et al. \cite{monad-secure-flow,monads-lightweight-ml} show that such properties can be checked
using a monadic library.

Systems for secure information flow typically define a lattice of security classes $(\mathcal{S}, \leq)$
where $\mathcal{S}$ is a finite set of classes and an ordering. For example a set $\{\cclrd{\ident{L}}, \ident{H}\}$
represents low and high secrecy, respectively with $\cclrd{\ident{L}} \leq \ident{H}$ meaning that low security
values can be treated as high security (but not the other way round).

\paragraph{Implicit flows.}
An important aspect of secure information flow is called \emph{implicit flows}. Consider the following
example which returns either $y$ or zero, depending on the value of $x$:
%
\begin{equation*}
\kvd{let}~z = \kvd{if}~x>0~\kvd{then}~y~\kvd{else}~0
\end{equation*}
%
If the value of $y$ is high-secure, then $z$ becomes high-secure after the assignment
(this is an \emph{explicit} flow). However, if $x$ is high-secure, then the value of
$z$ becomes high-secure, regardless of the security level of $y$, because the fact whether an
assignment is performed or not performed leaks information in its own (this is an
\emph{implicit} flow).

Although we do not describe a coeffect calculus for information flow checking, it is worth noting
that Abadi et al. \cite{app-dcc} realized that there is a number of analyses similar to secure information
flow and unified them using a single model called Dependency Core Calculus (DCC). This would be
a useful basis for coeffect-based information flow checking.

The DCC captures other cases where some information about expression relies on properties of variables
in the context where it executes.  This includes, for example, \emph{binding time analysis}
\cite{app-binding-time-analysis}, which detects which parts of programs can be partially evaluated
(do not depend on user input) and \emph{program slicing} \cite{app-slicing-survey} that identifies
parts of programs that contribute to the output of an expression.

\paragraph{Coeffect systems.}
The work outlined in this section is another area where coeffect systems could be applied.
We do not develop coeffect systems for taint tracking, security and provenance in detail,
but briefly mention some examples in the upcoming chapters.

The systems work in the same way as the examples discussed already. For example, consider the
tainting example with the \ident{query} function calling an SQL database. To capture such
tainting, we annotate variables with $\cclrd{\ident{T}}$ for \emph{tainted} and with
$\cclrd{\ident{U}}$ for \emph{untainted}. Accessing a variable marks it as untainted,
but using an expression that depends on some variable in certain dangerous contexts -- such
as in arguments of \ident{query} -- does introduce a taint on all the variables contributing to
the expression. This is captured using the standard application rule (\emph{app}):
%
\begin{equation*}
\hspace{-2em}
\tyrule{app}
  { \coctx{\Gamma}{\aclrd{r}} \vdash \ident{query} : \ident{string} \xrightarrow{\cclrd{\ident{T}}} \ident{Table} \qquad
    \coctx{\ident{id}:\ident{string}}{ \alift{\cclrd{\ident{U}}}} \vdash \ident{id} : \ident{string} }
  { \coctx{\Gamma, \ident{id}:\ident{string}}{ \aclrd{r} \cons \alift {\cclrd{\ident{T}}} \vdash \ident{query}(\str{...}, \ident{id}) : \ident{Table} } }
\end{equation*}
%
The derivation assumes that \ident{query} is a standard function that requires the parameters
to be tainted (it does not have to be a built-in language construct). The argument is a
variable and so it is not tainted in the assumptions.

In the conclusion, we need to derive an annotation for the variable \ident{id}. To do this, we
combine \cclrd{\ident{T}} (from the function) and \cclrd{\ident{U}} (from the argument). In case
of tainting, the variable is tainted whenever it is already tainted \emph{or} the function marks
it as tainted. For different kinds of annotations, the composition would work differently -- for
example, for provenance, we could union the \emph{set} of possible data sources, or even combine
\emph{probability distributions} modelling the influence of different sources on the value.
However, expanding such ideas is beyond the scope of this thesis.

% ==================================================================================================

\section{Beyond passive contexts}

In both flat and structural systems discussed so far, the context provides additional data (resources,
implicit parameters, historical values) or meta-data (security, provenance). However, \emph{within}
the language, it is impossible to write a function that modifies the context. We use the term
\emph{passive} context for such applications.

There is a number of systems that also capture contextual properties, but that make it possible to
\emph{change} the context -- not just by evaluating certain code block in a locally modified context
(\eg by wrapping it in $\ident{prev}$ in dataflow), but also by calling a function that, for example,
acquires new capabilities and returns those to the caller. Such actions appear to be closer to
effects than to coeffects. While this thesis focuses on systems with passive contexts, we briefly
consider the most important examples of the \emph{active} variant.

% --------------------------------------------------------------------------------------------------

\paragraph{Calculus of capabilities.}
\label{sec:applications-active-ccc}

Crary et al. \cite{app-capabilities} introduced the Calculus of Capabilities to provide
a sound system with region-based memory management for low-level code that can be easily
compiled to assembly language. They build on the work of Tofte and Talpin \cite{app-region-memory}
who developed an effect system (as discussed in Section~\ref{sec:path-sem-effects}) that uses
lexically scoped \emph{memory regions} to provide an efficient and controlled memory management.

In the work of Tofte and Talpin, the context is \emph{passive}. They extend a simple functional language
with the \kvd{letrgn} construct that defines a new memory region, evaluates an expression (possibly)
using memory in that region and then deallocates the memory of the region:

\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{calculate} = \lambda \ident{input} \rightarrow\\[-0.25em]
\quad \kvd{letrgn}~\rho~\kvd{in}\\[-0.25em]
\quad \kvd{let}~\ident{x} = \kvd{ref}_\rho ~\ident{input}~\kvd{in}\\[-0.25em]
\quad \ident{x} :=\, !\ident{x} + 1;~ !\ident{x}
\end{array}
\end{equation*}
%
The memory region $\rho$ is a part of the context, but only in the scope of the body of
\kvd{letrgn}. It is only available to the last two lines which allocate a memory cell in the region,
increment a value in the region and then read it. The region is de-allocated when the execution
leaves its lexical scope -- there is no way to allocate a region inside a function and pass it back
to the caller.

The calculus of capabilities differs in two ways. First, it allows explicit allocation and deallocation
of memory regions (and so region lifetimes do not necessarily follow strict LIFO ordering). Second,
it uses continuation-passing style. We ignore the latter aspect. The following example is almost
identical to the previous one:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{calculate} = \lambda \ident{input} \rightarrow\\[-0.25em]
\quad \kvd{letrgn}~\rho~\kvd{in}\\[-0.25em]
\quad \kvd{let}~\ident{x} = \kvd{ref}_\rho ~\ident{input}~\kvd{in}\\[-0.25em]
\quad \ident{x} :=\, !\ident{x} + 1;~ \ident{x}
\end{array}
\end{equation*}
%
The difference is that the example does not return the \emph{value} of a reference using
$!\ident{x}$, but returns the reference $\ident{x}$ itself. The reference is allocated in a newly
created region $\rho$. Together with the value, the function returns a \emph{capability} to access
the region $\rho$.

This is where systems with active context differ from systems with passive context. To type check
such programs, we do not only need to know what context is required to call \ident{calculate}
(\ie~context on the left-hand side of $\vdash$). We also need to know what effects an expression
has on the context when it evaluates and the current context meeds to be updated after a function
call. This is an effectful property that would appear on the right-hand side of $\vdash$.

\paragraph{Active contexts.}
In a systems with passive contexts, we only need an annotation that specifies the required
context. In semantics, this is reflected by having some structure (data type) $\C$ over the
\emph{input} of the function. Without giving any details, the semantics generally has the
following structure (with comonad to model coeffects on the left):
%
\begin{equation*}
\sem{\tau_1 \xrightarrow{\cclrd{r}} \tau_2} = \C^{\cclrd{r}} \tau_1 \rightarrow \tau_2
\end{equation*}
%
Systems with active contexts require two annotations -- one that specifies the context required
before the call is performed and one that specifies how the context changes after the call (this
could be either a \emph{new} context or \emph{update} to the original context). Thus the structure
of the semantics would look as follows (with comonad to model coeffects on the left and monad to
model effects on the right):
%
\begin{equation*}
\sem{\tau_1 \xrightarrow{\cclrd{r}, \cclrd{s}} \tau_2} = \C^{\cclrd{r}} \tau_1 \rightarrow \M^{\cclrd{s}} \tau_2
\end{equation*}
%
In case of Calculus of Capabilities, both of the structures could be the same and they could
carry a set of available memory regions. In this thesis, we focus only on passive contexts.
However, capturing active contexts is an interesting future work.

% --------------------------------------------------------------------------------------------------

~

\paragraph{Software updating.}
Another example of a system that uses contextual information actively is dynamic software updating
(DSU) \cite{app-dsu-programs,app-dsu}. The DSU systems have the ability to update programs at
runtime without stopping them. For example, Proteus developed by Stoyle et al. \cite{app-dsu-mutatis}
investigates what language support is needed to enable safe dynamic software updating in C-like
languages. The work is based on capabilities and follows a structure similar to the Calculus
of Capabilities \cite{app-capabilities}.

The system distinguishes between \emph{concrete} uses and \emph{abstract} uses of a value. When
a value is used concretely, the program examines its representation (and so it is not safe to
change the representation during an update). An abstract use of a value does not examine
the representation and so updating the value does not break the program.

The Proteus system uses capabilities to restrict what types may be used concretely after any point
in the program. All other types, not listed in the capability, can be dynamically updated as this
will not change concrete representation of types accessed later in the evaluation.

Similarly to Capability Calculus, capabilities in DSU can be changed by a function call. For
example, calling a function that may update certain types makes it impossible to use those types
concretely following the function call. This means that DSU uses the context \emph{actively}
and not just \emph{passively}.


%===================================================================================================
%
%     #####
%    #     # #    # #    # #    #   ##   #####  #   #
%    #       #    # ##  ## ##  ##  #  #  #    #  # #
%     #####  #    # # ## # # ## # #    # #    #   #
%          # #    # #    # #    # ###### #####    #
%    #     # #    # #    # #    # #    # #   #    #
%     #####   ####  #    # #    # #    # #    #   #
%
%===================================================================================================

\section{Summary}

This chapter served two purposes. The first aim was to present existing work on programming
languages and systems that include some notion of \emph{context}. Because there was no well-known
abstraction capturing contextual properties, the languages use a wide range of formalisms -- including
principled approaches based on comonads and modal S4, ad-hoc type system extensions and static analyses
as well as approaches based on monads. We looked at a number of applications including Haskell's implicit
parameters and type classes, dataflow languages such as Lucid, liveness analysis and also a number of
security properties.

The second aim of this chapter was to re-formulate the existing work in a more uniform style and thus
reveal that all \emph{context-dependent} languages share a common structure. In the upcoming three
chapters, we identify the common structure more precisely and develop three calculi to capture it. We
will then be able to re-create many of the examples discussed in this chapter just by instantiating our
unified calculi.

This chapter was divided into two major sections. First, we looked at \emph{flat} systems, which
track whole-context properties. Next, we look a \emph{structural} systems, which track per-variable
properties. Both of the variants are useful and important -- for example, implicit parameters can
only be expressed as \emph{flat} system, but liveness analysis is only useful as \emph{structural}.
For this reason, we explore both of these variants in this thesis (Chapter~\ref{ch:flat} and
Chapter~\ref{ch:structural}, respectively). We can, however, unify the two variants into a single
system discussed in Section~\ref{sec:further-unified}.
