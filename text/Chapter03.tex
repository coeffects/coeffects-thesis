% ==================================================================================================

\chapter{Context-aware systems} 
\label{ch:applications} 

Software developers as well as programming language researchers choose abstractions based not 
just on how appropriate they are. Other factors may include social aspects -- how well is the 
abstraction known, how well is it documented and whether it is a standard tool of the 
\emph{research programme}\footnote{ Research programme, as introduced by Lakatos \cite{philosophy-lakatos},
is a network of scientists sharing the same basic assumptions and techniques.}. This may
partly be why no unified context tracking mechanism has been developed so far.

In Chapter~\ref{ch:intro}, we argued that context-awareness had, so far, only limited influence 
on the design of programming languages because it is a challenge that is not easy to
see. However, many of the properties that this thesis treats uniformly as \emph{coeffects} have been
previously tracked by other means. This includes special-purpose type systems, systematic 
approaches arising from modal logic S4, as well as techniques based on abstractions designed 
for other purpose, most frequently monads.

In this chapter, we describe a number of simple calculi for tracking a wide range of contextual
properties. The systems are adapted from existing work, but the uniform presentation in this 
chapter is a novel contribution. The fact that we find a common structure in all systems presented 
here lets us develop unified coeffect calculi in the upcoming three chapters.

%===================================================================================================

\section{Structure of coeffect systems}

When introducing coeffect systems in Section~\ref{sec:intro-theory}, we related coeffect systems
with effect systems. Effect systems track how program affects the environment, or, in other words 
capture some \emph{output impurity}. In contrast, coeffect systems track what program requires from the 
environment, or \emph{input impurity}.

Effect systems generally use judgements of the form $\Gamma \vdash e : \tau \;\&\; \aclrd{\sigma}$, 
associating effects $\sigma$ with the output type. In contrast, we choose to write coeffect 
systems using judgements of the form $\coctx{\Gamma}{\aclrd{\sigma}} \vdash e : \tau$, associating
the context requirements with $\Gamma$. Thus, we extend the traditional notion of free-variable
context $\Gamma$ with richer notions of context. Besides the notation, there are more important 
differences between effects and coeffects.

% --------------------------------------------------------------------------------------------------

\subsection{Lambda abstraction}
\label{sec:applications-structure-lam}

The difference between effects and coeffects becomes apparent when we consider lambda abstraction.
The typical lambda abstraction rule for effect systems looks as (\emph{abs-eff}) in 
Figure~\ref{fig:applications-abs}. Wadler and Thiemann~\cite{monads-effects-marriage} explain how 
the effect analysis works as follows:
%
\begin{quote}
\emph{In the rule for abstraction, the effect is empty because evaluation immediately
returns the function, with no side effects. The effect on the function arrow
is the same as the effect for the function body, because applying the function will
have the same side effects as evaluating the~body.}
\end{quote}
%
This is the key property of \emph{output impurity}. The effects are only produced when the
function is evaluated and so the effects of the body are attached to the function. A recent
work by Tate~\cite{effects-producer-semantics} uses the term \emph{producer} effect systems
for such standard systems and characterises them as follows:
%
\begin{quote}
\emph{Indeed, we will define an effect as a producer effect if all computations with that 
effect can be thunked as ``pure'' computations for a domain-specific notion of purity.}
\end{quote} 
%
The thunking is typically performed by a lambda abstraction -- given an effectful expression 
$e$, the function $\lambda x.e$ is an effect free value (thunk) that delays all effects.
As shown in the next section, contextual properties do not follow this pattern.

% --------------------------------------------------------------------------------------------------

\begin{figure}
\[
\tyrule{abs-pure}
  { \Gamma, x\!:\!\tau_1 \vdash e : \tau_2}
  { \Gamma \vdash \lambda x.e : \tau_1 \rightarrow \tau_2 1}
\;\;
\tyrule{abs-eff}
  { \Gamma, x\!:\!\tau_1 \vdash e : \tau_2 \,\&\, \aclrd{\sigma} }
  { \Gamma \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{\sigma}} \tau_2 \,\&\, \aclrd{\emptyset} }
\]
\caption{Lambda abstraction for pure and effectful computations}
\label{fig:applications-abs}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsection{Notions of context}

We look at three notions of context. The first is the standard free-variable context in 
$\lambda$-calculus. This is well understood and we use it to demonstrate how contextual 
properties behave. Then we consider two notions of context introduced in this thesis --
\emph{flat coeffects} refer to overall properties of the environment and \emph{structural coeffects} 
refer to properties attached to individual variables. 

\paragraph{Variable coeffects.}

In standard $\lambda$-calculus, variable access can be seen as a primitive operation that 
accesses the context. The expression $x$ introduces a context requirement -- the expression 
is typeable only in a context that contains $x:\tau$ for some type $\tau$. 

The standard lambda abstraction (\emph{abs-pure}), shown in Figure~\ref{fig:applications-abs},
splits the free-variable context of an expression into two parts. The value of the parameter
has to be provided by the \emph{call site} (dynamic scope) and the remaining values are provided 
by the \emph{declaration site} (lexical scope). Here, the splitting is determined syntactically --
the notation $\lambda x.e$ names the variable whose value comes from the call site.

The flat and structural coeffects behave in the same way. They also split context-requirements
between the declaration site and call site, but they do it in two different ways.

\paragraph{Flat coeffects.}

In Section~\ref{sec:intro-context-example}, we used \emph{resources} in a distributed system as an 
example of flat coeffects. These could be, for example, a database, GPS sensor or access to the current 
time. We also outlined that such context requirements can be tracked as part of the typing assumption,
for example, say we have an expression $e$ that requires GPS coordinates and the current time. 
The context of such expression will be $\coctx{\Gamma}{ \aclrd{\ident{\{ gps, time \}}} }$.

The interesting case is when we construct a lambda function $\lambda x.e$, marshall it and
send it to another node. In that case, the context requirements can be satisfied in a number of
ways. When the same resource is available at the target machine (\eg.~current time), we can
send the function with a context requirement and \emph{rebind} the resource. However, if the
resource is not available (\eg.~GPS on the server), we need to capture a \emph{remote reference}.

In the example discussed here, $\lambda x.e$ would require GPS sensor from the declaration
site (lexical scope) where the function is declared, which is attached to the current context
as $\coctx{\Gamma}{ \aclrd{\ident{\{ gps \}}} }$. The current time is required from the caller
of the function. So, the context requirement on the call site (dynamic scope) will be
$\aclrd{r}=\aclrd{\footnotesize\ident{\{ time \}}}$. In coeffect systems, we attach this information
to the function writing $\tau_1 \xrightarrow{ \aclrd{r} } \tau_2$.

We look at resources in distributed programming in more details in Section~\ref{sec:applications-flat-distr}.
The important point here is that in flat coeffect systems, contextual requirements are 
\emph{split} between the call-site and declaration-site. Furthermore, in case of distributed
programming, the resources can be freely distributed between the two sites.

\paragraph{Structural coeffects.}

On the one hand, variable context provides a \emph{fine-grained tracking} mechanism of how context
(variables) are used. On the other hand, flat coeffects let us track \emph{additional information} about 
the context. The purpose of \emph{structural coeffects} is to reconcile the two and to provide a way
for fine-grained tracking of additional information related to variables in programs.

In Section~\ref{sec:intro-why-array}, we used an example of tracking array access patterns. For every
variable, the additional coeffect annotation keeps a range of indices that may be accessed relatively
to the current cursor. For example, consider an expression 
$x[\kvd{cursor}] = y[\kvd{cursor}-1] + y[\kvd{cursor}+1]$.

Here, the variable context $\Gamma$ contains two variables, both of type \ident{Arr}. This means
$\Gamma = x\!:\!\ident{Arr},\, y\-!\-!\ident{Arr}$. For simplicity, we treat \kvd{cursor} as a 
language primitive. The coeffect annotations will be $(0,0)$ for $x$ and $(-1,1)$ for $y$, 
denoting that we access only the current value in $x$, but we need access to both left and right 
neighbours in the $y$ array. In order to unify the flat and structural notions, we attach this information 
as a \emph{vector} of annotations associated with a \emph{vector} of variable and write:
$\coctx{x\!:\!\ident{Arr},\, y\!:\!\ident{Arr}}{ \aclrd{\alift{ (0,0), (-1,1) }} }$.
The unification is discussed in Chapter~\ref{ch:unified}.

Unlike in flat coeffects, in the structural systems, splitting of context determined by the syntax. 
For example, consider a function that takes $y$ and contains the above body:
$\lambda y.x[\kvd{cursor}] = y[\kvd{cursor}-1] + y[\kvd{cursor}+1]$. Here, the declaration site
contains $x$ and needs to provide access at least within a range $(0,0)$. The call site provides
a value for $y$, which needs to be accessible at least within $(-1, 1)$. In this way, structural
coeffects remove the non-determinism of flat coeffect systems.

Before looking at concrete flat and structural systems in mode details, we briefly overview 
some notation used in this thesis. As structural coeffects keep annotations as \emph{vectors},
we use a number of operations related to scalars and vectors.

% --------------------------------------------------------------------------------------------------

\subsection{Scalars and vectors}

The $\lambda$-calculus is asymmetric -- it maps a context with \emph{multiple} variables to a 
\emph{single} result. An expression with free variables of types $\tau_i$ can be modelled by a function 
$\tau_1 \times \ldots \times \tau_n \rightarrow \tau$ with a product on the left, but a single value
on the right. Effect systems attach effect annotations to the result $\tau$. In coeffect systems,
we attach a coeffect annotation to the context $\tau_1 \times \ldots \times \tau_n$.

Structural coeffects have one coeffect annotation per each variable. Thus, the annotation consists
of multiple values -- one belonging to each variable. To distinguish between the overall annotation
and individual (per-variable) annotations, we call the overall coeffect a \emph{vector} consisting of 
\emph{scalar} coeffects. This asymmetry also explains why coeffect systems are not trivially dual to 
effect systems.

It is useful to clarify how vectors are used in this thesis. Suppose we have a set $\C$ of
\emph{scalars} such that $\cclrd{r_1},\ldots,\cclrd{r_n} \in \C$. A vector $\aclrd{R}$ 
over $\C$ is a tuple $\alift{ \cclrd{r_1}, \ldots, \cclrd{r_n} }$ of scalars. 
We use upper-case letters like $\aclrd{R}, \aclrd{S}, \aclrd{T}$ for vectors and lower-case
letters $\cclrd{r},\cclrd{s},\cclrd{t}$ for scalars\footnote{For better readability, the thesis
also distinguishes different structures using colours. However ignoring the colour does not introduce 
any ambiguity.}. We also say that a \emph{shape} of a vector $\slift{\aclrd{R}}$ (or more generally any container) 
is the set of \emph{positions} in a vector. So, a vector of length $n$ has shape $\{ 1, 2, \ldots, n \}$. 
We discuss containers and shapes further in Chapter~\ref{ch:unified} and also discuss how our use
relates to containers of Abbott, Altenkirch and Ghani \cite{types-containers}.

Just as in the usual multiplication of a vector by scalar, we lift any binary operation on scalars into a 
scalar-vector one. For any binary operation on scalars $\circ : \C \times \C \rightarrow \C$, we define
 $\cclrd{s} \circ \aclrd{R} = \alift{ \cclrd{s}\circ\cclrd{r_1}, \ldots, \cclrd{s}\circ\cclrd{r_n}}$.
Relations on scalars can be also lifted to vectors. Given two vectors $\aclrd{R}, \aclrd{S}$ of the
same shape with positions $\{ 1, \ldots, n \}$ and a relation $\varpropto\, \subseteq \C \times \C$ we define 
$\aclrd{R} \varpropto \aclrd{S} \Leftrightarrow (\cclrd{r_1} \varpropto \cclrd{s_1}) \wedge \ldots \wedge (\cclrd{r_n} \varpropto \cclrd{s_n}) $
Finally, we often concatenate vectors -- for example, when joining two variable contexts.
Given vectors $\aclrd{R}, \aclrd{S}$ with (possibly different) shapes $\{ 1, \ldots, n \}$ and 
$\{ 1, \ldots, m \}$, the associative operation for concatenation $\times$ is defined as 
$\aclrd{R}\times\aclrd{S} = \alift{\cclrd{r_1},\ldots,\cclrd{r_n},\cclrd{s_1},\ldots,\cclrd{s_m}}$.

We note that an environment $\Gamma$ containing $n$ uniquely named, typed variables is also a vector, 
but we continue to write `$,$' for the product, so $\Gamma_1, x\!:\!\tau, \Gamma_2$ should 
be seen as $\Gamma_1 \times \langle x\!:\!\tau\rangle \times \Gamma_2$.

%===================================================================================================

\section{Flat coeffect systems}

In flat coeffect systems, the additional contextual information are independent of the variables.
As such, flat coeffects capture properties where the execution environment provides some 
additional data, resources or information about the execution context.

In this section, we look at a number of examples ranging from Haskell's type constraints
and implicit parameters to distributed computing. For three of our examples --
implicit parameters, liveness analysis and data-flow -- we show an ad-hoc type system that
captures their properties. This serves as a basis for Chapter~\ref{ch:flat}, which develops
a unified flat coeffect calculus.

%---------------------------------------------------------------------------------------------------

\subsection{Implicit parameters and type classes} 

Haskell provides two examples of flat coeffects -- type class and implicit parameter constraints
\cite{app-type-classes,app-implicit-parameters}. Both of the features introduce additional 
\emph{constraints} on the context requiring that the environment provides certain operations for
a type (type classes) or that it provides values for named implicit parameters.
In the Haskell type system, constraints $C$ are attached to the types of top-level declarations,
such as let-bound functions. The Haskell notation $\Gamma \vdash e : C \Rightarrow \tau$ 
corresponds to our notation $\coctx{\Gamma}{C} \vdash e : \tau$. 

In this section, we present a type system for implicit parameters in terms of the coeffect typing
judgement. We briefly consider type classes, but do no give a full type system.

\paragraph{Implicit parameters.}
Implicit parameters are a special kind of variables that support dynamic scoping.
They can be used to parameterise a computation (involving a long chain of function calls)
without passing parameters explicitly as additional arguments of all involved functions. 

The dynamic scoping means that if a function uses a parameter $\ident{?param}$ then the caller of the 
function must set a value of $\ident{?param}$ before calling the function. However, implicit 
parameters also support lexical scoping. If the parameter $\ident{?param}$ is available in the 
lexical scope where a function (which uses it) is defined, then the function will not require a
value from the caller.

A simple language with implicit parameters has an expression $\ident{?param}$ to read a parameter 
and an expression\footnote{Haskell uses $\kvd{let}~\ident{?p} = e_1~\kvd{in}~e_2$, but we use a 
different keyword to avoid confusion.} $\kvd{letdyn}~\ident{?param} = e_1~\kvd{in}~e_2$ that sets a 
parameter $\ident{?param}$ to the value of $e_1$ and evaluates $e_2$ in a context containing 
$\ident{?param}$. 

The fact that implicit parameters support both lexical and dynamic scoping becomes interesting
when we consider nested functions. The following function does some pre-processing and then returns a 
function that builds a formatted string based on two implicit parameters $\ident{?width}$ and 
$\ident{?size}$:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{format} = \lambda \ident{str}~\rightarrow \\[-0.25em]
\quad \kvd{let}~\ident{lines} = \ident{formatLines}~\ident{str}~\ident{?width}~\kvd{in}\\[-0.25em]
\quad (\lambda \ident{rest}~\rightarrow~\ident{append}~
         \ident{lines}~\ident{rest}~\ident{?width}~\ident{?size})
\end{array}
\end{equation*}
%
The body of the outer function accesses the parameter $\ident{?width}$, so it certainly requires a context 
$\{ \ident{?width} : \ident{int} \}$. The nested function (returned as a result) uses the parameter 
$\ident{?width}$, but in addition also uses $\ident{?size}$. Where should the parameters used by the 
nested function come from?

To keep examples in this chapter uniform, we do not use the Haskell notation and instead
write $\tau_1 \xrightarrow{r} \tau_2$ for a function that requires implicit parameters specified $r$.
In a purely dynamically scoped system, they would have to be defined when the user invokes the nested function.
However, implicit parameters behave as a combination of lexical and dynamic scoping. This means
that the nested function can capture the value of $\ident{?width}$ and require just $\ident{?size}$.
The following shows the two options:
%
\begin{equation}
\tag{dynamic}
\ident{string} \xrightarrow{ \{ \ident{?width} : \ident{int} \} }
  (\ident{string} \xrightarrow{ \{ \ident{?width} : \ident{int}, \ident{?size} : \ident{int} \} } \ident{string})
\end{equation}
\vspace{-1em}
\begin{equation}
\tag{mixed}
\ident{string} \xrightarrow{ \{ \ident{?width} : \ident{int} \} }
  (\ident{string} \xrightarrow{ \{ \ident{?size} : \ident{int} \} } \ident{string})
\end{equation}
%
This is not a complete list of possible typings, but it demonstrates the options. The \emph{dynamic}
case requires the parameter \ident{?width} twice (this may be confusing when the caller provides
two different values). In the \emph{mixed} case, the nested function captures the \ident{?width} 
parameter available from the declaration site. As a result, the latter function can be called as follows:\
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{formatHello} = \\[-0.25em]
\quad(~\kvd{letdyn}~\ident{?width}=5~\kvd{in}~\ident{format}~\texttt{"Hello"})\\[-0.25em]
\kvd{in}\,(~\kvd{letdyn}~\ident{?size} = 10~\kvd{in}~\ident{formatHello}~\texttt{"world"}~)
\end{array}
\end{equation*}
%
For different typings of \ident{format}, different ways of calling it are valid. This illustrates
the point made in Section~\ref{sec:applications-structure-lam} -- flat coeffect systems may 
introduce certain non-determinism in the typing. The following section shows how this looks in the
type system for implicit parameters.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}
  {x : \tau \in \Gamma}
  {\coctx{\Gamma}{\aclrd{\emptyset}} \vdash x : \tau }
\end{equation*}
\begin{equation*}
\tyrule{param}
  {}
  {\coctx{\Gamma}{ \{\ident{?param}:\tau \} } \vdash \ident{?param} : \tau }
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{r'}} \vdash e : \tau }
  {\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau }\quad\quad(\aclrd{r'} \subseteq \aclrd{r})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{t}} \tau_2 &
   \coctx{\Gamma}{\aclrd{s}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\aclrd{r} \cup \aclrd{s} \cup \aclrd{t}} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 &
    \coctx{\Gamma, x:\tau_1}{\aclrd{s}} \vdash e_2 : \tau_2}
  {\coctx{\Gamma}{\aclrd{r \cup s}} \vdash \kvd{let}~x=e_1~\kvd{in}~e_2 : \tau_2 }
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\aclrd{r} \cup \aclrd{s}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{s}} \tau_2 }
\end{equation*}
\vspace{-0.9em}
\caption{Coeffect rules for tracking implicit parameters}
\label{fig:applications-flat-impl}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type system.}

Figure~\ref{fig:applications-flat-impl} shows a type system that tracks the set of expression's 
implicit parameters. The type system uses judgements of the form $\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau$
meaning that an expression $e$ has a type $\tau$ in a free-variable context $\Gamma$ with a set 
of implicit parameters specified by $\aclrd{r}$. The annotations $\aclrd{r},\aclrd{s},\aclrd{t}$ are sets of 
pairs consisting of implicit parameter names and types, \ie~$\aclrd{r},\aclrd{s},\aclrd{t} \subseteq 
  \ident{Names} \times \ident{Types}$. The expressions include \ident{?param} to read implicit
parameter and \kvd{letdyn} to bind an implicit parameter. The types are standard, but functions are
annotated with the set of implicit parameters that must be available on the call-site, \ie~
$\tau_1 \xrightarrow{\aclrd{s}} \tau_2$.

Accessing an ordinary variable (\emph{var}) does not require any implicit parameters. The rule that 
introduces primitive context requirements is (\emph{param}) -- accessing a parameter \ident{?param} 
of type $\tau$ requires it to be available in the context. The context may provide more (unused) 
implicit parameters thanks to the (\emph{sub}) rule.

When we read the rules from the top to the bottom, application (\emph{app}) and let binding 
(\emph{let}) simply union the context requirements of the sub-expressions. However, lambda abstraction
(\emph{abs}) is where the example differs from effect systems. The implicit parameters required by
the body $\aclrd{r} \cup \aclrd{s}$ can be freely split between the declaration-site ($\coctx{\Gamma}{\aclrd{r}}$)
and the call-site ($\tau_1 \xrightarrow{\aclrd{s}} \tau_2$).

The union operation $\cup$ is not a disjoint union, which means that the values for implicit 
parameters can also be provided by both sites. For example, consider a function with a body
$\ident{?a} + \ident{?b}$. Assuming that the function takes and returns $\ident{int}$, the following
list shows 4 out of 9 possible valid typing. Full typing derivations can be found in Appendix~?:
%
\begin{equation*}
\begin{array}{rcllllr}
\coctx{\Gamma}{\aclrd{ \{ \ident{?a}:\ident{int} \} }} &\vdash& \lambda x.\ident{?a} + \ident{?b} &:& 
  \ident{int} \xrightarrow{ \{ \ident{?b}:\ident{int} \} } \ident{int} &\qquad\qquad&(1) \\
\coctx{\Gamma}{\aclrd{ \{ \ident{?b}:\ident{int} \} }} &\vdash& \lambda x.\ident{?a} + \ident{?b} &:& 
  \ident{int} \xrightarrow{ \{ \ident{?a}:\ident{int} \} } \ident{int} &&(2)\\
\coctx{\Gamma}{\aclrd{ \{\ident{?a}:\ident{int} \} }} &\vdash& \lambda x.\ident{?a} + \ident{?b} &:& 
  \ident{int} \xrightarrow{ \{\ident{?a}:\ident{int}, \ident{?b}:\ident{int} \} } \ident{int} &&(3)\\
\coctx{\Gamma}{\aclrd{ \emptyset }} &\vdash& \lambda x.\ident{?a} + \ident{?b} &:& 
  \ident{int} \xrightarrow{ \{\ident{?a}:\ident{int}, \ident{?b}:\ident{int} \} } \ident{int} &&(4)
\end{array}
\end{equation*}
%
The first two examples demonstrate why the system does not have the principal typing property. 
Both ($1$) and ($2$) are valid typings and they may both be desirable in certain contexts where
the function is used. 

In ($3$), the parameter \ident{?a} has to be provided from both the declaration-site and call-site.
We describe system that supports dynamic rebinding, meaning that when the caller provides a 
value, it hides the value that may be available from the declaration-site. This means that 
$4$ is a more precise typing modelling the same situation. 

%---------------------------------------------------------------------------------------------------

\begin{figure}

{\small The semantics is defined inductively over the typing derivation:}
\begin{equation}
\tag{\emph{var}}
\sem{\coctx{\Gamma}{\aclrd{r}} \vdash x_i : \tau_i} = \lambda ((x_1, \ldots, x_n), \_) \rightarrow x_i
\end{equation}
\vspace{-1.5em}
\begin{equation}
\tag{\emph{param}}
\sem{\coctx{\Gamma}{\aclrd{r}} \vdash ?p : \sigma} = \lambda (\_, f) \rightarrow f~?p
\end{equation}
\vspace{-1.5em}
\begin{equation}
\tag{\emph{sub}}
\sem{\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau} = \lambda (x, f) \rightarrow 
  \sem{\coctx{\Gamma}{\aclrd{r'}} \vdash e : \tau}~(x, \restr{f}{\aclrd{r'}})
\end{equation}
\vspace{-1.5em}
\begin{equation}
\tag{\emph{abs}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{r}} \vdash \lambda y. e : \tau_1 \xrightarrow{\aclrd{s}} \tau_2 } = \lambda ((x_1, \ldots, x_n), f) \rightarrow\\[-0.25em]
  \qquad\lambda (y, g) \rightarrow \sem{ \coctx{\Gamma,y:\tau_1}{\aclrd{r}\cup\aclrd{s}} \vdash e : \tau_2 }~((x_1, \ldots, x_n, y), f \uplus g)   	 
\end{array}
\end{equation}
\vspace{-1.0em}
\begin{equation*}
\tag{\emph{app}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{r}\cup\aclrd{s}\cup\aclrd{t}} \vdash e_1~e_2 : \tau_2 } = \lambda (x, f) \rightarrow \\[-0.25em]
  \qquad\kvd{let}~g=\sem{ \coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{t}} \tau_2 }~(x, \restr{f}{\aclrd{r}})\\[-0.25em]
  \qquad\kvd{in}~g~(\sem{ \coctx{\Gamma}{\aclrd{s}} \vdash e_2 : \tau_1 }~(x, \restr{f}{\aclrd{s}} ), \restr{f}{\aclrd{t}})
\end{array}
\end{equation*}

\vspace{1em}
{\small Monadic semantics using the reader monads differs as follows:}
\begin{equation}
\tag{\emph{rdabs}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{r}} \vdash \lambda y. e : \tau_1 \xrightarrow{\aclrd{s}} \tau_2 } = \lambda ((x_1, \ldots, x_n), \_) \rightarrow\\[-0.25em]
  \qquad\lambda (y, g) \rightarrow \sem{ \coctx{\Gamma,y:\tau_1}{\aclrd{r}\cup\aclrd{s}} \vdash e : \tau_2 }~((x_1, \ldots, x_n, y), g)   	 
\end{array}
\end{equation}

\vspace{1em}
{\small Where $\uplus$ and $\restr{f}{\aclrd{r}}$ are auxiliary definitions:}
\begin{equation*}
\begin{array}{rcl}
\restr{f}{\aclrd{r}} &=& \{ (p,v) \;|\; (p,v) \in f, \;p \in \aclrd{r} \}\\[-0.25em]
f \uplus g &=& \restr{f}{\, \textit{dom}(f) \setminus \textit{dom}(g)} \cup g 
\end{array}
\end{equation*}


\caption{Semantics of a language with implicit parameters}
\label{fig:applications-flat-implsem}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Semantics.}
Implicit parameters can be implemented by passing around a hidden dictionary that provides values
to the implicit parameters. Accessing a parameter then becomes a lookup in the dictionary and
the \kvd{letdyn} construct extends the dictionary. To elucidate how such hidden dictionaries 
are propagated through the program when using lambda abstractions and applications, we present a 
simple semantics for implicit parameters. The goal here is not to prove properties of the language,
but simply to provide a better explanation. A detailed semantics in terms of indexed comonads is
shown in Chapter~\ref{ch:flat}.

For simplicity, we assume that all implicit parameters have the same type $\sigma$. In that setting, 
coeffect annotations $\aclrd{r}$ are just sets of names, \ie~$\aclrd{r}, \aclrd{s}, \aclrd{t} \subseteq \ident{Names}$.
Given an expression $e$ of type $\tau$ that requires free variables $\Gamma$ and implicit parameters 
$\aclrd{r}$, our interpretation is a function that takes a product of variables from $\Gamma$ together 
with a hidden dictionary of implicit parameters and returns $\tau$:
%
\begin{equation*}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \aclrd{r} } \vdash e : \tau} 
  ~:~ (\tau_1 \times \ldots \times \tau_n) \times (\aclrd{r} \rightarrow \sigma) \rightarrow \tau
\end{equation*}
%
The hidden dictionary is represented as a function from $\aclrd{r}$ to $\sigma$. This means that it 
provides a $\sigma$ value for all implicit parameters that are required according to the typing.
Note that the domain of the function is not the set of all possible implicit parameter names, but
only a set of those that are specified by the type system.

A hidden dictionary also needs to be attached to all functions. A function $\tau_1 \xrightarrow{\aclrd{s}} \tau_2$
is interpreted by a function that takes $\tau_1$ together with a dictionary that defines values for
implicit parameters in $\aclrd{s}$:
%
\begin{equation*}
\begin{array}{l}
\sem{\tau_1 \xrightarrow{\aclrd{s}} \tau_2} = \tau_1 \times (\aclrd{s} \rightarrow \sigma) \rightarrow \tau_2
\end{array}
\end{equation*}
%
The definition of the semantics is shown in Figure~\ref{fig:applications-flat-implsem}. Let binding
can be viewed as a syntactic sugar for $(\lambda x.e_2)~e_1$ and so it is omitted for brevity. The 
(\emph{var}) and (\emph{param}) rules are simple -- they project the appropriate variable and 
implicit parameter, respectively.

When an expression requires implicit parameters $\aclrd{r}$, the semantics always provides a 
dictionary defined \emph{exactly} on $\aclrd{r}$. To achieve this, the (\emph{sub}) rule restricts
the function to $\aclrd{r'}$ (which is valid because $\aclrd{r'} \subseteq \aclrd{r}$).

The most interesting rules are (\emph{abs}) and (\emph{app}). In abstraction, we get two dictionaries
$f$ and $g$ (from the declaration-site and call-site, respectively), which are combined and passed 
to the body of the function. The semantics prefers values from the call-site, which is captured by
the $\uplus$ operation. In application, we first evaluate the expression $e_1$, then $e_2$ and finally
call the returned function. The three calls use (possibly overlapping) restrictions of the dictionary
as required by the static types.

Without providing a proof here, we note that the semantics is sounds with respect to the type 
system -- when evaluating an expression, it provides it with a dictionary that is guaranteed to
contain values for all implicit parameters that may be accessed. This can be easily checked by
examining the semantic rules (and noting that the restriction and union always provide the
expected set of parameters).

\paragraph{Monadic semantics.}
Implicit parameters are related to the \emph{reader mo\-nad}. The type 
$\tau_1 \times (\aclrd{r} \rightarrow \sigma) \rightarrow \tau_2$ is equivalent to
$\tau_1 \rightarrow ((\aclrd{r} \rightarrow \sigma) \rightarrow \tau_2)$ through currying. Thus, we can
express the function as $\tau_1 \rightarrow M\tau_2$ for $M\tau = (\aclrd{r} \rightarrow \sigma) \rightarrow \tau$.
Indeed, the reader monad can be used to model dynamic scoping. However, there is an important distinction
from implicit parameters. The usual monadic semantics models fully dynamic scoping, while implicit
parameters combine lexical and dynamic scoping.

The (\emph{rdabs}) rule in Figure~\ref{fig:applications-flat-implsem} shows a semantics that
matches the usual monadic semantics using the reader monad. Note that the declaration-site dictionary
is ignored and the body is called with only the dictionary provided by the call-site. This is
a consequence of the fact that monadic functions are always pure values created using \emph{unit}.

As we discuss later in Section~3.?, the reader monad can be extended to model rebinding.
However, later examples in this chapter, such as liveness in Section~\ref{sec:applications-flat-live}
show that other context-aware computations cannot be captured by \emph{any} monad.

%---------------------------------------------------------------------------------------------------

\paragraph{Type classes.}
Another type of constraints in Haskell that is closely related to implicit parameters are 
\emph{type class} constraints \cite{app-type-classes}. They provide a principled form of ad-hoc
polymorphism (overloading). When a code uses an overloaded operation (e.g.~comparison or numeric 
operators) a constraint is placed on the context in which the operation is used. For example:
%
\begin{equation*}
\begin{array}{l}
\ident{twoTimes}~::~\ident{Num}~\alpha \Rightarrow \alpha \rightarrow \alpha \\[-0.25em]
\ident{twoTimes}~x=x+x
\end{array}
\end{equation*}
%
The constraint $\ident{Num}~\alpha$ on the function type arises from the use of the $+$ operator. 
Similarly to implicit parameters, type classes can be implemented using a hidden dictionary. In 
the above case, the function \ident{twoTimes} takes a hidden dictionary that provides an operation
$+$ of type $\alpha \times \alpha \rightarrow \alpha$.

Type classes could be modelled as a coeffect system. The type system would annotate the context
with a set of required type classes. The typing of the body of \ident{twoTimes} would look as 
follows:
%
\begin{equation*}
\coctx{x\!:\!\alpha}{ \{ \ident{Num}_\alpha \} } \vdash x + x : \alpha
\end{equation*}
%
Similarly, the semantics of a language with type class constraints can be defined in a way
similar to implicit parameters. The interpretation of the body is a function that takes $\alpha$
together with a hidden dictionary of operations: $\alpha \times \ident{Num}_\alpha \rightarrow \alpha$.

Type classes and implicit parameters show two important points about flat coeffect systems.
First, the context requirements are associated with some \emph{scope}, such as the body
of a function. Second, they are associated with the input. To call a function that takes an 
implicit parameter or has a type-class constraint, the caller needs to pass a (hidden) parameter
together with the function inputs.

\paragraph{Summary.}
Implicit parameters are the simplest example of a system where function abstraction does not 
delay all impurities of the body. As discussed in Section~\ref{sec:applications-structure-lam},
this is the defining feature of \emph{coeffect} systems. 

In this section, we have seen how this affects both the type system and the semantics of the 
language. In the type system, the (\emph{abs}) rule places context-requirements on both the 
declaration-site and the call-site. For implicit parameters, this rule introduces non-determinism,
because the parameters can be split arbitrarily. However, as we show in the next section, this is 
not always the case. Semantically, lambda abstraction \emph{merges} two parts of context (implicit 
parameter dictionaries) that are provided by the call-site and declaration-site. 

%---------------------------------------------------------------------------------------------------

\subsection{Distributed computing}
\label{sec:applications-flat-distr}

Distributed programming was used as one of the motivating examples for coeffects in 
Chapter~\ref{ch:intro}. This section explores the use case. We look at rebindable resources and
cross-compilation. The structure of both is very similar to implicit parameters and type
class constraints, but they demonstrate that there is a broader use for coeffect systems.

% --------------------------------------------------------------------------------------------------

\paragraph{Rebindable resources.}

The need for parameters that support dynamic scoping also arises in distributed computing.
To quote an example discussed by Bierman et al. \cite{app-distributed-rebinding}: \emph{``Dynamic 
binding is required in various guises, for example when a marshalled value is received from the 
network, containing identifiers that must be rebound to local resources.''} 

Rebindable parameters are identifiers that refer to some specific resource. When a function value
is marshalled and sent to another machine, rebindable resources can be handled in two ways. 
First, if the resource is available on the target machine, the parameter is \emph{rebound} to
the resource on the new machine. This is captured by dynamic scoping rules. Second, if the 
resource is not available on the target machine, the resource is either marshalled or a \emph{remote 
reference} is created. This is captured by lexical scoping rules.

A practical language that supports rebindable resources is for example Acute \cite{app-distributed-acute}.
In the following example, we use the construct $\kvd{access}~\ident{Res}$ to represent
access to a rebindable resource named $\ident{Res}$. The following simple function accessed
a database and a current date and filters values based on the date:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{recentEvents} = \lambda () \rightarrow\\[-0.25em]
\quad\kvd{let}~\ident{db} = \kvd{access}~\ident{News}~\kvd{in}\\[-0.25em]
\quad\ident{query}~\ident{db}~\str{SELECT * WHERE Date > \%1}~(\kvd{access}~\ident{Clock})
\end{array}
\end{equation*}
%
When \ident{recentEvents} is created on the server and sent to the client, a remote reference to 
the database (available only on the server) must be captured. If the client device supports a 
clock, then \ident{Clock} can be locally \emph{rebound}, e.g., to accommodate time-zone changes. 
Otherwise, the date and time needs to be obtained from the server too.

The type system and semantics for rebindable resources are essentially the same as those for
implicit parameters. Primitive requirements are introduced by the $\kvd{access}$ keyword. 
Lambda abstraction splits the resources non-deterministically between declaration-site 
(capturing remote reference) and call-site (representing rebinding). For this reason, we do not
discuss the system in details and instead look at other uses.

%---------------------------------------------------------------------------------------------------

\begin{figure}
\begin{equation*}
\begin{array}{l}
\cmt{// Checks that input is valid; can run on both server and client}\\[-0.25em]
\kvd{let}~\ident{validateInput} = \lambda \ident{name} \rightarrow\\[-0.25em]
\quad\ident{name} \neq \str{} ~~\&\&~~ \ident{forall~isLetter~name}
\\[0.5em]
\cmt{// Searches database for a product; can run on the server-side}\\[-0.25em]
\kvd{let}~\ident{retrieveProduct} = \lambda \ident{name} \rightarrow\\[-0.25em]
\quad\kvd{if}~\ident{validateInput name}~\kvd{then}~\ident{Some}(\ident{queryProductDb~name})\\[-0.25em]
\quad\kvd{else}~\ident{None}
\\[0.5em]
\cmt{// Client-side function to show price or error (for invalid inputs)}\\[-0.25em]
\kvd{let}~\ident{showPrice} = \lambda \ident{name} \rightarrow\\[-0.25em]
\quad\kvd{if}~\ident{validateInput name}~\kvd{then}\\[-0.25em]
\quad\quad\kvd{match}~(\kvd{remote}~\ident{retrieveProduct}())~\kvd{with}\\[-0.25em]
\quad\quad|~\ident{Some}~\ident{p} \rightarrow \ident{showPrice}~(\ident{getPrice}~\ident{p})\\[-0.25em]
\quad\quad|~\ident{None}~\rightarrow \ident{showError}~\str{Invalid input on the server}\\[-0.25em]
\quad\kvd{else}~\ident{showError}~\str{Invalid input on the client}
\end{array}
\end{equation*}

\vspace{1em}
\noindent\makebox[\linewidth]{\rule{\textwidth}{0.5pt}} 
\vspace{-1.5em}
\caption{Sample client-server application with input validation}
\label{fig:applications-flat-distr}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Cross-compilation.}
A related issue with distributed programming is the need to target increasing number of diverse
platforms. Modern applications often need to run on multiple platforms (iOS, Android, Windows or
as JavaScript) or multiple versions of the same platform. Many programming languages are capable
of targeting multiple different platforms. For example, functional languages that can be compiled 
to native code and JavaScript include, among others, F\#, Haskell and OCaml \cite{app-ocaml-js}.

Links \cite{app-distributed-links}, F\# WebTools and WebSharper \cite{app-fsharp-webapps,app-fsharp-webtools},
ML5 and QWeSST \cite{app-distributed-ml5, app-distributed-qwesst} and Hop \cite{app-hop-lang} go 
further and allow including code for multiple distinct platforms in a single source file. 
A single program is then automatically split and compiled to multiple target runtimes. This
posses additional challenges -- it is necessary to check where each part of the program can run
and statically guarantee that it will be possible to compile code to the required target 
platform (safe \emph{multi-targetting}).

We demonstrate the problem by looking at input validation. In applications that communicate over 
unsecured HTTP channel, user input needs to be validated interactively on the client-side (to 
provide immediate response) and then again on the server-side (to guarantee safety). 

Consider the client-server example in Figure~\ref{fig:applications-flat-distr}. The 
\ident{retrieveProduct} function represents the server-side, while \ident{showPrice} is called 
on the client-side and performs a remote call to the server-side function (how this is implemented 
is not our concern here). To ensure that the input is valid \emph{both} functions call 
\ident{validateInput} -- however, this is fine, because \ident{validateInput} uses only basic
functions and language features that can be cross-compiled to both client-side and server-side.

In Links \cite{app-distributed-links}, functions can be annotated as client-side, server-side
and database-side. F\# WebTools \cite{app-fsharp-webtools} supports cross-compiled (mixed-side)
functions similar to \ident{validateInput}. However, these are single-purpose language features 
and they are not extensible. A practical implementation needs to be able to capture multiple
different patterns -- sets of environments (client, server, mobile) for distributed computing,
but also Android API level \cite{app-android-multitarget} to cross-compile for multiple versions 
of the same platform.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]

{\small a.) Set based type system for cross-compilation, inspired by Links \cite{app-distributed-links}}

\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{r'}} \vdash e : \tau }
  {\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau }\quad\quad(\aclrd{r'} \supseteq \aclrd{r})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{t}} \tau_2 &
   \coctx{\Gamma}{\aclrd{s}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\aclrd{r} \cap \aclrd{s} \cap \aclrd{t}} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\aclrd{r} \cup \aclrd{s}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{s}} \tau_2 }
\end{equation*}
\vspace{0.5em}

{\small b.) Version number based type system, inspired by Android API level \cite{app-android-multitarget}}

\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{r'}} \vdash e : \tau }
  {\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau }\quad\quad(\aclrd{r'} \leq \aclrd{r})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{t}} \tau_2 &
   \coctx{\Gamma}{\aclrd{s}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\ident{max} \{\aclrd{r}, \aclrd{s}, \aclrd{t} \}} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\aclrd{r}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{r}} \tau_2 }
\end{equation*}

\caption{Two variants of coeffect typing rules for cross-compilation}
\label{fig:applications-flat-cross}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type systems.}

Cross-compilation may seem similar to the tracking of resources (and thus to the tracking of implicit 
parameters), but it actually demonstrates a couple of new ideas that are important for flat coeffect 
systems. Unlike with implicit parameters, we will not present a specific existing system in this 
section -- instead we briefly look at two examples that let us explore the range of possibilities. 

In the first system, shown in Figure~\ref{fig:applications-flat-cross} (a), the coeffect annotations
are sets of execution environments, \ie~$\aclrd{r}, \aclrd{s}, \aclrd{t} \subseteq \{ \ident{client},
\ident{server}, \ident{database} \}$. Sub-coeffecting (\emph{sub}) lets us ignore some of the supported 
execution environments; application (\emph{app}) can be only executed in the \emph{intersection} of the
environments required by the two expressions and the function value.

Sub-coeffecting and application are trivially dual to the rules for implicit parameters. We just track
supported environments using intersection as opposed to tracking of required parameters using union.
However, this symmetry does not hold for lambda abstraction (\emph{abs}), which still uses \emph{union}.
This models the case where the function can be executed in two different ways:
%
\begin{itemize}
\item[--] The function is represented as executable code for an environment available at the call-site
  and is executed there, possibly after it is marshalled and transferred to another machine.
\vspace{-0.5em}
\item[--] The function body is compiled for the environment available at the declaration-site; the value
  that is returned is a remote reference to the code and function calls are performed as remote invocations.
\end{itemize}
%
This example ignores important considerations -- for example, it is likely desirable to make this
difference explicit and the implementation (and semantics) needs to be clarified. However, the
example shows that the algebraic structure of coeffect annotations may be more complex. Here, using
$\cap$ for application and $\cup$ for abstraction.

The second system, shown in Figure~\ref{fig:applications-flat-cross} (b) is inspired by the API
level requirements in Android. Coeffect annotations are simply numbers representing the level
($\aclrd{r}, \aclrd{s}, \aclrd{t} \in \mathbb{N}$). Levels are ordered increasingly, so we can
always require higher level (\emph{sub}). The requirement on function application (\emph{app}) is
the highest level of the levels required by the sub-expressions and the function. The system uses 
yet another variant of lambda abstraction (\emph{abs}) -- the requirements of the body are duplicated
and placed on \emph{both} the declaration-site and the call-site.

In addition to the work discussed already, ML5 \cite{app-distributed-ml5} is another important work 
that looks at tracking of execution environments. It uses modalities of modal S4 to represent the 
environment -- this approach is similar to coeffects, both from the practical perspective, but also 
through deeper theoretical links. We return to this topic in Chapter~\ref{ch:meta}.

% --------------------------------------------------------------------------------------------------

\subsection{Liveness analysis}
\label{sec:applications-flat-live}

\emph{Live variable analysis} (LVA) \cite{app-modern-compiler} is a standard technique in compiler 
theory. It detects whether a free variable of an expression may be used by a program during its
evaluation (it is \emph{live}) or whether it is definitely not needed (it is \emph{dead}). As an 
optimization, compiler can remove bindings to dead variables as they are never accessed. Wadler 
\cite{app-strictness-absecnce} describes the property of a variable that is dead as the 
\emph{absence} of a variable. 

\paragraph{Flat liveness analysis.}
In this section, we discuss a restricted form of liveness analysis. We do not track liveness of 
\emph{individual} variables, but of the \emph{entire} variable context. This is not practically
useful, but it provides interesting insight into how flat coeffects work. A per-variable liveness
analysis can be captured using structural coeffects and is discussed in Section~\ref{sec:applications-struct-live}.
Consider the following two examples:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{constant42} = \lambda \ident{x} \rightarrow 42\\
\kvd{let}~\ident{constant} = \lambda \ident{value} \rightarrow \lambda \ident{x} \rightarrow \ident{value}
\end{array}
\end{equation*}
%
The body of the first function is just a constant $42$ and so the context of the body is marked
as \emph{dead}. The parameter (call-site) of the function is not used and can also be marked as dead. 
Similarly, no variables from the declaration-site are used and so they are also marked as dead.

In contrast, the body of the second function accesses a variable \ident{value} and so the body 
of the function is marked as \emph{live}. In the flat system, we do not track \emph{which} 
variable was used and so we have to mark both the call-site and declaration-site as live (this will
be refined in structural liveness system).

\paragraph{Forward vs. backward \& may vs. must.}
Static analyses can be classified as either \emph{forward} or \emph{backward} (depending on how they 
propagate information) and as either \emph{must} or \emph{may} (depending on what properties they
guarantee). Liveness is a \emph{backward} analysis -- the requirements are propagated from variables 
to their declarations. The distinction between \emph{must} and \emph{may} is apparent when we look 
at an example with conditionals:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{defaultArg}~= \lambda \ident{cond} \rightarrow \lambda \ident{input} \rightarrow\\
\quad\kvd{if}~\ident{cond}~\kvd{then}~42~\kvd{else}~\ident{input}
\end{array}
\end{equation*}
%
Liveness analysis is a \emph{may} analysis meaning that it marks variable as live when it
\emph{may} be used and as dead if it is \emph{definitely} not used. This means that the variable
\ident{input} is \emph{live} in the example above. A \emph{must} analysis would mark the variable
only if it was used in both of the branches (this is sometimes called \emph{neededness}).

The distinction between \emph{may} and \emph{must} analyses demonstrates the importance of 
interaction between contextual properties and certain language constructs such as conditionals.
We discuss this in Section~\ref{sec:flat-conditionals}

% --------------------------------------------------------------------------------------------------

\begin{figure}
{\small a.) The operations of a two-point lattice $\mathcal{L} = \{\ident{L}, \ident{D}\}$ 
where $\ident{D} \sqsubseteq \ident{L}$ are defined as:}
%
\begin{equation*}
\begin{array}{rcl}
\ident{L} \sqcup \ident{L} &=& \ident{L}\\
\ident{D} \sqcup \ident{L} &=& \ident{D}\\
\end{array}
\qquad
\begin{array}{rcl}
\ident{L} \sqcup \ident{D} &=& \ident{D}\\
\ident{D} \sqcup \ident{D} &=& \ident{D}
\end{array}
\qquad
\begin{array}{rcl}
\ident{L} \sqcap \ident{L} &=& \ident{L}\\
\ident{D} \sqcap \ident{L} &=& \ident{L}\\
\end{array}
\qquad
\begin{array}{rcl}
\ident{L} \sqcap \ident{D} &=& \ident{L}\\
\ident{D} \sqcap \ident{D} &=& \ident{D}
\end{array}
\end{equation*}

{\small b.) Sequential composition of (semantic) functions composes annotations using $\sqcup$:}
\begin{equation*}
\begin{array}{llll}
f : \tau_1 \xrightarrow{\aclrd{r}} \tau_2 \qquad\qquad&
g : \tau_2 \xrightarrow{\aclrd{s}} \tau_3 \qquad\qquad&
g \circ f : \tau_1 \xrightarrow{\aclrd{r} \sqcup \aclrd{s}} \tau_3 \qquad\qquad& ~
\\[0.75em]
f : \tau_1 \xrightarrow{\aclrd{\ident{L}}} \tau_2 &
g : \tau_2 \xrightarrow{\aclrd{\ident{L}}} \tau_3 &
g \circ f : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_3 & (1)
\\[-0.10em]
f : \tau_1 \xrightarrow{\aclrd{\ident{D}}} \tau_2 &
g : \tau_2 \xrightarrow{\aclrd{\ident{L}}} \tau_3 &
g \circ f : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_3 & (2)
\\[-0.10em]
f : \tau_1 \xrightarrow{\aclrd{\ident{L}}} \tau_2 &
g : \tau_2 \xrightarrow{\aclrd{\ident{D}}} \tau_3 &
g \circ f : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_3 & (3)
\\[-0.10em]
f : \tau_1 \xrightarrow{\aclrd{\ident{D}}} \tau_2 &
g : \tau_2 \xrightarrow{\aclrd{\ident{D}}} \tau_3 &
g \circ f : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_3 & (4)
\end{array}
\end{equation*}

{\small c.) Pointwise composition of (semantic) functions composes annotations using $\sqcap$:}
\begin{equation*}
\begin{array}{llll}
f : \tau_1 \xrightarrow{\aclrd{r}} \tau_2 \qquad\qquad&
h : \tau_1 \xrightarrow{\aclrd{s}} \tau_3 \qquad\qquad&
\langle f, h \rangle : \tau_1 \xrightarrow{\aclrd{r} \sqcap \aclrd{s}} \tau_2 \times \tau_3 \qquad&~
\\[0.75em]
f : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_2 &
h : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_3 &
\langle f, h \rangle : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_2 \times \tau_3 & (1)
\\[-0.10em]
f : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_2 &
h : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_3 &
\langle f, h \rangle : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_2 \times \tau_3 & (2)
\\[-0.10em]
f : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_2 &
h : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_3 &
\langle f, h \rangle : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_2 \times \tau_3 & (3)
\\[-0.10em]
f : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_2 &
h : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_3 &
\langle f, h \rangle : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_2 \times \tau_3 & (4)
\end{array}
\end{equation*}

\caption{Liveness annotations with sequential and pointwise composition}
\label{fig:applications-flat-livealg}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type system.}
A type system that captures whole-context liveness annotates the context with value of a 
two-point lattice $\mathcal{L} = \{ \ident{L}, \ident{D} \}$. The annotation \ident{L} marks
the context as \emph{live} and \ident{D} stands for a \emph{dead} context. 
Figure~\ref{fig:applications-flat-livealg} (a) defines the ordering $\sqsubseteq$, meet $\sqcup$ and join 
operations $\sqcap$ of the lattice.

The typing rules for tracking whole-context liveness are shown in Figure~\ref{fig:applications-flat-liveness}.
The language now includes constants $c:\tau \in \Delta$. Accessing a constant (\emph{const}) annotates
the context as dead using \ident{D}. This contrasts with variable access (\emph{var}), which marks the
context as live using \ident{L}. A dead context (definitely not needed) can be treated as live context
(which may be used) using the (\emph{sub}) rule. This captures the \emph{may} nature of the analysis.

The (\emph{app}) rule is best understood by discussing its semantics. The semantics uses 
\emph{sequential composition} to compose the semantics of $e_2$ with the function obtained
as the result of $e_1$. However, we need more than just sequential composition. The same input
context is passed to the expression $e_1$ (in order to get the function value) and to the
sequentially composed function (to evaluate $e_2$ followed by the function call). This is captured 
by \emph{pointwise composition}.


Consider first \emph{sequential composition} of (semantic) functions $f, g$ annotated with 
$\aclrd{r}, \aclrd{s}$. The composed function $g \circ f$ is annotated with $\aclrd{r} \sqcup \aclrd{s}$
as shown in Figure~\ref{fig:applications-flat-livealg} (b).
The argument of the function $g \circ f$ is live only when the arguments of both $f$ and $g$ are 
live ($1$). When the argument of $f$ is dead, but $g$ requires $\tau_2$ ($2$), we can evaluate 
$f$ without any input and obtain $\tau_2$, which is then passed to $g$. When $g$ does not require
its argument ($3, 4$), we can just evaluate $g$, without evaluating $f$. Here, the semantics
\emph{implements} the dead code elimination optimization.

Secondly, a \emph{pointwise composition} passes the same argument to $f$ and $h$. The parameter 
is live if either the parameter of $f$ or $h$ is live. The pointwise composition is written as
$\langle f, h \rangle$ and it combines annotations using $\sqcap$ as shown in Figure~\ref{fig:applications-flat-livealg} (c).
Here, the argument is not needed only when both $f$ and $h$ do not need it ($1$). In all other cases,
the parameter is needed and is then used either once ($2,3$) or twice ($4$). The rule for function
application (\emph{app}) combines the two operations. The context $\Gamma$ is live if it is needed by
$e_1$ (which always needs to be evaluated) \emph{or} when it is needed by the function value \emph{and}
by $e_2$. 

The (\emph{abs}) rule duplicates the annotation of the body, similarly to the cross-compilation 
example in Figure~\ref{fig:applications-flat-cross}. When the body accesses any variables, it 
requires both the argument and the variables from declaration-site. When it does not use any variables,
it marks both as dead. Finally, the (\emph{let}) rule annotates the composed expression with the
liveness of the expression $e_2$ -- if the context of $e_2$ is live, then it also requires variables
from $\Gamma$; if it is dead, then it does not require $\Gamma$ or $x$. 
As further discussed later in Section~?, the (\emph{let}) rule is again just a syntactic sugar for 
$(\lambda x.e_2)~e_1$. Briefly, this follows from the simple observation that 
$\aclrd{r} \sqcup (\aclrd{s} \sqcap \aclrd{r}) = \aclrd{r}$.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}
  {x : \tau \in \Gamma}
  {\coctx{\Gamma}{\aclrd{\ident{L} }} \vdash x : \tau }
\end{equation*}
\begin{equation*}
\tyrule{const}
  {c : \tau \in \Delta}
  {\coctx{\Gamma}{ \aclrd{\ident{D}} } \vdash c : \tau }
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{r'}} \vdash e : \tau }
  {\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau }\quad\quad(\aclrd{r'} \sqsubseteq \aclrd{r})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{t}} \tau_2 &
   \coctx{\Gamma}{\aclrd{s}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\aclrd{r} \sqcup (\aclrd{s} \sqcap \aclrd{t})} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 &
    \coctx{\Gamma, x:\tau_1}{\aclrd{s}} \vdash e_2 : \tau_2}
  {\coctx{\Gamma}{\aclrd{s}} \vdash \kvd{let}~x=e_1~\kvd{in}~e_2 : \tau_2 }
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\aclrd{r}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{r}} \tau_2 }
\end{equation*}
\vspace{-0.9em}

\caption{Coeffect rules for tracking whole-context liveness}
\label{fig:applications-flat-liveness}
\vspace{-1.2em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Examples.}
Before looking at the semantics, we consider a number of simple examples to demonstrate the
key aspects of the system. Full typing derivations are shown in Appendix~?:
%
\begin{equation*}
\begin{array}{lll}
(\lambda x \rightarrow 42)~y &~\hspace{1em}~&(1)\\
\ident{twoTimes}~42          &&(2)\\
(\lambda x \rightarrow x)~42 &&(3)\\
\end{array}
\end{equation*}
%
In the first case, the context is dead. In ($1$), the function's parameter is dead and so the
overall context is dead, even though the argument uses a variable $y$ -- the semantics evaluates 
the function without passing it an actual argument. In the second case ($2$), the function is
a variable that needs to be obtained and so the context is live. In the last case ($3$), the 
function accesses a variable and so its declaration-site is marked as requiring the context 
(\emph{abs}). This is where structural coeffect analysis would be more precise -- the system shown
here cannot capture the fact that $x$ is a bound variable.

%---------------------------------------------------------------------------------------------------

\begin{figure}
\begin{equation}
\tag{\emph{var}}
\sem{\coctx{\Gamma}{\aclrd{ \ident{L} }} \vdash x_i : \tau_i} = \lambda (x_1, \ldots, x_n) \rightarrow x_i
\end{equation}
\vspace{-1.75em}
\begin{equation}
\tag{\emph{const}}
\sem{\coctx{\Gamma}{\aclrd{ \ident{D} }} \vdash c_i : \tau_i} = \lambda () \rightarrow \delta(c_i)
\end{equation}
%
%
\vspace{-0.5em}
%
%
\begin{equation}
\tag{\emph{sub-1}}
\sem{\coctx{\Gamma}{\aclrd{\ident{L} }} \vdash e : \tau} = \lambda x \rightarrow 
  \sem{\coctx{\Gamma}{\aclrd{\ident{D} }} \vdash e : \tau}~()
\end{equation}
\vspace{-1.75em}
\begin{equation}
\tag{\emph{sub-2}}
\sem{\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau} = \lambda x \rightarrow 
  \sem{\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau}~x
\end{equation}
%
%
\vspace{-0.5em}
%
%
\begin{equation}
\tag{\emph{abs-1}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{\ident{L}}} \vdash \lambda y. e : \tau_1 \xrightarrow{\aclrd{\ident{L}}} \tau_2 } = \lambda (x_1, \ldots, x_n) \rightarrow\\[-0.25em]
  \qquad\lambda y \rightarrow \sem{ \coctx{\Gamma,y:\tau_1}{\aclrd{\ident{L}}} \vdash e : \tau_2 }~(x_1, \ldots, x_n, y)   	 
\end{array}
\end{equation}
\vspace{-1.0em}
\begin{equation}
\tag{\emph{abs-2}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{\ident{D}}} \vdash \lambda y. e : \tau_1 \xrightarrow{\aclrd{\ident{D}}} \tau_2 } = \lambda () \rightarrow\\[-0.25em]
  \qquad\lambda () \rightarrow \sem{ \coctx{\Gamma,y:\tau_1}{\aclrd{\ident{D}}} \vdash e : \tau_2 }~()
\end{array}
\end{equation}
%
%
\vspace{0.0em}
%
%
%
\begin{equation*}
\tag{\emph{app-1}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{r}} \vdash e_1~e_2 : \tau_2 } = \lambda x \rightarrow \\[-0.25em]
  \qquad\kvd{let}~g=\sem{ \coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_2 }~x
    ~\kvd{in}~g~()
\end{array}
\end{equation*}
\vspace{-1.0em}
\begin{equation*}
\tag{\emph{app-2}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{\ident{L}}} \vdash e_1~e_2 : \tau_2 } = \lambda x \rightarrow \\[-0.25em]
  \qquad\kvd{let}~g=\sem{ \coctx{\Gamma}{\aclrd{ \ident{L} }} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_2 }~x
    ~\kvd{in}~g~(\sem{ \coctx{\Gamma}{\aclrd{ \ident{D} }} \vdash e_2 : \tau_1 }~())
\end{array}
\end{equation*}
\vspace{-1.0em}
\begin{equation*}
\tag{\emph{app-3}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{r} \sqcup (\aclrd{s} \sqcap \aclrd{t}) } \vdash e_1~e_2 : \tau_2 } = \lambda x \rightarrow \\[-0.25em]
  \qquad\kvd{let}~g=\sem{ \coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{t}} \tau_2 }~x
    ~\kvd{in}~g~(\sem{ \coctx{\Gamma}{\aclrd{s}} \vdash e_2 : \tau_1 }~x)
\end{array}
\end{equation*}

\caption{Semantics of a language with liveness analysis}
\label{fig:applications-flat-livsem}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Semantics.} 
The type system presented above requires the semantics to \emph{implement} dead code elimination.
This means that when a function does not require an input (it is marked as dead), the semantics
does not evaluate the argument and passes an empty value as the input instead.

We can represent such empty values using the option type (known as \ident{Maybe} in Haskell).
We use the notation $\tau + 1$ to denote option types. Given a context with variables $x_i$ of
type $\tau_i$, the semantics is a function taking $(\tau_1 \times \ldots \times \tau_n) + 1$.
When the context is live, it will be called with the left value (product of variable assignments);
when the context is dead, it will be called with the right value (containing no information).

However, ordinary option type is not sufficient. We need to capture the fact that the 
representation depends on the annotation -- in other words, the type is \emph{indexed} by 
the coeffect annotation. The indexing is discussed in details in Section~X. For now, it suffices
to define the semantics using two separate rules:
%
\begin{equation*}
\begin{array}{rlrcl}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \aclrd{\ident{L}} } \vdash e : \tau} 
  &:& (\tau_1 \times \ldots \times \tau_n) &\narrow{\rightarrow}& \tau\\
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \aclrd{\ident{D}} } \vdash e : \tau} 
  &:& 1 &\narrow{\rightarrow}& \tau
\end{array}
\end{equation*}
%
The semantics of functions is defined similarly. When the argument of a function is live, the function 
takes the input value; when the argument is dead, the semantic function takes a unit as its argument:
%
\begin{equation*}
\begin{array}{l}
\sem{\tau_1 \xrightarrow{\aclrd{\ident{L}}} \tau_2} = \tau_1 \rightarrow \tau_2\\
\sem{\tau_1 \xrightarrow{\aclrd{\ident{D}}} \tau_2} = 1 \rightarrow \tau_2
\end{array}
\end{equation*}
%
Unlike with implicit parameters, the coeffect system for liveness tracking cannot be modelled 
using monads. Any monadic semantics would express functions as $\tau_1 \rightarrow M\, \tau_2$.
Unless laziness is already built-in in the semantics, there is no way to call such function without
first obtaining a value $\tau_1$. The above semantics makes this possible by taking a unit $1$ when
the argument is not live.

In Figure~\ref{fig:applications-flat-livsem}, we define the semantics directly. We write $()$ for
the only value of type $1$. This appears, for example, in (\emph{const}) which takes $()$ as the
input and returns constant using a global dictionary $\delta$. In (\emph{var}), the context is live
and so the semantics performs a projection. Sub-coeffecting is captured by two rules. A dead context 
can be treated as live using (\emph{abs-1}); in other cases, the annotation is not changed (\emph{abs-2}).

Lambda abstraction can be annotated in just two ways. When the body requires context (\emph{abs-1}),
the value of a bound variable $y$ is added to the context $\Gamma$ before passing it to the body.
When the body does not require context (\emph{abs-2}), it is called with $()$ as the input.

For application, there are 8 possible combinations of annotations. The semantics of some of them
is the same, so we only need to show 3 cases. The rules should be read as ML-style pattern matching,
where the last rule handles all cases not covered by the first two. In (\emph{app-1}), we handle the
case when the function $g$ does not require its argument -- $e_2$ is not used and instead, the function
is called with $()$ as the argument. The case (\emph{app-2}) covers the case when the expression
$e_1$ does not require a context, but $e_1$ does. Finally, in (\emph{app-3}), the same input
(which may be either tuple of variables or unit) is propagated uniformly to both $e_1$ and $e_2$.

\paragraph{Summary.}
Unlike with implicit parameters, the lambda abstraction for liveness analysis does not introduce 
non-determinism. It simply duplicates the context requirements. However, this still matches the
property of coeffects that impurities cannot be thunked.

The semantics of liveness reveals a number of interesting properties too. Firstly, the semantics
cannot be captured by any monad. Secondly, the system would not work without the coeffect annotations. 
The shape of the semantic function depends on the annotation (the input is either $1$ or $\tau$) and 
is \emph{indexed} by the annotation. Finally, we discussed at length how the semantics of application
arises from \emph{sequential} and \emph{pointwise} composition. This is another important aspect of
coeffect systems -- categorical semantics typically builds on \emph{sequential} composition, but to
model full $\lambda$ calculus it needs more. For coeffect systems, we need \emph{pointwise} composition
where the same context is shared by multiple sub-expressions.

% --------------------------------------------------------------------------------------------------

\subsection{Data-flow languages}
The Section~\ref{sec:intro-why-array} briefly demonstrated that we can treat array access as an 
operation that accesses a context. In case of arrays, the context is neighbourhood of a current
location in the array specified by a cursor. In this section, we make the example more concrete,
using a simpler and better studied programming model, data-flow languages.

Lucid \cite{app-lucid} is a declarative data-flow language designed by Wadge and Ashcroft. In Lucid, 
variables represent streams and programs are written as transformations over streams. A function 
application $\ident{square}(x)$ represents a stream of squares calculated from the stream of values $x$.

The data-flow approach has been successfully used in domains such as development of real-time embedded 
application where many \emph{synchronous languages} \cite{app-synchronous-lang} build on the data-flow
paradigm. The following example is inspired by the Lustre \cite{app-synchronous-lustre} language
and implements program to count the number of edges on a Boolean stream:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{edge} = \ident{false}~\kvd{fby}~(\ident{input}~\&\&~\ident{not}~(\kvd{prev}~\ident{input}))
\\[0.5em]
\kvd{let}~\ident{edgeCount} = \\[-0.25em]
\quad 0~\kvd{fby}~ (~\kvd{if}~\ident{edge}~\kvd{then}~1 + (\kvd{prev}~\ident{edgeCount})\\[-0.25em]
\quad\quad\quad~~~\, \kvd{else}~\kvd{prev}~\ident{edgeCount} ~)
\end{array}
\end{equation*}
%
The construct $\kvd{prev}~x$ returns a stream consisting of previous values of the stream 
$x$. The second value of $\kvd{prev}~x$ is first value of $x$ (and the first
value is undefined). The construct $y~\kvd{fby}~x$ returns a stream whose first element is the 
first element of $y$ and the remaining elements are values of $x$. Note that in Lucid, the constants
such as \ident{false} and $0$ are constant streams. Formally, the constructs are defined as follows
(writing $x_n$ for $n$-th element of a stream $x$):
%
\[ 
(\kvd{prev}~x)_n = \left\{ 
  \begin{array}{ll}
    nil     & \; \text{if $n=0$}\\
    x_{n-1} & \; \text{if $n>0$}
  \end{array} \right.
\quad
(y~\kvd{fby}~x)_n = \left\{ 
  \begin{array}{ll}
    y_0     & \; \text{if $n=0$}\\
    x_n     & \; \text{if $n>0$}
  \end{array} \right.
\]  
%
When reading data-flow programs, we do not need to think about variables in terms of streams --
we can see them as simple values. Most of the operations perform calculation just on the 
\emph{current} value of the stream. However, the operation \kvd{fby} and \kvd{prev} are different.
They require additional \emph{context} which provides past values of variables
(for \kvd{prev}) and information about the current location in the stream (for \kvd{fby}). 

The semantics of Lucid-like languages can be captured using a number of mathematical 
structures. Wadge \cite{app-lucid-monads} originally proposed to use monads, while Uustalu and 
Vene later used comonads \cite{app-dataflow-essence}. In Chapter~\ref{ch:flat}, we extend
the latter approach. However, the present chapter presents a sketch of a data-flow semantics
defined directly on streams.

In the introductory example with array access patterns, we used coeffects to track the range
of values accessed. In this section, we look at a simpler example -- we only consider the
\kvd{prev} operation and track the maximal number of \emph{past values} needed. This is an 
important information for efficient implementation of data-flow languages. When we can guarantee
that at most $x$ past values are accessed, the values can be stored in a pre-allocated buffer
rather than using \eg~on-demand computed lazy streams.


% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}
  {x : \tau \in \Gamma}
  {\coctx{\Gamma}{\aclrd{ 0 }} \vdash x : \tau }
\end{equation*}
\begin{equation*}
\tyrule{prev}
  {\coctx{\Gamma}{ \aclrd{n} } \vdash e : \tau}
  {\coctx{\Gamma}{ \aclrd{n}+1} \vdash \kvd{prev}~e : \tau}
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{n'}} \vdash e : \tau }
  {\coctx{\Gamma}{\aclrd{n}} \vdash e : \tau }\quad\quad(\aclrd{n'} \leq \aclrd{n})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\aclrd{m}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{p}} \tau_2 &
   \coctx{\Gamma}{\aclrd{n}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\textnormal{max}(\aclrd{m}, \aclrd{n} + \aclrd{p})} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma}{\aclrd{m}} \vdash e_1 : \tau_1 &
    \coctx{\Gamma, x:\tau_1}{\aclrd{n}} \vdash e_2 : \tau_2}
  {\coctx{\Gamma}{\aclrd{n}+\aclrd{m}} \vdash \kvd{let}~x=e_1~\kvd{in}~e_2 : \tau_2 }
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\aclrd{n}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{n}} \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{n}} \tau_2 }
\end{equation*}

\caption{Coeffect rules for tracking context-usage in data-flow language}
\label{fig:applications-flat-dataflow}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type system.}
A type system that tracks the maximal number of accessed past values annotates the context with
a single integer. The current value is always present, so $0$ means that no past values are 
needed, but the current value is still available. The typing rules of the system are shown
in Figure~\ref{fig:applications-flat-dataflow}.

Variable access (\emph{var}) annotates the context with $0$; sub-coeffecting (\emph{sub}) allows
us to require more values than is actually needed. Primitive context-requirements are introduced
in (\emph{prev}), which increments the number of past values by one. Thus, for example, 
$\kvd{prev}~(\kvd{prev}~x)$ requires 2 past values.

The (\emph{app}) rule follows the same intuition as for liveness. It combines \emph{sequential} 
and \emph{pointwise} composition of semantic functions. In case of data-flow, the operations
combine annotations using $+$ and \emph{max} operations:
%
\begin{equation*}
\begin{array}{lll}
f : \tau_1 \xrightarrow{\aclrd{m}} \tau_2 \qquad\qquad&
g : \tau_2 \xrightarrow{\aclrd{n}} \tau_3 \qquad\qquad&
g \circ f : \tau_1 \xrightarrow{\aclrd{m} + \aclrd{n}} \tau_3 \qquad\qquad
\\
f : \tau_1 \xrightarrow{\aclrd{m}} \tau_2 \qquad\qquad&
h : \tau_1 \xrightarrow{\aclrd{n}} \tau_3 \qquad\qquad&
\langle f, h \rangle : \tau_1 \xrightarrow{\textnormal{max}(\aclrd{m}, \aclrd{s})} \tau_2 \times \tau_3 \qquad
\end{array}
\end{equation*}
%
Sequential composition adds the annotations. The function $f$ needs $\aclrd{m}$ past values to 
produce a single $\tau_2$ value. To produce two $\tau_2$ values, we thus need $\aclrd{m}+1$ past
values of $\tau_1$; to produce three $\tau_2$ values, we need $\aclrd{m}+2$ past values of $\tau_1$,
and so on. To produce $\ident{n}$ past values that are required as the input of $g$, we need
$\aclrd{m}+\aclrd{n}$ past values of type $\tau_1$. The pointwise composition is simpler. It uses
the same stream to evaluate functions requiring $\aclrd{m}$ and $\aclrd{n}$ past values, and so it
needs maximum of the two at most.

In summary, function application (\emph{app}) requires maximum of the values needed to evaluate 
$e_1$ and the number of values needed to evaluate the argument $e_2$, sequentially composed with
the function. 

In function abstraction (\emph{abs}), the requirements of the body are duplicated on the declaration-site
and the call-site as in liveness analysis. If the body requires $\aclrd{n}$ past values, it may access
$\aclrd{n}$ values of any variables -- including those available in $\Gamma$, as well as the parameter
$x$. Finally, the (\emph{let}) rule simply adds the two requirements. This corresponds to the sequential
composition operation, but it is also a rule that we obtain by treating let-binding as a syntactic 
sugar for $(\lambda x.e_2)~e_1$.

% --------------------------------------------------------------------------------------------------

\paragraph{Example.} 
As with the liveness example, the application rule might require more explanation. The following 
example is somewhat arbitrary, but it demonstrates the rule well. We assume that \ident{counter} 
is a stream of positive integers (starting from zero) and \ident{tick} flips between $0$ and $1$.
The full typing derivation is shown in Appendix~?:
%
\begin{equation*}
\begin{array}{l}
(\,   \kvd{if}~~(\kvd{prev}~\ident{tick})=0\\[-0.25em]
\,\,\, \kvd{then}~(\lambda x \rightarrow \kvd{prev}~x)\\[-0.25em]
\,\,\, \kvd{else}~(\lambda x \rightarrow x) \,)\qquad(\kvd{prev}~\ident{counter})
\end{array}
\end{equation*}
%
The left-hand side of the application returns a function depending on the \emph{previous}
value of \ident{tick}. The resulting stream of functions flips between a function returning
a current value and a function returning the previous value. If the current \ident{tick} is 0, and
the function is applied to a stream $\langle{\ldots,4,3,2,1}\rangle$ 
(where $1$ is the current value), it yields the stream $\langle{\ldots,4,4,2,2}\rangle$. 

To obtain the function, we need one past value from the context (for $\kvd{prev}~\ident{tick}$). The 
returned function needs either none or one past value (thus a subtyping rule is required to type 
it as requiring one past value). So, the annotations for (\emph{app}) are $\aclrd{m}=1, \aclrd{p}=1$.
The function is called with $\kvd{prev}~\ident{counter}$ as an argument, meaning that the result
is either the first or second past element. Given 
$\ident{counter}\hspace{-0.1em}=\hspace{-0.1em}\langle{\ldots,5,4,3,2,1}\rangle$, the argument 
is $\langle{\ldots,5,4,3,2}\rangle$ and so the overall result is a stream $\langle{\ldots,5,5,3,3}\rangle$.
From the argument, we get the requirement $\aclrd{n}=1$.

Using the (\emph{app}) rule, we get that the overall number of past elements needed is
$\mathit{max}(1, 1+1) = 2$. This should match the intuition about the code -- when the first function
is applied to the argument, the computation will first access $\kvd{prev}~\ident{tick}$ (using one
past value) and then $\kvd{prev}~(\kvd{prev}~\ident{counter}))$ (using two past values).

%---------------------------------------------------------------------------------------------------

\begin{figure}
\begin{equation}
\tag{\emph{var}}
\hspace{-1em}
\sem{\coctx{\Gamma}{\aclrd{0}} \vdash x_i : \tau_i} = \lambda \langle(x_0, \ldots, x_n)\rangle \rightarrow x_i
\end{equation}
\vspace{-1.0em}
\begin{equation}
\tag{\emph{prev}}
\hspace{-1.5em}
\begin{array}{l}
\sem{\coctx{\Gamma}{\aclrd{n}+1} \vdash \kvd{prev}~e : \tau} = \lambda \langle \mathbf{v}_0, \ldots, \mathbf{v}_{\aclrd{n}+1} \rangle \rightarrow\\[-0.1em]
  \qquad\sem{ \coctx{\Gamma}{ \aclrd{n} } \vdash e : \tau }~\langle \mathbf{v}_1, \ldots, \mathbf{v}_{ \aclrd{n}+1 }\rangle
\end{array}
\end{equation}
\vspace{-0.5em}
\begin{equation}
\tag{\emph{sub}}
\hspace{-1.5em}
\begin{array}{l}
\sem{\coctx{\Gamma}{\aclrd{n}} \vdash e : \tau} = \lambda \langle \mathbf{v}_0, \ldots, \mathbf{v}_{\aclrd{n}} \rangle \rightarrow\\[-0.1em]
  \qquad\sem{ \coctx{\Gamma}{ \aclrd{n'} } \vdash e : \tau }~\langle \mathbf{v}_0, \ldots, \mathbf{v}_{ \aclrd{n'} }\rangle
\end{array}
\end{equation}
\vspace{-0.5em}
\begin{equation}
\tag{\emph{abs}}
\hspace{-1.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{n}} \vdash \lambda y. e : \tau_1 \xrightarrow{\aclrd{n}} \tau_2 } = 
    \lambda \langle \mathbf{v}_0, \ldots \mathbf{v}_{\aclrd{n}} \rangle \rightarrow\\[-0.1em]
  \qquad\lambda (y, g) \rightarrow \sem{ \coctx{\Gamma,y:\tau_1}{\aclrd{n}} \vdash e : \tau_2 
    }~\langle (\mathbf{v}_0, y_0), \ldots, (\mathbf{v}_{ \aclrd{n}  }, y_{ \aclrd{n} } ) \rangle
\end{array}
\end{equation}
\vspace{-0.5em}
\begin{equation*}
\tag{\emph{app}}
\hspace{-1.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\textnormal{max}(\aclrd{m}, \aclrd{n}+\aclrd{p})} \vdash e_1~e_2 : \tau_2 } = 
    \lambda (\mathbf{v}_0, \ldots, \mathbf{v}_{ \textnormal{max}(\aclrd{m}, \aclrd{n}+\aclrd{p}) } ) \rightarrow \\[-0.1em]
  \qquad\kvd{let}~g=\sem{ \coctx{\Gamma}{\aclrd{m}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{p}} \tau_2 
    }~(\mathbf{v}_0, \ldots, \mathbf{v}_{ \aclrd{m} })\\[-0.1em]
  \qquad\kvd{in}~g~(~\sem{ \coctx{\Gamma}{\aclrd{n}} \vdash e_2 : \tau_1 }~(\mathbf{v}_0, \ldots, \mathbf{v}_{ \aclrd{n} }),\ldots, \\[-0.1em]
  \qquad\qquad\;~\sem{ \coctx{\Gamma}{\aclrd{n}} \vdash e_2 : \tau_1 }~(\mathbf{v}_{ \aclrd{p} }, \ldots, \mathbf{v}_{ \aclrd{n}+\aclrd{p} })~)
\end{array}
\end{equation*}

\caption{Semantics of a simple data-flow language}
\label{fig:applications-flat-dfsem}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Semantics.}
The sample language discussed in this section is a \emph{causal} data-flow language. This means that
a computation can access \emph{past} values of the stream (but not future values). In the semantics, 
we again need richer structure over the input.

Uustalu and Vene \cite{comonads-notions} model causal data-flow computations using a non-empty list
$\ident{NeList}~\tau = \tau \times (\ident{NeList}~\tau + 1)$ over the input. A function $\tau_1 \rightarrow \tau_2$
is thus modelled as $\ident{NeList}~\tau_1 \rightarrow \tau_2$. This model is difficult to implement
efficiently, as it creates unbounded lists of past elements.

The coeffect system tracks maximal number of past values and so we can define the semantics using
a list of fixed length. As with liveness, this is a data structure \emph{indexed} by the coeffect
annotation. We write $\tau^{\aclrd{n}}$ for a list containing $\aclrd{n}$ elements (which can be 
also viewed as an $\aclrd{n}$-element product $\tau \times \ldots \times \tau$). 

As with the previous examples, our semantics interprets a judgement using a (semantic) function;
functions in the language are modelled as functions taking a list of inputs:
%
\begin{equation*}
\begin{array}{rcl}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \aclrd{n} } \vdash e : \tau} 
  &:& (\tau_1 \times \ldots \times \tau_n)^{\aclrd{n}+1} \rightarrow \tau\\
\sem{\tau_1 \xrightarrow{\aclrd{n}} \tau_2} &:& \tau_1^{\aclrd{n}+1} \rightarrow \tau_2
\end{array}
\end{equation*}
%
Note that the semantics requires one more value than is the number of past values. This is because 
the first value is the current value and has to be always available, even when the annotation is
zero as in (\emph{var}).

The rules defining the semantics are shown in Figure~\ref{fig:applications-flat-dfsem}. The
semantics of the context is a \emph{list of pairs}. To make the rules easier to follow, we write
$\langle \mathbf{v}_1, \ldots, \mathbf{v}_n \rangle$ for an $n$-element list containing pairs.
Pairs that model the entire context such as $\mathbf{v}_1$ are written in bold. When we access
individual variables, we write $\mathbf{v} = (x_1, \ldots, x_m)$ where $x_i$ denote individual
variables of the context.

In (\emph{var}), the context is a singleton-list containing a product of variables, from which
we project the right one. In (\emph{prev}) and (\emph{sub}), we drop some of the elements from 
the history (from the front and end, respectively) and then evaluate the original expression.

Lambda abstractions (\emph{abs}) receives two lists of the same size -- one containing values of
the variables from the declaration-site $\langle \mathbf{v}_0, \ldots, \mathbf{v}_{\aclrd{n}} \rangle$ and one
containing the argument provided by the call-site $\langle y_0, \ldots, v_{\aclrd{n}} \rangle$.
The semantics applies the well-known \emph{zip} operation on the lists and passes the result to the
body.

Finally, application (\emph{abs}) uses the input context in two ways, which gives rise to the
two requirements combined using \emph{max}. First, it evaluates the expression $e_1$ which is 
called with the past $\aclrd{m}$ values. The resulting function $g$ is then sequentially composed
with the semantics of $e_2$. To call the function, we need to evaluate $e_2$ repeatedly -- namely,
$\aclrd{p}+1$ times, which results in the overall requirement for $\aclrd{n}+\aclrd{p}$ past values.

\paragraph{Summary.}
The most interesting point about the data-flow example is that it is remarkably similar to our
earlier liveness example. In the type system, abstraction (\emph{abs}) duplicates the context
requirements and application (\emph{abs}) arises from sequential and pointwise composition.
We capture this striking similarity in Chapter~\ref{ch:flat}. Before doing that, we look at one
more example and then explore the \emph{structural} class of systems.

% --------------------------------------------------------------------------------------------------

\subsection{Permissions and safe locking}
In the implicit parameters and data-flow examples, the context provides additional resources or 
values that may be accessed at runtime. However, it may also track \emph{permissions} or 
\emph{capabilities} to perform some operation. Liveness can be seen as a trivial example -- when
the context is live, it contains a permission to access variables. In this section, we briefly
consider a system for safe locking of Flanagan and Abadi \cite{app-safe-locking} as one, more
advanced example. Calculus of capabilities of Cray et al. \cite{app-capabilities} is discussed 
later in Section~\ref{sec:applications-active-ccc}.

\paragraph{Safe locking.}
The system for safe locking prevents race conditions (by only allowing access to mutable state 
under a lock) and avoids deadlocks (by imposing strict partial order on locks). The following 
program uses a mutable state under a lock:
%
\begin{equation*}
\begin{array}{l}
\kvd{newlock}~l:\rho~\kvd{in}\\[-0.25em]
\kvd{let}~\ident{state}~=~\ident{ref}_\rho~10~\kvd{in}\\[-0.25em]
\kvd{sync}~l~(!\ident{state})
\end{array}
\end{equation*}
%
The declaration \kvd{newlock} creates a lock $l$ protecting memory region $\rho$. We can than
allocate mutable variables in that memory region (second line). An access to mutable variable
is only allowed in scope that is protected by a lock. This is done using the \kvd{sync} keyword,
which locks a lock and evaluates an expression in a context that contains permission to access
memory region of the lock ($\rho$ in the above example).

The type system for safe locking associates a list of acquired locks with the context. 
Interestingly, the original presentation of the system uses a coeffect-style judgements
of a form $\Gamma; p \vdash e : \tau$ where $p$ is a list of accessible regions (protected by
an acquired lock). Using our notation, the rule for \kvd{sync} looks as follows:
%
\begin{equation*}
\tyrule{sync}
  { \coctx{\Gamma}{\aclrd{p}} \vdash e_1 : m& 
    \coctx{\Gamma}{\aclrd{p} \cup \{m\} } \vdash e_2 : \tau }
  { \coctx{\Gamma}{\aclrd{p}} \vdash \kvd{sync}~e_1~e_2 : \tau }
\end{equation*}
%
The rule requires that $e_1$ yields a value of a singleton type $m$. The type is added as an
indicator of the locked region to the context $\aclrd{p}\cup \{m\}$ which is then used to evaluate
the expression $e_2$.

\paragraph{Summary.}
Despite attaching annotations to the variable context, the system for safe locking uses 
effect-style lambda abstraction. Lambda abstraction associates all requirements with the 
call-site -- a lambda function created under a lock cannot access protected memory available at 
the time of creation. It will be executed later and can only access the memory available then.
This suggests that safe locking is perhaps better seen as an effect system. 

Another interesting aspect is the extension to avoid deadlocks. In that case, the type system
needs to reject programs that acquire locks in an invalid order. One way to model this is to 
replace $\aclrd{p} \cup \{m\}$ with a \emph{partial} operation $\aclrd{p} \uplus \{m\}$ which
is only defined when the lock $m$ can be added to the set $\aclrd{p}$. Supporting partial 
operations on coeffect annotations is an interesting extension which we discuss in Section~?.
The extension also lets us capture systems with effect-style lambda abstraction such as safe
locking.

% ==================================================================================================

\section{Structural coeffect systems}

We now turn our attention to system where additional contextual information are associated not
with the context as a whole (or program scope), but with individual variables. We start by looking
simple static analysis -- variable \emph{liveness}. Then we revisit data-flow computations and
look at applications in security and software updating.

% % % % % % % %

Coeffects are way to describe notions of context in programming that keep turning up. 
To illustrate this, we overview three systems tracking contextual properties that 
 motivate our general coeffect system. Two systems track per-variable properties (bounded 
linear logic and dataflow) and one tracks whole-context properties (implicit parameters).

%---------------------------------------------------------------------------------------------------

\subsection{Liveness}
\label{sec:applications-struct-live}

todo

% --------------------------------------------------------------------------------------------------

\subsection{Bounded reuse}

Bounded linear logic \cite{girard1992bounded} restricts well-typed terms to polynomial-time algorithms.  
This is done by limiting the number of times a value (proposition) can be used. An assumption
$!_k A$ means that a variable can be used at most $k$ times. 
We attach annotations to the whole context rather than individual assumptions and so a context
$!_{k_1} A_1, ..., !_{k_n} A_n$ is written as $\coctx{\tau_1, ..., \tau_n}{\langle \cclrd{k_1}, ..., \cclrd{k_n}\rangle}$. 
This difference is further explained in Section~\ref{sec:related-work}. %For uniformity
%with later systems, we also write assumptions $A$ as $\tau$ and annotations $K$ as $\cclrd{r}$.

Bounded linear logic includes explicit weakening and contraction rules
that affect the multiplicity. Following the original logical style (but with our notation), these are written as:
\[
\inference
  {\coctx{\Gamma}{\aclrd{R}} \vdash \tau}
  {\coctx{\Gamma,\sigma}{\aclrd{R} \cons \alift{0}} \vdash \tau} 
\quad
\inference
  {\coctx{\Gamma_1,\sigma,\sigma,\Gamma_2}{\aclrd{R}\cons \alift{\cclrd{s},\cclrd{t}} \cons \aclrd{Q}} \vdash \tau}
  {\coctx{\Gamma_1,\sigma,\Gamma_2}{\aclrd{R}\cons\alift{\cclrd{s}+\cclrd{t}} \cons \aclrd{Q}} \vdash \tau}
\]
The context $\coctx{\Gamma}{\aclrd{R}}$ includes a \emph{coeffect annotation} $\aclrd{R}$ which is a vector
$\alift{\cclrd{r_1}, \ldots, \cclrd{r_n}}$ of the same length as $\Gamma$ (a side-condition omitted for brevity).
In weakening (left), unused propositions are annotated with $0$ (no uses), while in contraction (right), multiple 
occurrences of a proposition are joined by adding the number of uses.


\begin{figure}[t]
\vspace{-0.5em}
\begin{align*}
\begin{array}{c}
%
\hspace{-0.6em}
\begin{array}{c}
\tyrule{var}{}
  {\coctx{x \!:\! \tau}{\alift{1}} \vdash x : \tau} 
\quad 
\tyruleCompact{weak}
  {\coctx{\Gamma}{R} \vdash e : \tau}
  {\coctx{\Gamma,x \!:\! \sigma}{\aclrd{R} \cons \alift{0}} \vdash e : \tau} 
\\[1.8em]
\tyruleCompact{sub}
  {\coctx{\Gamma}{\aclrd{R}} \vdash e : \tau}
  {\coctx{\Gamma}{\aclrd{R'}} \vdash e : \tau}~(\text{\scriptsize $\aclrd{R} \leq \aclrd{R'}$})
\quad 
\tyrule{abs}
  {\coctx{\Gamma, x \!:\! \sigma}{\aclrd{R} \cons \alift{s}} \vdash e : \tau}
  {\coctx{\Gamma}{\aclrd{R}} \vdash \lambda x . e : \sigma \xrightarrow{\cclrd{s}} \tau} 
\\[1.2em]
\end{array} \\
%
% ------------------------ 
%
\begin{array}{c}
\tyrule{app}
  { \coctx{\Gamma_1}{\aclrd{R}} \vdash e_1 : \sigma \xrightarrow{\cclrd{t}} \tau \quad 
    \coctx{\Gamma_2}{\aclrd{S}} \vdash e_2 : \sigma}
  { \coctx{\Gamma_1, \Gamma_2}{\aclrd{R} \cons (\cclrd{t} \ast \aclrd{S})} \vdash e_1 \, e_2 : \tau} 
\\[1.3em]
\tyrule{contr}
  {\coctx{\Gamma_1,y\!:\!\sigma,z\!:\!\sigma,\Gamma_2}{\aclrd{R}\cons \alift{\cclrd{s},\cclrd{t}} \cons \aclrd{Q}} \vdash e : \tau}
  {\coctx{\Gamma_1,x\!:\!\sigma,\Gamma_2}{\aclrd{R}\cons\alift{\cclrd{s}+\cclrd{t}} \cons \aclrd{Q}} \vdash \subst{e}{z,y}{x} : \tau}
\\[1.3em]
\tyrule{exch}
  {\coctx{\Gamma_1,x\!:\!\sigma',y\!:\!\sigma,\Gamma_2}{\aclrd{R}\cons\alift{\cclrd{s},\cclrd{t}} \cons \aclrd{Q}} \vdash e : \tau}
  {\coctx{\Gamma_1,y\!:\!\sigma,x\!:\!\sigma',\Gamma_2}{\aclrd{R}\cons\alift{\cclrd{t},\cclrd{s}} \cons \aclrd{Q}} \vdash e : \tau}
\end{array} 
% ------------------------ 
%
% \hspace{-1em}
%\begin{array}{c}
%
% TP: I removed the 'let' rule again because we do not need it to explain the storage axiom here.
% Also, I think the BLL sample is already used to explain quite a lot of things, so I'd be happier
% to keep it simple.
%
% BTW: The \tyruleCompact macro creates a rule that *looks* differently..
% (I do not understand why but it makes the line somehow thicker...)
%
% \tyruleCompact{let}
%   {\coctxs{\Gamma_1, v : \sigma}{R \times \langle{t}\rangle} \vdash e_1 : \tau \quad 
%    \coctxs{\Gamma_2}{S} \vdash e_2 : \sigma}
%   {\coctxs{\Gamma_1, \Gamma_2}{R \times (t \ast S)} \vdash \kvd{let}~x=e_2~\kvd{in}~e_1 : \tau} \\[1.8em]
\end{array}
\end{align*}
\vspace{-0.5em}
\caption{type and coeffect system for bounded reuse}
\label{fig:bounded-coeff}
\end{figure}


\paragraph{Bounded linear coeffects.}
The system in Figure~\ref{fig:bounded-coeff} extends the outlined idea into a simple calculus.
Variable access (\emph{var}) has a singleton context with a singleton coeffect vector
$\alift{1}$. Weakening (\emph{weak}) extends the free-variable context with an unused variable and 
the coeffect with an associated scalar $0$. Explicit contraction (\emph{contr}) and
exchange (\emph{exch}) rules manipulate variables in the context and
modify the annotations accordingly -- adding the number of uses in
contraction and switching vector elements in exchange.

For abstraction (\emph{abs}), we know the number of uses of the parameter variable $x$ 
and attach it to the function type $\sigma \xrightarrow{\cclrd{s}}
\tau$ as a \emph{latent} coeffect. The remaining variables in $\Gamma$ are 
annotated with the remaining coeffect vector $\aclrd{R}$, specifying \emph{immediate} coeffects.

Application (\emph{app}) describes call-by-name evaluation.  Applying
a function that uses its parameter $\cclrd{t}$-times to an argument
that uses variables in $\Gamma_2$ $\aclrd{S}$-times means that, in
total, the variables in $\Gamma_2$ will be used $(\cclrd{t} \ast \aclrd{S})$-times. 
Recall that $\cclrd{t} \ast \aclrd{S}$ is a scalar multiplication of a
vector. Meanwhile, the variables in $\Gamma_1$ are used just
$\aclrd{R}$-times when reducing the expression $e_1$ to a function
value. 

Finally, the sub-coeffecting rule (\emph{sub}) safely overapproximates
the number of uses using the pointwise
$\leq$ relation. We can view any variable as being used a greater
number of times than it actually is.

\paragraph{Example.} To demonstrate, consider a term
$(\lambda v.x+v+v)~(x+y)$. According to the call-by-name intuition, the variable $x$ is used three 
times -- once directly inside the function and twice via the variable $v$ after 
substitution. Similarly, $y$ is used 
twice. Assuming a judgment for the function body, abstraction yields:
%
\begin{equation*}
\tyrule{abs}
 { \coctx{x\!:\!\mathbb{Z},v:\mathbb{Z}}{\alift{\cclrd{1},\cclrd{2}}} \vdash x+v+v : \mathbb{Z} }
 { \coctx{x\!:\!\mathbb{Z}}{\alift{\cclrd{1}}} \vdash (\lambda v.x+v+v) : \mathbb{Z} \xrightarrow{\cclrd{2}} \mathbb{Z} }
\end{equation*}
%
To avoid name clashes, we $\alpha$-rename $x$ to $x'$ and later join $x$ and $x'$ using contraction.
Assuming $(x'+y)$ is checked in a context that marks $x'$ and $y$ as used once, the application rule yields
a judgment that is simplified as follows:
\[
\hspace{-0.7em}\inference
  { \coctx{x\!:\!\mathbb{Z},x'\!:\!\mathbb{Z},y\!:\!\mathbb{Z}}
          {\alift{\cclrd{1}} \cons (\cclrd{2} \ast \alift{\cclrd{1},\cclrd{1}}) } \vdash (\lambda v.x+v+v)~(x'+y) : \mathbb{Z} }
{\inference
  { \coctx{x\!:\!\mathbb{Z},x'\!:\!\mathbb{Z},y\!:\!\mathbb{Z}}{\alift{\cclrd{1}, \cclrd{2}, \cclrd{2}} } \vdash (\lambda v.x+v+v)~(x'+y) : \mathbb{Z} }
  { \coctx{x\!:\!\mathbb{Z},y\!:\!\mathbb{Z}}{\alift{\cclrd{3}, \cclrd{2}}} \vdash (\lambda v.x+v+v)~(x+y)  : \mathbb{Z}} }
\]
%
The first step performs scalar multiplication, producing the vector
$\alift{\cclrd{1},\cclrd{2},\cclrd{2}}$. In the second step, we use contraction to join variables 
$x$ and $x'$ from the function and argument terms respectively.

It is worth pointing out that reduction by substitution yields $x+(x+y)+(x+y)$ which has the same coeffect as
the original. We return to evaluation strategies in Section~\ref{sec:syntax}, and 
show that structural coeffect systems preserve types and coeffects under $\beta$-reduction. 

% --------------------------------------------------------------------------------------------------

\subsection{Data-flow languages (revisited)}
When discussing data-flow languages in the previous section, we said that the context provides 
past values of variables. This can be viewed as a flat contextual property (the context needs
to keep all past values), but we can also view it as a structural property. Consider the following
example:
%
\begin{equation*}
\kvd{let}~\ident{offsetZip} = 0~\kvd{fby}~(\ident{left} + \kvd{prev}~\ident{right})
\end{equation*}
%
The value \ident{offsetZip} adds values of \ident{left} with previous values of \ident{right}.
To evaluate a current value of the stream, we need the current value of \ident{left} and one past
value of \ident{right}. 

As mentioned earlier, a static analysis for data-flow computations could calculate how many past 
values must be cached. This can be done as a \emph{flat} coeffect analysis that produces just a 
single number for each function. However, we can design a more precise \emph{structural} analysis
and track the number of required elements for individual variables.

% % % % % %

\paragraph{Dataflow and data access}

Dataflow languages such as Lucid \cite{wadge1985lucid} describe computations over \emph{streams}.
An expression is re-evaluated when new inputs are available (push) or when more output
is demanded (pull).  In causal dataflow, programs can access past
values of a stream. We consider a language where $\kvd{prev}~e$
returns the previous value of $e$, where 
$\kvd{prev}~(\kvd{prev}~e)$ therefore returns the second past value.

An implementation of causal dataflow may cache past values of
variables as an optimisation. The question is, how many past values
should be cached?  This can be approximated by a coeffect system.

\paragraph{Dataflow coeffects.} The coeffect system for dataflow is
similar to the one for bounded reuse in that it tracks a vector
of numbers $\aclrd{R}$ as part of the context
$\coctx{\Gamma}{\aclrd{R}}$. Here, coeffects represent the maximal number of
past values (\emph{causality depth}) required for a variable. 

Weakening, exchange, abstraction and sub-coeffecting are the same as in bounded linear
coeffects, but the remaining rules differ. In Figure~\ref{fig:dataflow-coeff},
accessed variables (\emph{var}) are annotated with
$0$ meaning that no past value is required (only the
current one). The (\emph{prev}) rule crates caching requirements --
it increments the number of required values for all variables
used in $e$ using scalar-vector addition.

Application and contraction have the same structure as before, 
but use different operators. If two variables 
are contracting, requiring $\cclrd{s}$ and $\cclrd{t}$ past
values, then overall we need at most
$\ident{max}(\cclrd{s}, \cclrd{t})$ past values (\emph{contr}). That is, 
two caches are combined with the maximum of the two requirements, 
which satisfy the smaller requirements. 

In (\emph{app}), the function requires $\cclrd{t}$ past values of
its parameter.  This means $\cclrd{t}$ past values of
$e_2$ are needed which in turn requires $\aclrd{S}$ past values of its free
variables $\Gamma_2$. Thus, we need $\cclrd{t}+\aclrd{S}$ past values of $\Gamma_2$ to perform the
call (\eg{}, we need $1+\aclrd{S}$ values to
get $1$ past value of the input $\sigma$, $2+\aclrd{S}$
values to get $2$ past values of $\sigma$, \emph{etc.}).


\paragraph{Example.} As an example, consider a function $\lambda x.\kvd{prev}~(y+x)$ applied to an argument
$\kvd{prev}~(\kvd{prev}~y)$. The body of the function accesses the past value of two variables, one free
and one bound:
\[
\dfrac
  {\coctx{y\!:\!\mathbb{Z}, x\!:\!\mathbb{Z}}{\alift{1, 1}} \vdash \kvd{prev}~(y+x) : \mathbb{Z} }
  {\coctx{y\!:\!\mathbb{Z}}{\alift{1}} \vdash \lambda x . \kvd{prev}~(y+x) : \mathbb{Z} \xrightarrow{\cclrd{1}} \mathbb{Z} }
\]
The expression always requires the previous value of $y$ and adds it to
a previous value of the parameter $x$. Evaluating the value of the
argument $\kvd{prev}~(\kvd{prev}~y)$ requires two past values of $y$
and so the overall requirement is $3$ past values:
\[
\inference
  { \coctx{y\!:\!\mathbb{Z}}{\alift{1} } \vdash \lambda x.~(\ldots) \quad  \coctx{x\!:\!\mathbb{Z}}{\alift{2}} \vdash (\kvd{prev}~(\kvd{prev}~x) : \mathbb{Z} }
{\inference
  { \coctx{y\!:\!\mathbb{Z}, x\!:\!\mathbb{Z}}{\alift{1,3}} \vdash (\lambda x.\kvd{prev}~(y+x))~(\kvd{prev}~(\kvd{prev}~x)) : \mathbb{Z} }
  { \coctx{y\!:\!\mathbb{Z}}{\alift{3}} \vdash (\lambda x.\kvd{prev}~(y+x))~(\kvd{prev}~(\kvd{prev}~y)) : \mathbb{Z} } }
\]
The derivation uses (\emph{app}) to get requirements $\alift{1,3}$ and then 
(\emph{contr}) to take the maximum, showing three past values are sufficient. Reducing 
the expression by substitution we get $\kvd{prev}~(y+(\kvd{prev}~(\kvd{prev}~y)))$. 
Semantically, this performs stream lookups $y[1] + y[3]$ where the indices are the 
number of enclosing $\kvd{prev}$s.% expressions.

We previously used dataflow as an example of
coeffects~\cite{petricek2013coeffects}, but tracked caching
requirements on the whole context. The system outlined here is more
powerful and practically useful, with finer-grained coeffects tracking
caching requirements per-variable.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\[
\tyrule{contr}
  {\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{R}\cons\alift{\cclrd{s},\cclrd{t}} \cons \aclrd{Q}} \vdash e : \tau}
  {\coctx{\Gamma_1,x\!:\!\tau,\Gamma_2}{\aclrd{R}\cons\alift{\ident{max}(\cclrd{s},\cclrd{t})} \cons \aclrd{Q}} \vdash \subst{e}{y,z}{x} : \tau}
\]
\[
\tyrule{app}
  { \coctx{\Gamma_1}{\aclrd{R}} \vdash e_1 : \sigma \xrightarrow{\cclrd{t}} \tau &
    \coctx{\Gamma_2}{\aclrd{S}} \vdash e_2 : \sigma }
  { \coctx{\Gamma_1, \Gamma_2}{\aclrd{R} \cons (\cclrd{t} + \aclrd{S})} \vdash e_1 \, e_2 : \tau} 
\]
\[
\tyrule{var}{}
  {\coctx{x\!:\!\tau}{\alift{0}} \vdash x : \tau}
\quad\;
\tyrule{prev}
  {\coctx{\Gamma}{\aclrd{R}} \vdash e : \tau}
  {\coctx{\Gamma}{1 + \aclrd{R}} \vdash \kvd{prev}~e : \tau}  
\]
\caption{type and coeffect system for dataflow caching}
\label{fig:dataflow-coeff}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsection{Tainting and provenance}
Tainting is a mechanism where variables coming from potentially untrusted sources are marked
(\emph{tainted}) and the use of such variables is disallowed in contexts where untrusted input
can cause security issues or other problems. Tainting can be done dynamically as a runtime mark
(e.g.~in the Perl language) or statically using a type system. Tainting can be viewed as a special
case of \emph{provenance tracking}, known from database systems \cite{app-provenance-db}, where
values are annotated with more detailed information about their source.

Statically typed systems that based on tainting have been use to prevent cross-site scripting
attacks \cite{app-tainting-xss} and a well known attack known as SQL injection
\cite{app-tainting-sql,app-tainting-wasp}. In the latter chase, we want to check that SQL commands 
cannot be directly constructed from, potentially dangerous, inputs provided by the user. Consider the 
type checking of the following expression in a context containing variables \ident{id} and \ident{msg}:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{name} = \ident{query}~(\str{"SELECT Name WHERE Id = "}~+~\ident{id})~\kvd{in}\\
\ident{msg}~+~\ident{name}
\end{array}
\end{equation*}
%
In this example, \ident{id} must not come directly from a user input, because \ident{query} requires 
untainted string. Otherwise, the attacker could specify values such as \str{"1; DROP TABLE Users"}. 
The variable \ident{msg} may or may not be tainted, because it is not used in protected context 
(i.e.~to construct an SQL query). 

In runtime checking, all (string) values need to be wrapped in an object that stores Boolean 
flag (for tainting) or more complex data (for provenance). In static checking, the information
need to be associated with the variables in the variable context. We use tainting as a motivating
example for \emph{structural} coeffects in Section~X.

% --------------------------------------------------------------------------------------------------

\subsection{Security and core dependency calculus}

The checking of tainting is a special case of checking of the \emph{non-interference} property 
in \emph{secure information flow}. Here, the aim is to guarantee that sensitive information (such
as credit card number) cannot be leaked to contexts with low secrecy (e.g.~sent via an unsecured
network channel). Volpano et al. \cite{app-secure-flow} provide the first (provably) sound type 
system that guarantees non-inference and Sabelfeld et al. \cite{app-secure-information-flow} survey
more recent work. The checking of information flows has been also integrated (as a single-purpose
extension) in the FlowCaml \cite{app-security-flowcaml} language. Finally, Russo et al. and 
Swamy et al. \cite{monad-secure-flow,monads-lightweight-ml} show that the properties can be checked
using a monadic library.

Systems for secure information flow typically define a lattice of security classes $(\mathcal{S}, \leq)$
where $\mathcal{S}$ is a finite set of classes and an ordering. For example a set $\{\ident{L}, \ident{H}\}$ 
represents low and high secrecy, respectively with $\ident{L} \leq \ident{H}$ meaning that low security
values can be treated as high security (but not the other way round).

An important aspect of secure information flow is called \emph{implicit flows}. Consider the following
example which may assign a new value to $z$:
%
\begin{equation*}
\kvd{if}~x>0~\kvd{then}~z := y
\end{equation*}
%
If the value of $y$ is high-secure, then $z$ becomes high-secure after the assignment
(this is an \emph{explicit} flow). However, if $x$ is high-secure, then the value of
$z$ becomes high-secure, regardless of the security level of $y$, because the fact whether an 
assignment is performed or not performed leaks information in its own (this is an 
\emph{implicit} flow).

Abadi et al. realized that there is a number of analyses similar to secure information flow
and proposed to unify them using a single model called Dependency Core Calculus (DCC) \cite{app-dcc}.
It captures other cases where some information about expression relies on properties of variables
in the context where it executes.  The DCC captures, for example, \emph{binding time analysis}
\cite{app-binding-time-analysis}, which detects which parts of programs can be partially evaluated
(do not depend on user input) and \emph{program slicing} \cite{app-slicing-survey} that identifies
parts of programs that contribute to the output of an expression.
	

% ==================================================================================================

\section{Beyond passive contexts}

In the systems discussed so far, the context provides additional data (resources, implicit 
parameters, historical values) or meta-data (security, provenance). However, it is impossible to
write a function that modifies the context. We use the term \emph{passive} context for such 
applications. 

However, there is a number of systems where the context may be changed -- not just be evaluating
certain code block in a different scope (e.g. by wrapping it in $\ident{prev}$ in data-flow), but
also by calling a function that, for example, acquires new capabilities. While this thesis focuses
on systems with passive context, we quickly look at the most important examples of the 
\emph{active} variant.

% --------------------------------------------------------------------------------------------------

\paragraph{Calculus of capabilities}
\label{sec:applications-active-ccc}

Crary et al. \cite{app-capabilities} introduced the Calculus of Capabilities to provide 
a sound system with region-based memory management for low-level code that can be easily 
compiled to assembly language. They build on the work of Tofte and Talpin \cite{app-region-memory}
who developed an \emph{effect system} (discussed in Section~\ref{sec:path-sem-effects}) that uses
lexically scoped \emph{memory regions} to provide an efficient and controlled memory management.

In the work of Tofte and Talpin, the context is \emph{passive}. They extend a simple functional language
with the \kvd{letrgn} construct that defines a new memory region, evaluates an expression (possibly)
using memory in that region and then deallocates the memory of the region:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{calculate} = \lambda \ident{input} \rightarrow\\
\quad\kvd{letrgn}~\rho~\kvd{in}\\
\quad\kvd{let}~\ident{x} = \kvd{ref}_\rho \ident{input}~\kvd{in}~!\ident{x}
\end{array}
\end{equation*}
%
The memory region $\rho$ is a part of the context, but only in the scope of the body of 
\kvd{letrgn}. It is only available to the last line which allocates a memory cell in the region
and reads it (before the region is deallocated). There is no way to allocate a region inside a 
function and pass it back to the caller.

Calculus of capabilities differs in two ways. First, it allows explicit allocation and deallocation
of memory regions (and so region lifetimes do not follow strict LIFO ordering). Second, it
uses continuation-passing style. We ignore the latter aspect and so the following example:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{calculate} = \lambda \ident{input} \rightarrow\\
\quad \kvd{letrgn}~\rho~\kvd{in}\\
\quad \kvd{let}~\ident{x} = \kvd{ref}_\rho \ident{input}~\kvd{in}~\ident{x}
\end{array}
\end{equation*}
%
The example is almost identical to the previous one, except that it does not return the value
of reference \ident{x}. Instead, it returns the reference, which is located in a newly allocated
region. Together with the value, the function returns a \emph{capability} to access the region
$\rho$.

This is where systems with active context differ. To type check such programs, we do not only need
to know what context is required to call \ident{calculate}. We also need to know what effects it
has on the context when it evaluates and the current context meeds to be appropriately adjusted
after a function call. We briefly consider this problem in Section~X. % future work

% --------------------------------------------------------------------------------------------------

\paragraph{Software updating}
Dynamic software updating (DSU) \cite{app-dsu-programs,app-dsu} is the ability to update programs at
runtime without stopping them. The Proteus system developed by Stoyle et al. \cite{app-dsu-mutatis} 
investigates what language support is needed to enable safe dynamic software updating in C-like 
languages. The system is based on the idea of capabilities.

The system distinguishes between \emph{concrete} uses and \emph{abstract} uses of a value. When
a value is used concretely, the program examines its representation (and so it is not safe to
change the representation during an update). An abstract use of a value does not need to examine
the representation and so updating the value does not break the program.

The Proteus system uses capabilities to restrict what types may be used concretely after any point
in the program. All other types, not listed in the capability, can be dynamically updated as this
will not change concrete representation of types accessed later in the evaluation.

Similarly to Capability Calculus, capabilities in DSU can be changed by a function call. For 
example, calling a function that may update certain types makes it impossible to use those types
concretely following the function call. This means that DSU uses the context \emph{actively}
and not just \emph{passively}.

% --------------------------------------------------------------------------------------------------

\paragraph{Thesis perspective}

As demonstrated in this section, there is a huge number of systems and applications that exhibit
a form of context-dependence. The range includes different static analyses (liveness, provenance), 
well-known programming language features (implicit parameters and type classes) as well as features
not widely available (e.g. for distributed programming).

It is impossible to cover all of these topics in a single coherent thesis and so we focus on 
two key aspects:

\begin{compactitem}
\item \textbf{Flat vs. structural.} We look at both flat coeffects (single value for entire context) and 
  structural coeffects (single value per variable). We use liveness, implicit parameters and 
  data-flow to introduce flat coeffects (Section~X) and liveness, refined data-flow and tainting
  to talk about structural coeffects (Section~Y).
  
\item \textbf{Analysis vs. restriction.} Some of the discussed examples can be viewed as static
  analyses that obtain some information about programs (i.e.~the number of required past values
  in data-flow). Other examples provide type system that rules out certain invalid programs 
  (e.g.~safe locking). We cover this topic when discussing \emph{partial coeffects} in Section~Z.
  
\item \textbf{May vs. must analysis.} When discussing liveness, we observed that we can obtain 
  two different analyses depending on how conditionals are treated. We discuss this topic in 
  Section~X. % TBD - could be a chapter
\end{compactitem}

Although we also looked at examples of \emph{active} contextual computations (where developers can
write functions that modify the context), we do not consider these applications, to keep the 
material presented in this thesis focused. We briefly discuss them as future work in Section~X.

%===================================================================================================

\section{Summary}

TODO

% \section{Missing}
% ~
% 
% indexed/layered/etc. monads, productors or whatever