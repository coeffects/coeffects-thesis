% ==================================================================================================

\chapter{Context-aware applications} 
\label{ch:applications} 

Software developers as well as programming language researchers choose abstractions based not 
just on how appropriate they are. Other factors may include social aspects -- how well is the 
abstraction known, how well is it documented and whether it is a standard tool of the 
\emph{research programme}\footnote{ Research programme, as introduced by Lakatos \cite{philosophy-lakatos},
is a network of scientists sharing the same basic assumptions and techniques.}. 

In Chapter~\ref{ch:intro}, we argued that context-awareness had, so far, only limited influence 
on the design of programming languages, possibly because it is a challenge that is not easy to
see. However, many of the properties that we treat uniformly as \emph{coeffects} have been
previously tracked by other means. This includes special-purpose type systems, systematic 
approaches arising from modal logic S4, as well as techniques based on abstractions designed 
for other purpose, most frequently monads.

In this chapter, we describe a number of simple calculi for tracking a wide range of contextual
properties. The systems are adapted from existing work, but the uniform presentation in this 
chapter is a novel contribution. The fact that we find a common structure in all systems presented 
here lets us develop unified coeffect calculi in the upcoming three chapters.

%===================================================================================================

\section{Structure of coeffect systems}

When introducing coeffect systems in Section~\ref{sec:intro-theory}, we related coeffect systems
with effect systems. Effect systems track how program affects the environment, or, in other words 
capture some \emph{output impurity}. In contrast, coeffect systems track what program requires from the 
environment, or \emph{input impurity}.

Effect systems generally use judgements of the form $\Gamma \vdash e : \tau \;\&\; \aclrd{\sigma}$, 
associating effects $\sigma$ with the output type. In contrast, we choose to write coeffect 
systems using judgements of the form $\coctx{\Gamma}{\aclrd{\sigma}} \vdash e : \tau$, associating
the context requirements with $\Gamma$. Thus, we extend the traditional notion of free-variable
context $\Gamma$ with richer notions of context. Besides the notation, there are more important 
differences between effects and coeffects.

% --------------------------------------------------------------------------------------------------

\subsection{Lambda abstraction}

The difference between effects and coeffects becomes apparent when we consider lambda abstraction.
The typical lambda abstraction rule for effect systems looks as (\emph{abs-eff}) in 
Figure~\ref{fig:applications-abs}. Wadler and Thiemann~\cite{monads-effects-marriage} explain how 
the effect analysis works `as follows:
%
\begin{quote}
\emph{In the rule for abstraction, the effect is empty because evaluation immediately
returns the function, with no side effects. The effect on the function arrow
is the same as the effect for the function body, because applying the function will
have the same side effects as evaluating the body.}
\end{quote}
%
This is the key property of \emph{output impurity}. The effects are only produced when the
function is evaluated and so the effects of the body are attached to the function. A recent
work by Tate~\cite{effects-producer-semantics} uses the term \emph{producer} effect systems
for such standard systems and characterises them as follows:
%
\begin{quote}
\emph{Indeed, we will define an effect as a producer effect if all computations with that 
effect can be thunked as ``pure'' computations for a domain-specific notion of purity.}
\end{quote} 
%
The thunking is typically a lambda abstraction -- given an effectful expression $e$, the
function $\lambda x.e$ is effect free value (thunk) that delays all effects.

Coeffects do not follow this pattern. Indeed, we can see this even when we consider the classical
notion of context. Standard lambda abstraction (\emph{app-pure}) in Figure~\ref{fig:applications-abs}
splits the free-variable context of an expression between variables defined at the \emph{declaration 
site} (the lexical scope) and those provided by the \emph{call site} (bound variable, or the 
parameter). This is also the case for other notions of context that we consider in this thesis.

% --------------------------------------------------------------------------------------------------

\begin{figure}
\[
\tyrule{abs-pure}
  { \Gamma, x\-:\-\tau_1 \vdash e : \tau_2}
  { \Gamma \vdash \lambda x.e : \tau_1 \rightarrow \tau_2 1}
\;\;
\tyrule{abs-eff}
  { \Gamma, x\-:\-\tau_1 \vdash e : \tau_2 \,\&\, \aclrd{\sigma} }
  { \Gamma \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{\sigma}} \tau_2 \,\&\, \aclrd{\emptyset} }
\]
\caption{Lambda abstraction for pure and effectful computations}
\label{fig:applications-abs}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsection{Notions of context}

Aside from the standard free-variable context, we consider two notions of context -- 
\emph{flat} refers to overall properties of the environment and \emph{structural} refer to 
properties attached to individual variables. Similarly to free-variable context, both of these
notions split the context between declaration-site (lexical scope) and call-site (dynamic scope).

\paragraph{Flat coeffects.}

In distributed 
systems, additional resources available at certain nodes (\eg~a database or GPS sensor) can be 
also viewed as a part of typing assumptions. 

Similarly, resources in a distributed system can be satisfied by both the declaration site (by 
capturing a remote reference) and the call site (by resource rebinding)~\cite{app-distributed-acute}. 
In this case, the resource requirements are split freely. 

\paragraph{Structural coeffects.}

The previously described notion of a \emph{coeffect system} \cite{petricek2013coeffects} tracks
contextual properties of entire programs, which is practically useful for implicit parameters 
or resources. However, for per-variable coeffects, the previous work provides only an approximation 
with limited practical usefulness (\eg~marking the whole context as live when just one 
variable in the context is live).

Furthermore, contextual requirements may relate to 
specific variables. For example, liveness or access patterns, such as the number of accesses in 
bounded linear logic or past values in causal dataflow.

For contextual properties associated with 
variables (\eg~liveness or dataflow), the splitting tracks free variables -- requirements associated 
with a \emph{bound} variable should be satisfied by the call site, while those associated with 
\emph{free} variables should be provided by the declaration site.

lambda abstraction places 
requirements on both the \emph{call-site} (latent requirements) and the \emph{declaration-site} 
(immediate requirements), 

 We start with some background and finish with a brief overview of the literature leading to coeffects.

In the rest of the chapter, we look at instances of both. But before, we need to look at vectors.

% --------------------------------------------------------------------------------------------------

\subsection{Scalars and vectors}

The $\lambda$-calculus is asymmetric-- it maps a context with \emph{multiple} variables to a 
\emph{single} result. An expression with $n$ free variables of types $\sigma_i$ can be modelled
by a function
$\sigma_1 \times \ldots \times \sigma_n \rightarrow \tau$ with a product on the left, but a single value
on the right. Effect systems attach effect annotations to the result $\tau$. In coeffect systems,
we attach coeffects to the context $\sigma_1 \times \ldots \times \sigma_n$ and we often (but not always)
have one coeffect per each variable. We call the overall coeffect a \emph{vector} consisting of
\emph{scalar} coeffects. This asymmetry explains why coeffect systems are not trivially dual to 
effect systems.

It is useful to clarify how vectors are used in this paper. Suppose we have a set $\C$ of
\emph{scalars} such as $\cclrd{r_1},\ldots,\cclrd{r_n} \in \C$. A vector $\aclrd{R}$ over $\C$
is a tuple $\langle \cclrd{r_1}, \ldots, \cclrd{r_n}\rangle$ of scalars. 
We use letters like $\aclrd{R}, \aclrd{S}, \aclrd{T}$ for 
vectors and $\cclrd{r},\cclrd{s},\cclrd{t}$ for scalars.\footnote{For better readability, the paper 
distinguishes different structures using colours. However ignoring the colour does not introduce 
any ambiguity.} We also say that a \emph{shape} of a vector $\slift{\aclrd{R}}$ (or more generally any container) 
is the set of \emph{positions} in a vector. So, a vector of length
$n$ has shape $\{ 1, 2, \ldots, n \}$. 

Just as in scalar-vector multiplication, we lift any binary operation on scalars into a scalar-vector one:
$\cclrd{s} \bullet \aclrd{R} = \langle \cclrd{s}\bullet\cclrd{r_1}, \ldots, \cclrd{s}\bullet\cclrd{r_n}\rangle$.
Given two vectors $\aclrd{R},\aclrd{S}$ of the same shape, containing partially ordered scalars, we 
write $\aclrd{R} \leq \aclrd{S}$ for the pointwise extension of $\leq$ on scalars. Finally,
the associative operation $\times$ concatenates vectors.

We note that an environment $\Gamma$ containing $n$ uniquely named, typed variables is also a vector, 
but we continue to write `$,$' for the product, so $\Gamma_1, x\!:\!\tau, \Gamma_2$ should 
be seen as $\Gamma_1 \times \langle x\!:\!\tau\rangle \times \Gamma_2$.

%===================================================================================================

\section{Flat coeffects (1.)}

In a number of systems, the execution environment provides some additional data, resources or 
information about the execution context, but are independent of the variables used by the 
program. We look at implicit parameters and rebindable resources (that both provide additional
identifiers that can be accessed similarly to variables, but follow different scoping rules),
distributed programming, cross-compilation and data-flow.

%---------------------------------------------------------------------------------------------------

\paragraph{Implicit parameters} In Haskell, implicit parameters \cite{app-implicit-parameters} are 
a special kind of variables that may behave as dynamically scoped. This means, if a function uses 
parameter $\ident{?p}$, then the caller of the function must define $\ident{?p}$ and set its value.
Implicit parameters can be used to parameterise a computation (involving a chain of function calls)
without passing parameters explicitly as additional arguments of all involved functions. A simple 
language with implicit parameters has an expression $\ident{?p}$ to read a parameter value and an 
expression\footnote{Haskell uses $\kvd{let}~\ident{?p} = e_1~\kvd{in}~e_2$, but we use a different keyword to 
avoid confusion.} $\kvd{letdyn}~?p = e_1~\kvd{in}~e_2$ that sets a parameter $\ident{?p}$ to the value of $e_1$ 
and evaluates $e_2$ in a context containing $\ident{?p}$

An interesting question arises when we use implicit parameters in a nested function. The following 
function does some pre-processing and then returns a function that builds a formatted string based 
on two implicit parameters $\ident{?width}$ and $\ident{?size}$:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{format} = \lambda \ident{str}~\rightarrow \\
\quad \kvd{let}~\ident{lines} = \ident{formatLines}~\ident{str}~\ident{?width}~\kvd{in}\\
\quad (\lambda \ident{rest}~\rightarrow~\ident{append}~
         \ident{lines}~\ident{rest}~\ident{?width}~\ident{?size})\\
\end{array}
\end{equation*}
%
The body of the outer function accesses the parameter $\ident{?width}$, so it certainly requires a context 
$\{ \ident{?width} : \ident{int} \}$. The nested function (returned as a result) uses the parameter 
$\ident{?width}$, but in addition also uses $\ident{?size}$. Where should the parameters of the nested 
function come from?

In a purely dynamically scoped system, they would have to be defined when the user invokes the nested function.
However, in Haskell, implicit parameters behave as a combination of lexical and dynamic scoping. This means
that the nested function can capture the value of $\ident{?width}$ and require just $\ident{?size}$
In Haskell, this corresponds to the following type:
%
\begin{equation*}
(\ident{?width} :: \ident{Int}) \Rightarrow \ident{String} \rightarrow 
  ((\ident{?size} :: \ident{Int}) \Rightarrow \ident{String} \rightarrow \ident{string})
\end{equation*}
%
As a result, the function can be called as follows:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{formatHello} = \\
\quad(~\kvd{letdyn}~\ident{?width}=5~\kvd{in}\\
\quad~~\ident{format}~\texttt{"Hello"})~~\kvd{in}\\
\kvd{letdyn}~\ident{?size} = 10~\kvd{in}~\ident{formatHello}~\texttt{"world"}
\end{array}
\end{equation*}
%
This way of assigning type to \ident{format} and calling it is not the only possible, though. 
We could also say that the outer function requires both of the implicit parameters and the result
is a (pure) function with no context requirements. This interaction between implicit parameters 
and lambda abstraction demonstrates one of the key aspects of coeffects and will be discussed 
later. Implicit parameters will also sever as one of our examples in Chapter~Y.

%---------------------------------------------------------------------------------------------------

\paragraph{Type classes}
Implicit parameters are closely related to \emph{type classes} \cite{app-type-classes}. In Haskell,
type classes provide a principled form of ad-hoc polymorphism (overloading). When a code uses 
an overloaded operation (e.g.~comparison or numeric operators) a constraint is placed on the 
context in which the operation is used. For example:
%
\begin{equation*}
\begin{array}{l}
\ident{twoTimes}~::~\ident{Num}~\alpha \Rightarrow \alpha \rightarrow \alpha \\
\ident{twoTimes}~x=x+x
\end{array}
\end{equation*}
%
The constraint $\ident{Num}~a$ on the function type arises from the use of the $+$ operator. 
From the implementation perspective, the type class constraint means that the function takes 
a hidden parameter -- a dictionary that provides the operation $+ :: \alpha \rightarrow \alpha \rightarrow \alpha$.
Thus, the type $\ident{Num}~\alpha \Rightarrow \alpha \rightarrow \alpha$ can be viewed as
$(\ident{Num}_\alpha \times \alpha) \rightarrow \alpha$. Implicit parameters work in exactly
the same way -- they are passed around as hidden parameters.

The implementation of type classes and implicit parameters shows two important points about 
context-dependent properties. First, they are associated with some \emph{scope}, such as the body
of a function. Second, they are associated with the input. To call a function that takes an 
implicit parameter or has a type-class constraint, the caller needs to pass a (hidden) parameter
together with the function inputs.

%---------------------------------------------------------------------------------------------------

\paragraph{Rebindable resources}
The need for parameters that do not strictly follow static scoping rules also arises in distributed
computing. This problem has been addressed, for example, by Bierman et al. and Sewell et al. 
\cite{app-distributed-rebinding,app-distributed-acute}. To quote the first work: \emph{``Dynamic 
binding is required in various guises, for example when a marshalled value is received from the 
network, containing identifiers that must be rebound to local resources.''}

This situation arises when marshalling and transferring function values. A function may depend 
on a local resource (e.g.~a database available only on the server) and also resources that are 
available on the target node (e.g.~current time). In the following example, the construct
$\kvd{access}~\ident{Res}$ represents access to a re-bindable resource named $\ident{Res}$:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{recentEvents} = \lambda () \rightarrow\\
\quad\kvd{let}~\ident{db} = \kvd{access}~\ident{News}~\kvd{in}\\
\quad\ident{query}~\ident{db}~\str{"SELECT * WHERE Date > \%1"}~(\kvd{access}~\ident{Clock})
\end{array}
\end{equation*}
%
When \ident{recentEvents} is created on a server and sent to a client, a remote reference to the 
database (available only on the server) must be captured. If the client device supports a clock, 
then \ident{Clock} can be locally \emph{rebound}, e.g., to accommodate time-zone changes. 
Otherwise, the date and time needs to be obtained from the server too.

The use of re-bindable resources creates a context requirement similar to the one arising from
the use of implicit parameters. For function values, such context-requirements can be satisfied
in different ways -- resources must be available either at the declaration site (i.e.~when a 
function is created) or at the call site (i.e.~when a function is called).

%---------------------------------------------------------------------------------------------------

\paragraph{Distributed computing and multi-targetting}

An increasing number of programming languages is capable of running across multiple different 
platforms or execution environments. Functional programming languages that can be compiled to
JavaScript (to target web and mobile clients) include, among others, F\#, Haskell and OCaml \cite{app-ocaml-js}.

Links \cite{app-distributed-links}, F\# libraries \cite{app-fsharp-webapps,app-fsharp-webtools},
ML5 and QWeSST \cite{app-distributed-ml5, app-distributed-qwesst} and Hop \cite{app-hop-lang} go 
further and allow a single source program to be compiled to multiple target runtimes. This posses 
additional challenges -- it is necessary to track where each part of computation runs and statically 
guarantee that it will be possible to compile code to the required target platform 
(safe \emph{multi-targetting}).

We demonstrate the problem by looking at input validation. In distributed applications 
that communicate over unsecured HTTP channel, user input needs to be validated interactively
on the client-side (to provide immediate response) and then again on the server-side (to 
guarantee safety). For example:

\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{validateInput} = \lambda \ident{name} \rightarrow\\
\quad\ident{name} \neq \str{""} ~~\&\&~~ \ident{forall~isLetter~name}
\\[0.5em]
\kvd{let}~\ident{displayProduct} = \lambda \ident{name} \rightarrow\\
\quad\kvd{if}~\ident{validateInput name}~\kvd{then}~\ident{displayProductPage~name}\\
\quad\kvd{else}~\ident{displayErrorPage}~() 
\end{array}
\end{equation*}
%
The function \ident{validateInput} can be compiled to both JavaScript (for client-side) and
native code (for server-side). However, \ident{displayProduct} uses other functionality
(generating web pages) that is only available on the server-side, so it can only be compiled to
native code.

In Links \cite{app-distributed-links}, functions can be annotated as client-side, server-side
and database-side. F\# WebTools \cite{app-fsharp-webtools} adds functions that support multiple
targets (mixed-side). However, these are single-purpose language features and they are not 
extensible. For example, in modern mobile development it is also important to track minimal 
supported version of runtime\footnote{Android Developer guide \cite{app-android-multitarget} 
demonstrates how difficult it is to solve the problem without language support.}. 

Requirements on the execution environment can be viewed as contextual properties, but could be
also presented as effects (use of some API required only in certain environment is a computational
effect). We discuss the difference in Section~X. Furthermore, the theoretical foundations of
distributed languages like ML5 \cite{app-distributed-ml5} suggest that a contextual treatment
is more appropriate. We return to ML5 when discussing semantics in Section~\ref{sec:path-sem-contextdep}.

% --------------------------------------------------------------------------------------------------

\paragraph{Safe locking}
In the previous examples, the context provides additional values or functions that may be accessed
at runtime. However, it may also track \emph{permissions} to perform some operation. This is done
in the type system for safe locking of Flanagan and Abadi \cite{app-safe-locking}.

The system prevents race conditions (by only allowing access to mutable state under a lock)
and avoids deadlocks (by imposing strict partial order on locks). The following 
program uses a mutable state under a lock:
%
\begin{equation*}
\begin{array}{l}
\kvd{newlock}~l:\rho~\kvd{in}\\
\kvd{let}~\ident{state}~=~\ident{ref}_\rho~10~\kvd{in}\\
\kvd{sync}~l~(!\ident{state})
\end{array}
\end{equation*}
%
The declaration \kvd{newlock} creates a lock $l$ protecting memory region $\rho$. We can than
allocate mutable variables in that memory region (second line). An access to mutable variable
is only allowed in scope that is protected by a lock. This is done using the \kvd{sync} keyword,
which locks a lock and evaluates an expression in a context that contains permission to access
memory region of the lock ($\rho$ in the above example).

The type system for safe locking associates the list of permission with the variable context.
It uses judgements of a form $\Gamma, m \vdash e : \alpha$ specifying that an expression has a
type in context $\Gamma$, given permissions (a list of locked regions) $m$. However, the treatment
of lambda abstraction differs from the one for implicit parameters or rebindable resources.
In the system for locking, code inside lambda function cannot use permissions from the scope
where the function is declared. This is a necessary requirement -- a lambda function created 
under a lock cannot access protected memory, because it will be executed later. We discuss how
this restriction fits into our general coeffect framework in Section~X.Y.

%
% => This has coeffect style judgments, but it has effect-style lambda
%

%---------------------------------------------------------------------------------------------------

\paragraph{Data-flow languages}

The examples discussed so far are all -- to some extent -- similar. They attach additional 
information (implicit parameters, dictionaries) or restrictions (on execution environment) to the
context where code evaluates. By \emph{context}, we mean, most importantly, the values of variables
and declarations that are in scope. The examples so far add more information to the context, but
do not operate on the variable values.

Data-flow languages provide a different example. Lucid \cite{app-lucid} is a declarative data-flow 
language designed by Wadge and Ashcroft. In Lucid, variables represent streams and programs
are written as transformations over streams. A function application $\mathit{square}(a)$ represents
a stream of squares calculated from the stream of values $a$.

The data-flow approach has been successfully used in domains such as development of real-time embedded 
application where many \emph{synchronous languages} \cite{app-synchronous-lang} build on the data-flow
paradigm. The following example is inspired by the Lustre \cite{app-synchronous-lustre} language
and implements program to count the number of edges on a Boolean stream:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{edge} = \ident{false}~\kvd{fby}~(\ident{input}~\&\&~\ident{not}~(\kvd{prev}~\ident{input}))
\\[0.5em]
\kvd{let}~\ident{edgeCount} = \\
\quad 0~\kvd{fby}~ (~\kvd{if}~\ident{edge}~\kvd{then}~\kvd{prev}~\ident{edgeCount}\\
\quad\quad\quad~~~\, \kvd{else}~\kvd{prev}~\ident{edgeCount} ~)
\end{array}
\end{equation*}
%
The construct $\kvd{prev}~x$ returns a stream consisting of previous values of the stream 
$x$. The second value of $\kvd{prev}~x$ is first value of $x$ (and the first
value is undefined). The construct $y~\kvd{fby}~x$ returns a stream whose first element is the 
first element of $y$ and the remaining elements are values of $x$. Note that in Lucid, the constants
such as \ident{false} and $0$ are constant streams. Formally, the construct are defined as follows
(writing $x_n$ for $n$-th element of a stream $x$):
%
\[ 
(\kvd{prev}~x)_n = \left\{ 
  \begin{array}{ll}
    nil     & \; \text{if $n=0$}\\
    x_{n-1} & \; \text{if $n>0$}
  \end{array} \right.
\quad
(y~\kvd{fby}~x)_n = \left\{ 
  \begin{array}{ll}
    y_0     & \; \text{if $n=0$}\\
    x_n     & \; \text{if $n>0$}
  \end{array} \right.
\]  
%
When reading data-flow programs, we do not need to think about variables in terms of streams --
we can see them as simple values. However, the operations \kvd{fby} and \kvd{prev} cannot operate
on plain values -- they require additional \emph{context} which provides past values of variables
(for \kvd{prev}) and information about the current location in the stream (for \kvd{fby}). 

In this case, the context is not simply an additional (hidden) parameter. It completely changes
how variables must be represented. We may want to capture various \emph{contextual properties}
of Lucid programs. For example, how many past elements need to be cached when we evaluate the 
stream.

To understand the nature of the context, we later look at the semantics of Lucid. This can be
captured using a number of mathematical structures. Wadge \cite{app-lucid-monads} originally 
proposed to use monads, while Uustalu and Vene later used comonads \cite{app-dataflow-essence}.

% ==================================================================================================

\section{Flat coeffects (2.)}

% --------------------------------------------------------------------------------------------------
\subsection{Implicit parameters and resources.}
\label{sec:coeffects-res}

Implicit parameters~\cite{app-implicit-parameters} are \emph{dynamically-scoped} variables.
They can be used to parameterize a computation without propagating arguments explicitly through a 
chain of calls and are part of the context in which expressions evaluate. As correctly expected
\cite{app-implicit-parameters}, they can be modelled by comonads. Rebindable resources in distributed
computations follow a similar pattern, but we discuss implicit parameters for simplicity.

The following function prints a number using implicit parameters
\ident{?culture} (determining the decimal mark) and \ident{?format}
(the number of decimal places):
%
\begin{equation*}
\lambda n . \ident{printNumber}~n~\ident{?culture}~\ident{?format}
\end{equation*}
%
Figure~\ref{fig:example-resources} shows a type-and-coeffect system
tracking the set of an expression's implicit parameters. 
For simplicity here, all implicit parameters have type $\rho$.

Context requirements are created in (\emph{access}), while (\emph{var}) requires no
implicit parameters; (\emph{app}) combines requirements of
both sub-expressions as well as the latent requirements of the
function. The (\emph{abs}) rule is where the example differs from
effect systems.  Function bodies can access the union of the
parameters (or resources) available at the declaration-site ($\ctyp{r}{\Gamma}$) and
at the call-site ($\ctyp{s}{\tau_1}$). Two of the nine permissible
judgements for the above example are:
%
\newcommand{\cfebody}{(\ldots)} % \ident{countFutureEvents}
\begin{equation*}
\begin{array}{rcl}
\ctyp{\emptyset}{\Gamma} &\vdash& \cfebody : \ctyp{\{\ident{?culture}, \ident{?format} \}}{\ident{int}} \rightarrow \ident{string}\\
\ctyp{\{\ident{?culture}, \ident{?format}\}}{\Gamma} &\vdash& \cfebody : \ctyp{\{\ident{?format}\}}{\ident{int}} \rightarrow \ident{string}
\end{array}
\end{equation*}
%
The coeffect system infers multiple, \ie{} non-principal, coeffects for functions.
Different judgments are desirable depending on how a function is used. 
In the first case, both parameters have to be provided by the caller.
In the second, both are available at declaration-site, but \ident{?format} may be
rebound (precise meaning is provided by the monoidal structure on the product comonad in \S\ref{sec:comonads}).

Implicit parameters can be captured by the
\emph{reader} monad, where parameters are associated with the function codomain $\mtyp{\emptyset}{(\ident{int} \rightarrow
  \mtyp{\{\ident{?culture}, \ident{?format} \}}{\ident{string}})}$,
modelling only the first case. Whilst the reader monad can be extended to model rebinding, 
the next example cannot be structured by \emph{any} monad.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\vspace{-1.4em}
\begin{equation*}
\inference[(\emph{var})\;]
  {x : \tau \in \Gamma}
  {\ctyp{\emptyset}{\Gamma} \vdash x : \tau }
%
\quad\quad
%
\inference[(\emph{app})\;]
  {\ctyp{r}{\Gamma} \vdash e_1 : \ctyp{t}{\tau_1} \rightarrow \tau_2 &
   \ctyp{s}{\Gamma} \vdash e_2 : \tau_1 }
  {\ctyp{r \cup s \cup t}{\Gamma} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\vspace{-0.7em}
\begin{equation*}
\inference[(\emph{access})\;]
  {}
  {\ctyp{ \{\ident{?a} \} }{\Gamma} \vdash \ident{?a} : \rho }
%
\quad\quad\quad
%
\inference[(\emph{abs})\;]
  {\ctyp{r \cup s}{(\Gamma, x:\tau_1)} \vdash e : \tau_2}
  {\ctyp{r}{\Gamma} \vdash \lambda x.e : \ctyp{s}{\tau_1} \rightarrow \tau_2 }
\end{equation*}
\vspace{-0.9em}
\caption{Selected coeffect rules for implicit parameters}
\label{fig:example-resources}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\begin{figure}[!b]
\vspace{-2em}
\begin{equation*}
\inference[(\emph{var})\;]
  {x : \tau \in \Gamma}
  {\ctyp{\ident L}{\Gamma} \vdash x : \tau }
\quad
\inference[(\emph{app})\;]
  { \ctyp{s}{\Gamma} \vdash e_2 : \tau_1 &
    \ctyp{r}{\Gamma} \vdash e_1 : \ctyp{t}{\tau_1} \rightarrow \tau_2 }
  {\ctyp{r \sqcup (s \sqcap t)}{\Gamma} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\vspace{-1.5em}
\caption{Selected coeffect rules for liveness analysis}
\label{fig:example-need}
\vspace{-1.2em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\vspace{-1em}
\subsection{Liveness analysis.}

Liveness analysis detects whether a free variable of an expression may be used (\emph{live}) or 
whether it is definitely not needed (\emph{dead}). A compiler can remove
bindings to dead variables as the result is never used. 

We start with a restricted analysis and briefly mention how to make it practical
later (\S\ref{sec:related}). The restricted form is interesting theoretically as it gives rise
to the indexed Maybe comonad (\S\ref{sec:comonads}), which is a basic but instructive example.

A coeffect system in Fig.~\ref{fig:example-need} detects whether all variables are dead 
($\ctyp{\ident D}{\Gamma}$) or whether at least one variable is live ($\ctyp{\ident L}{\Gamma}$). 
Variable access (\emph{var}) is annotated with \ident L and constant access with \ident D. That is,
if $c\in\mathbb{N}$ then $\ctyp{\ident D}{\Gamma} \vdash c : \ident{int}$.
A dead context may be marked as live by
letting $\ident D \sqsubseteq \ident L$ and adding sub-coeffecting (\S\ref{sec:calculus}).

The (\emph{app}) rule is best understood by discussing its semantics. Consider first 
\emph{sequential composition} of (semantic) functions $g, f$ annotated with $r, s$. 
The argument of $g \circ f$ is live only when arguments of both $f$ and $g$ are live. 
The coeffect semantics captures the additional behaviour that $f$ is not evaluated when
$g$ ignores its input (regardless of the evaluation order of the underlying language).
We write $r \sqcap s$ for a conjunction (returning \ident L iff $r = s = \ident{L}$). 
Secondly, a \emph{pointwise composition} passes the same
argument to $g$ and $h$. The parameter is live if either the parameter
of $g$ or $h$ is live ($r \sqcup s$). Application combines the
two operations, so the context $\Gamma$ is live if it is needed by
$e_1$ \emph{or} by the function value \emph{and} by $e_2$.

An (\emph{abs}) rule (not shown) compatible with the structure in Fig.~\ref{fig:example-resources}
combines the context annotations using $\sqcap$. Thus, if the body uses some 
variables, both the function argument and the context of the declaration-site are marked as live.

Liveness cannot be modelled using monads as $\tau_1 \rightarrow \mtyp{r}{\tau_2}$.
In call-by-value languages, the argument $\tau_1$ is always evaluated. Using 
indexed comonads (\S\ref{sec:comonads}), we
model liveness as $\ctyp{r}{\tau_1} \rightarrow \tau_2$ where
$\ctyp{r}$ is the parametric type $\mathsf{Maybe}~\tau = \tau + 1$
(which contains a value $\tau$ when $r=\ident{L}$ and does not contain
value when $r=\ident{D}$).

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\vspace{-1em}
\begin{equation*}
\inference[(\emph{var})\;]
  {x : \tau \in \Gamma}
  {\ctyp{0}{\Gamma} \vdash x : \tau }
%
\quad\quad
% 
\inference[(\emph{app})\;]
  {\ctyp{m}{\Gamma} \vdash e_1 : \ctyp{p}{\tau_1} \rightarrow \tau_2 &
   \ctyp{n}{\Gamma} \vdash e_2 : \tau_1 }
  {\ctyp{\textit{max}(m, n + p)}{\Gamma} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\inference[(\emph{prev})\;]
  {\ctyp{n}{\Gamma} \vdash e : \tau}
  {\ctyp{n+1}{\Gamma} \vdash \kvd{prev}~e : \tau}
%
\quad\quad
%
\inference[(\emph{abs})\;]
  {\ctyp{\textit{min}(m, n)}{(\Gamma, x:\tau_1)} \vdash e : \tau_2}
  {\ctyp{m}{\Gamma} \vdash \lambda x.e : \ctyp{n}{\tau_1} \rightarrow \tau_2 }
\end{equation*}
\vspace{-1em}
\caption{Selected coeffect rules for causal data flow}
\label{fig:example-dataflow}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\vspace{-1em}
\subsection{Efficient dataflow.}
Dataflow languages (\eg~\cite{app-lucid}) declaratively describe
computations over streams. In \emph{causal} data flow, program may
access past values -- in this setting, a function $\tau_1 \rightarrow
\tau_2$ becomes a function from a list of historical values $[\tau_1]
\rightarrow \tau_2$. A coeffect system here tracks how many past values
to cache.

Figure~\ref{fig:example-dataflow} annotates contexts with an integer specifying the maximum
number of required past values. The current value is always present, so (\emph{var}) is annotated with $0$.
The expression $\kvd{prev}~e$ gets the previous value of stream $e$ and requires one
additional past value (\emph{prev}); \eg~$\kvd{prev}~(\kvd{prev}~e)$ requires 2 past values.

The (\emph{app}) rule follows the same intuition as for liveness. Sequential composition
adds the tags (the first function needs $n + p$ past values to produce $p$ past inputs
for the second function); passing the context to two subcomputations requires the maximum
number of the elements required by the two subcomputations. The (\emph{abs}) rule for data-flow 
needs a distinct operator -- \emph{min} -- therefore, the declaration-site and 
call-site must each provide at least the number of past values required by the function body
(the body may use variables coming from the declaration-site as well as the argument).

The soundness follows from our categorical model (\S\ref{sec:comonads}). Uustalu and Vene
\cite{comonads-notions} model causal dataflow computations using a non-empty list comonad 
$\ident{NeList}~\tau = \tau \times (\ident{NeList}~\tau + 1)$. However, such model leads to
(inefficient) unbounded lists of past elements. The above static analysis provides an
approximation of the number of required past elements and so we use just fixed-length lists.

% ==================================================================================================

\section{Structural coeffects (1.)}

We now turn our attention to system where additional contextual information are associated not
with the context as a whole (or program scope), but with individual variables. We start by looking
simple static analysis -- variable \emph{liveness}. Then we revisit data-flow computations and
look at applications in security and software updating.

%---------------------------------------------------------------------------------------------------

\paragraph{Liveness analysis}

\emph{Live variable analysis} (LVA) \cite{app-modern-compiler} is a standard technique in compiler theory. 
It detects whether a free variable of an expression may be used by a program later (it is
\emph{live}) or whether it is definitely not needed (it is \emph{dead}). As an optimization, 
compiler can remove bindings to dead variables as the result is never accessed. Wadler 
\cite{app-strictness-absecnce} describes the property of a variable that is dead as the 
\emph{absence} of a variable. 

In this thesis, we first use a restricted (and not practically useful) form of liveness analysis
to introduce the theory of indexed comonads (Section~X) and then use liveness analysis as one of the
motivations for structural coeffects. Consider the following two simple functions:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{constant42} = \lambda \ident{x} \rightarrow 42\\
\kvd{let}~\ident{constant} = \lambda \ident{value} \rightarrow \lambda \ident{x} \rightarrow \ident{value}
\end{array}
\end{equation*}
%
In liveness analysis, we annotate the context with a value specifying whether the variables in
scope are \emph{live} or \emph{dead}. If we associate just a single value with the entire 
context, then the liveness analysis is very limited -- it can say that the context of the 
expression $42$ in the first function is dead, because no variables are accessed. 

A useful liveness analysis needs to consider individual variables. For example, in the body of
the second function (\ident{value}), two variables are in scope. The variable \ident{value} is
accessed and thus is \emph{live}, but the variable \ident{x} is dead.

Static analyses can be classified as either \emph{forward} or \emph{backward} (depending on how they 
propagate information) and as either \emph{must} or \emph{may} (depending on what properties they
guarantee). Liveness is a \emph{backward} analysis -- this means that the requirements propagates
from variables to their declaration sites. The distinction between \emph{must} and \emph{may} is 
apparent when we look at an example with conditionals:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{defaultArg}~= \lambda \ident{cond} \rightarrow \lambda \ident{input} \rightarrow\\
\quad\kvd{if}~\ident{cond}~\kvd{then}~42~\kvd{else}~\ident{input}
\end{array}
\end{equation*}
%
The liveness analysis is a \emph{may} analysis meaning that it marks variable as live when it
\emph{may} be used and as dead if it is \emph{definitely} not used. This means that the variable
\ident{input} is \emph{live} in the example above. A \emph{must} analysis would mark the variable
only if it was used in both of the branches (this is sometimes called \emph{neededness}).

The distinction between \emph{may} and \emph{must} analyses demonstrates the importance of 
interaction between contextual properties and certain language constructs such as conditionals.

% --------------------------------------------------------------------------------------------------

\paragraph{Data-flow languages (revisited)}
When discussing data-flow languages in the previous section, we said that the context provides 
past values of variables. This can be viewed as a flat contextual property (the context needs
to keep all past values), but we can also view it as a structural property. Consider the following
example:
%
\begin{equation*}
\kvd{let}~\ident{offsetZip} = 0~\kvd{fby}~(\ident{left} + \kvd{prev}~\ident{right})
\end{equation*}
%
The value \ident{offsetZip} adds values of \ident{left} with previous values of \ident{right}.
To evaluate a current value of the stream, we need the current value of \ident{left} and one past
value of \ident{right}. 

As mentioned earlier, a static analysis for data-flow computations could calculate how many past 
values must be cached. This can be done as a \emph{flat} coeffect analysis that produces just a 
single number for each function. However, we can design a more precise \emph{structural} analysis
and track the number of required elements for individual variables.

% --------------------------------------------------------------------------------------------------

\paragraph{Tainting and provenance}
Tainting is a mechanism where variables coming from potentially untrusted sources are marked
(\emph{tainted}) and the use of such variables is disallowed in contexts where untrusted input
can cause security issues or other problems. Tainting can be done dynamically as a runtime mark
(e.g.~in the Perl language) or statically using a type system. Tainting can be viewed as a special
case of \emph{provenance tracking}, known from database systems \cite{app-provenance-db}, where
values are annotated with more detailed information about their source.

Statically typed systems that based on tainting have been use to prevent cross-site scripting
attacks \cite{app-tainting-xss} and a well known attack known as SQL injection
\cite{app-tainting-sql,app-tainting-wasp}. In the latter chase, we want to check that SQL commands 
cannot be directly constructed from, potentially dangerous, inputs provided by the user. Consider the 
type checking of the following expression in a context containing variables \ident{id} and \ident{msg}:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{name} = \ident{query}~(\str{"SELECT Name WHERE Id = "}~+~\ident{id})~\kvd{in}\\
\ident{msg}~+~\ident{name}
\end{array}
\end{equation*}
%
In this example, \ident{id} must not come directly from a user input, because \ident{query} requires 
untainted string. Otherwise, the attacker could specify values such as \str{"1; DROP TABLE Users"}. 
The variable \ident{msg} may or may not be tainted, because it is not used in protected context 
(i.e.~to construct an SQL query). 

In runtime checking, all (string) values need to be wrapped in an object that stores Boolean 
flag (for tainting) or more complex data (for provenance). In static checking, the information
need to be associated with the variables in the variable context. We use tainting as a motivating
example for \emph{structural} coeffects in Section~X.

% --------------------------------------------------------------------------------------------------

\paragraph{Security and core dependency calculus}

The checking of tainting is a special case of checking of the \emph{non-interference} property 
in \emph{secure information flow}. Here, the aim is to guarantee that sensitive information (such
as credit card number) cannot be leaked to contexts with low secrecy (e.g.~sent via an unsecured
network channel). Volpano et al. \cite{app-secure-flow} provide the first (provably) sound type 
system that guarantees non-inference and Sabelfeld et al. \cite{app-secure-information-flow} survey
more recent work. The checking of information flows has been also integrated (as a single-purpose
extension) in the FlowCaml \cite{app-security-flowcaml} language. Finally, Russo et al. and 
Swamy et al. \cite{monad-secure-flow,monads-lightweight-ml} show that the properties can be checked
using a monadic library.

Systems for secure information flow typically define a lattice of security classes $(\mathcal{S}, \leq)$
where $\mathcal{S}$ is a finite set of classes and an ordering. For example a set $\{\ident{L}, \ident{H}\}$ 
represents low and high secrecy, respectively with $\ident{L} \leq \ident{H}$ meaning that low security
values can be treated as high security (but not the other way round).

An important aspect of secure information flow is called \emph{implicit flows}. Consider the following
example which may assign a new value to $z$:
%
\begin{equation*}
\kvd{if}~x>0~\kvd{then}~z := y
\end{equation*}
%
If the value of $y$ is high-secure, then $z$ becomes high-secure after the assignment
(this is an \emph{explicit} flow). However, if $x$ is high-secure, then the value of
$z$ becomes high-secure, regardless of the security level of $y$, because the fact whether an 
assignment is performed or not performed leaks information in its own (this is an 
\emph{implicit} flow).

Abadi et al. realized that there is a number of analyses similar to secure information flow
and proposed to unify them using a single model called Dependency Core Calculus (DCC) \cite{app-dcc}.
It captures other cases where some information about expression relies on properties of variables
in the context where it executes.  The DCC captures, for example, \emph{binding time analysis}
\cite{app-binding-time-analysis}, which detects which parts of programs can be partially evaluated
(do not depend on user input) and \emph{program slicing} \cite{app-slicing-survey} that identifies
parts of programs that contribute to the output of an expression.
	
%===================================================================================================

\section{Structural coeffects}
\label{sec:intro-coeffects}

Coeffects are way to describe notions of context in programming that keep turning up. 
To illustrate this, we overview three systems tracking contextual properties that 
 motivate our general coeffect system. Two systems track per-variable properties (bounded 
linear logic and dataflow) and one tracks whole-context properties (implicit parameters).

\subsection{Bounded reuse}
\label{sec:intro-coeffects-bll}

Bounded linear logic \cite{girard1992bounded} restricts well-typed terms to polynomial-time algorithms.  
This is done by limiting the number of times a value (proposition) can be used. An assumption
$!_k A$ means that a variable can be used at most $k$ times. 
We attach annotations to the whole context rather than individual assumptions and so a context
$!_{k_1} A_1, ..., !_{k_n} A_n$ is written as $\coctx{\tau_1, ..., \tau_n}{\langle \cclrd{k_1}, ..., \cclrd{k_n}\rangle}$. 
This difference is further explained in Section~\ref{sec:related-work}. %For uniformity
%with later systems, we also write assumptions $A$ as $\tau$ and annotations $K$ as $\cclrd{r}$.

Bounded linear logic includes explicit weakening and contraction rules
that affect the multiplicity. Following the original logical style (but with our notation), these are written as:
\[
\inference
  {\coctx{\Gamma}{\aclrd{R}} \vdash \tau}
  {\coctx{\Gamma,\sigma}{\aclrd{R} \cons \alift{0}} \vdash \tau} 
\quad
\inference
  {\coctx{\Gamma_1,\sigma,\sigma,\Gamma_2}{\aclrd{R}\cons \alift{\cclrd{s},\cclrd{t}} \cons \aclrd{Q}} \vdash \tau}
  {\coctx{\Gamma_1,\sigma,\Gamma_2}{\aclrd{R}\cons\alift{\cclrd{s}+\cclrd{t}} \cons \aclrd{Q}} \vdash \tau}
\]
The context $\coctx{\Gamma}{\aclrd{R}}$ includes a \emph{coeffect annotation} $\aclrd{R}$ which is a vector
$\alift{\cclrd{r_1}, \ldots, \cclrd{r_n}}$ of the same length as $\Gamma$ (a side-condition omitted for brevity).
In weakening (left), unused propositions are annotated with $0$ (no uses), while in contraction (right), multiple 
occurrences of a proposition are joined by adding the number of uses.


\begin{figure}[t]
\vspace{-0.5em}
\begin{align*}
\begin{array}{c}
%
\hspace{-0.6em}
\begin{array}{c}
\tyrule{var}{}
  {\coctx{x \!:\! \tau}{\alift{1}} \vdash x : \tau} 
\quad 
\tyruleCompact{weak}
  {\coctx{\Gamma}{R} \vdash e : \tau}
  {\coctx{\Gamma,x \!:\! \sigma}{\aclrd{R} \cons \alift{0}} \vdash e : \tau} 
\\[1.8em]
\tyruleCompact{sub}
  {\coctx{\Gamma}{\aclrd{R}} \vdash e : \tau}
  {\coctx{\Gamma}{\aclrd{R'}} \vdash e : \tau}~(\text{\scriptsize $\aclrd{R} \leq \aclrd{R'}$})
\quad 
\tyrule{abs}
  {\coctx{\Gamma, x \!:\! \sigma}{\aclrd{R} \cons \alift{s}} \vdash e : \tau}
  {\coctx{\Gamma}{\aclrd{R}} \vdash \lambda x . e : \sigma \xrightarrow{\cclrd{s}} \tau} 
\\[1.2em]
\end{array} \\
%
% ------------------------ 
%
\begin{array}{c}
\tyrule{app}
  { \coctx{\Gamma_1}{\aclrd{R}} \vdash e_1 : \sigma \xrightarrow{\cclrd{t}} \tau \quad 
    \coctx{\Gamma_2}{\aclrd{S}} \vdash e_2 : \sigma}
  { \coctx{\Gamma_1, \Gamma_2}{\aclrd{R} \cons (\cclrd{t} \ast \aclrd{S})} \vdash e_1 \, e_2 : \tau} 
\\[1.3em]
\tyrule{contr}
  {\coctx{\Gamma_1,y\!:\!\sigma,z\!:\!\sigma,\Gamma_2}{\aclrd{R}\cons \alift{\cclrd{s},\cclrd{t}} \cons \aclrd{Q}} \vdash e : \tau}
  {\coctx{\Gamma_1,x\!:\!\sigma,\Gamma_2}{\aclrd{R}\cons\alift{\cclrd{s}+\cclrd{t}} \cons \aclrd{Q}} \vdash \subst{e}{z,y}{x} : \tau}
\\[1.3em]
\tyrule{exch}
  {\coctx{\Gamma_1,x\!:\!\sigma',y\!:\!\sigma,\Gamma_2}{\aclrd{R}\cons\alift{\cclrd{s},\cclrd{t}} \cons \aclrd{Q}} \vdash e : \tau}
  {\coctx{\Gamma_1,y\!:\!\sigma,x\!:\!\sigma',\Gamma_2}{\aclrd{R}\cons\alift{\cclrd{t},\cclrd{s}} \cons \aclrd{Q}} \vdash e : \tau}
\end{array} 
% ------------------------ 
%
% \hspace{-1em}
%\begin{array}{c}
%
% TP: I removed the 'let' rule again because we do not need it to explain the storage axiom here.
% Also, I think the BLL sample is already used to explain quite a lot of things, so I'd be happier
% to keep it simple.
%
% BTW: The \tyruleCompact macro creates a rule that *looks* differently..
% (I do not understand why but it makes the line somehow thicker...)
%
% \tyruleCompact{let}
%   {\coctxs{\Gamma_1, v : \sigma}{R \times \langle{t}\rangle} \vdash e_1 : \tau \quad 
%    \coctxs{\Gamma_2}{S} \vdash e_2 : \sigma}
%   {\coctxs{\Gamma_1, \Gamma_2}{R \times (t \ast S)} \vdash \kvd{let}~x=e_2~\kvd{in}~e_1 : \tau} \\[1.8em]
\end{array}
\end{align*}
\vspace{-0.5em}
\caption{type and coeffect system for bounded reuse}
\label{fig:bounded-coeff}
\end{figure}


\paragraph{Bounded linear coeffects.}
The system in Figure~\ref{fig:bounded-coeff} extends the outlined idea into a simple calculus.
Variable access (\emph{var}) has a singleton context with a singleton coeffect vector
$\alift{1}$. Weakening (\emph{weak}) extends the free-variable context with an unused variable and 
the coeffect with an associated scalar $0$. Explicit contraction (\emph{contr}) and
exchange (\emph{exch}) rules manipulate variables in the context and
modify the annotations accordingly -- adding the number of uses in
contraction and switching vector elements in exchange.

For abstraction (\emph{abs}), we know the number of uses of the parameter variable $x$ 
and attach it to the function type $\sigma \xrightarrow{\cclrd{s}}
\tau$ as a \emph{latent} coeffect. The remaining variables in $\Gamma$ are 
annotated with the remaining coeffect vector $\aclrd{R}$, specifying \emph{immediate} coeffects.

Application (\emph{app}) describes call-by-name evaluation.  Applying
a function that uses its parameter $\cclrd{t}$-times to an argument
that uses variables in $\Gamma_2$ $\aclrd{S}$-times means that, in
total, the variables in $\Gamma_2$ will be used $(\cclrd{t} \ast \aclrd{S})$-times. 
Recall that $\cclrd{t} \ast \aclrd{S}$ is a scalar multiplication of a
vector. Meanwhile, the variables in $\Gamma_1$ are used just
$\aclrd{R}$-times when reducing the expression $e_1$ to a function
value. 

Finally, the sub-coeffecting rule (\emph{sub}) safely overapproximates
the number of uses using the pointwise
$\leq$ relation. We can view any variable as being used a greater
number of times than it actually is.

\paragraph{Example.} To demonstrate, consider a term
$(\lambda v.x+v+v)~(x+y)$. According to the call-by-name intuition, the variable $x$ is used three 
times -- once directly inside the function and twice via the variable $v$ after 
substitution. Similarly, $y$ is used 
twice. Assuming a judgment for the function body, abstraction yields:
%
\begin{equation*}
\tyrule{abs}
 { \coctx{x\!:\!\mathbb{Z},v:\mathbb{Z}}{\alift{\cclrd{1},\cclrd{2}}} \vdash x+v+v : \mathbb{Z} }
 { \coctx{x\!:\!\mathbb{Z}}{\alift{\cclrd{1}}} \vdash (\lambda v.x+v+v) : \mathbb{Z} \xrightarrow{\cclrd{2}} \mathbb{Z} }
\end{equation*}
%
To avoid name clashes, we $\alpha$-rename $x$ to $x'$ and later join $x$ and $x'$ using contraction.
Assuming $(x'+y)$ is checked in a context that marks $x'$ and $y$ as used once, the application rule yields
a judgment that is simplified as follows:
\[
\hspace{-0.7em}\inference
  { \coctx{x\!:\!\mathbb{Z},x'\!:\!\mathbb{Z},y\!:\!\mathbb{Z}}
          {\alift{\cclrd{1}} \cons (\cclrd{2} \ast \alift{\cclrd{1},\cclrd{1}}) } \vdash (\lambda v.x+v+v)~(x'+y) : \mathbb{Z} }
{\inference
  { \coctx{x\!:\!\mathbb{Z},x'\!:\!\mathbb{Z},y\!:\!\mathbb{Z}}{\alift{\cclrd{1}, \cclrd{2}, \cclrd{2}} } \vdash (\lambda v.x+v+v)~(x'+y) : \mathbb{Z} }
  { \coctx{x\!:\!\mathbb{Z},y\!:\!\mathbb{Z}}{\alift{\cclrd{3}, \cclrd{2}}} \vdash (\lambda v.x+v+v)~(x+y)  : \mathbb{Z}} }
\]
%
The first step performs scalar multiplication, producing the vector
$\alift{\cclrd{1},\cclrd{2},\cclrd{2}}$. In the second step, we use contraction to join variables 
$x$ and $x'$ from the function and argument terms respectively.

It is worth pointing out that reduction by substitution yields $x+(x+y)+(x+y)$ which has the same coeffect as
the original. We return to evaluation strategies in Section~\ref{sec:syntax}, and 
show that structural coeffect systems preserve types and coeffects under $\beta$-reduction. 

% --------------------------------------------------------------------------------------------------

\subsection{Dataflow and data access}

Dataflow languages such as Lucid \cite{wadge1985lucid} describe computations over \emph{streams}.
An expression is re-evaluated when new inputs are available (push) or when more output
is demanded (pull).  In causal dataflow, programs can access past
values of a stream. We consider a language where $\kvd{prev}~e$
returns the previous value of $e$, where 
$\kvd{prev}~(\kvd{prev}~e)$ therefore returns the second past value.

An implementation of causal dataflow may cache past values of
variables as an optimisation. The question is, how many past values
should be cached?  This can be approximated by a coeffect system.

\paragraph{Dataflow coeffects.} The coeffect system for dataflow is
similar to the one for bounded reuse in that it tracks a vector
of numbers $\aclrd{R}$ as part of the context
$\coctx{\Gamma}{\aclrd{R}}$. Here, coeffects represent the maximal number of
past values (\emph{causality depth}) required for a variable. 

Weakening, exchange, abstraction and sub-coeffecting are the same as in bounded linear
coeffects, but the remaining rules differ. In Figure~\ref{fig:dataflow-coeff},
accessed variables (\emph{var}) are annotated with
$0$ meaning that no past value is required (only the
current one). The (\emph{prev}) rule crates caching requirements --
it increments the number of required values for all variables
used in $e$ using scalar-vector addition.

Application and contraction have the same structure as before, 
but use different operators. If two variables 
are contracting, requiring $\cclrd{s}$ and $\cclrd{t}$ past
values, then overall we need at most
$\ident{max}(\cclrd{s}, \cclrd{t})$ past values (\emph{contr}). That is, 
two caches are combined with the maximum of the two requirements, 
which satisfy the smaller requirements. 

In (\emph{app}), the function requires $\cclrd{t}$ past values of
its parameter.  This means $\cclrd{t}$ past values of
$e_2$ are needed which in turn requires $\aclrd{S}$ past values of its free
variables $\Gamma_2$. Thus, we need $\cclrd{t}+\aclrd{S}$ past values of $\Gamma_2$ to perform the
call (\eg{}, we need $1+\aclrd{S}$ values to
get $1$ past value of the input $\sigma$, $2+\aclrd{S}$
values to get $2$ past values of $\sigma$, \emph{etc.}).


\paragraph{Example.} As an example, consider a function $\lambda x.\kvd{prev}~(y+x)$ applied to an argument
$\kvd{prev}~(\kvd{prev}~y)$. The body of the function accesses the past value of two variables, one free
and one bound:
\[
\dfrac
  {\coctx{y\!:\!\mathbb{Z}, x\!:\!\mathbb{Z}}{\alift{1, 1}} \vdash \kvd{prev}~(y+x) : \mathbb{Z} }
  {\coctx{y\!:\!\mathbb{Z}}{\alift{1}} \vdash \lambda x . \kvd{prev}~(y+x) : \mathbb{Z} \xrightarrow{\cclrd{1}} \mathbb{Z} }
\]
The expression always requires the previous value of $y$ and adds it to
a previous value of the parameter $x$. Evaluating the value of the
argument $\kvd{prev}~(\kvd{prev}~y)$ requires two past values of $y$
and so the overall requirement is $3$ past values:
\[
\inference
  { \coctx{y\!:\!\mathbb{Z}}{\alift{1} } \vdash \lambda x.~(\ldots) \quad  \coctx{x\!:\!\mathbb{Z}}{\alift{2}} \vdash (\kvd{prev}~(\kvd{prev}~x) : \mathbb{Z} }
{\inference
  { \coctx{y\!:\!\mathbb{Z}, x\!:\!\mathbb{Z}}{\alift{1,3}} \vdash (\lambda x.\kvd{prev}~(y+x))~(\kvd{prev}~(\kvd{prev}~x)) : \mathbb{Z} }
  { \coctx{y\!:\!\mathbb{Z}}{\alift{3}} \vdash (\lambda x.\kvd{prev}~(y+x))~(\kvd{prev}~(\kvd{prev}~y)) : \mathbb{Z} } }
\]
The derivation uses (\emph{app}) to get requirements $\alift{1,3}$ and then 
(\emph{contr}) to take the maximum, showing three past values are sufficient. Reducing 
the expression by substitution we get $\kvd{prev}~(y+(\kvd{prev}~(\kvd{prev}~y)))$. 
Semantically, this performs stream lookups $y[1] + y[3]$ where the indices are the 
number of enclosing $\kvd{prev}$s.% expressions.

We previously used dataflow as an example of
coeffects~\cite{petricek2013coeffects}, but tracked caching
requirements on the whole context. The system outlined here is more
powerful and practically useful, with finer-grained coeffects tracking
caching requirements per-variable.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\[
\tyrule{contr}
  {\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{R}\cons\alift{\cclrd{s},\cclrd{t}} \cons \aclrd{Q}} \vdash e : \tau}
  {\coctx{\Gamma_1,x\!:\!\tau,\Gamma_2}{\aclrd{R}\cons\alift{\ident{max}(\cclrd{s},\cclrd{t})} \cons \aclrd{Q}} \vdash \subst{e}{y,z}{x} : \tau}
\]
\[
\tyrule{app}
  { \coctx{\Gamma_1}{\aclrd{R}} \vdash e_1 : \sigma \xrightarrow{\cclrd{t}} \tau &
    \coctx{\Gamma_2}{\aclrd{S}} \vdash e_2 : \sigma }
  { \coctx{\Gamma_1, \Gamma_2}{\aclrd{R} \cons (\cclrd{t} + \aclrd{S})} \vdash e_1 \, e_2 : \tau} 
\]
\[
\tyrule{var}{}
  {\coctx{x\!:\!\tau}{\alift{0}} \vdash x : \tau}
\quad\;
\tyrule{prev}
  {\coctx{\Gamma}{\aclrd{R}} \vdash e : \tau}
  {\coctx{\Gamma}{1 + \aclrd{R}} \vdash \kvd{prev}~e : \tau}  
\]
\caption{type and coeffect system for dataflow caching}
\label{fig:dataflow-coeff}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsection{Implicit parameters}
\label{sec:intro-coeffects-impl}

As our third example, we revisit Haskell implicit parameters \cite{lewis2000implicit} 
used in our earlier coeffect work \cite{petricek2013coeffects}. Implicit parameters are variables
that mix aspects of dynamic and lexical scoping. Implicit parameters are a distinct syntactic 
category to variables and we write them as \ident{?p}. For simplicity, we omit \emph{let}-binding for
implicit parameters and focus just on tracking requirements.

\paragraph{Implicit parameters coeffects.} Implicit parameters are a whole-context coeffect 
not linked to ordinary variables. We keep track of sets of implicit parameters that are required
by an expression (and their types). For example $\coctx{\Gamma}{\{ \ident{?p}_1 : \tau_1, \ldots, \ident{?p}_n : \tau_n \}}$
means that a context provides ordinary variables $\Gamma$ and values for implicit parameters $\ident{?p}_i$.
Unlike in the previous examples, we no longer need to distinguish between coeffects attached
to variables (scalars) and coeffects attached to contexts (vectors), so we write $\cclrd{r},\cclrd{s},\cclrd{t}$
for both.

Despite the differences, the type system in Figure~\ref{fig:implpar-coeff} follows the same 
structure as the earlier two examples. Context requirements are created when accessing an implicit
parameter (\emph{param}) (a system-specific rule). Structural rules (exchange, weaken, contract) 
do not affect the coeffects. For example parameters are reordered in (\emph{exch}),
but this has no effect as set union $\cup$ is commutative.

In abstraction and application, the structural $\cons$ operator (previously vector 
concatenation) becomes $\cup$. Sets of implicit parameters are not associated to
individual variables and so they are unioned. The (\emph{app}) rule uses $\cup$ to
combine the implicit parameters required by the function with the requirements of the argument too.

We call this a \emph{flat} coeffect system since coeffects have only
one shape (there is no scalar/vector distinction).  Other flat
coeffect systems may use a richer structure~\cite{petricek2013coeffects}. In
particular, the operations used in abstraction and application may differ
(to accommodate over-approximation). We return to this in
Section~\ref{sec:coeffects-structural}.

\paragraph{Example.} Unlike structural coeffect systems, flat systems
do not necessarily have principal coeffects. 
This arises from the (\emph{abs}) rule which can freely split
requirements between the function type and the declaring
context. Consider a function %filters news based on a location:
$\lambda ().\ident{?p}_1 + \ident{?p}_2$.  There are nine possible 
 type and coeffect derivations, two of which are:
%% 1 p1p2  p1p2
%% 2 p1p2  p1
%% 3 p1p2  p2
%% 4 p1p2  
%% 5 p1    p1p2
%% 6 p1    p2
%% 7 p2    p1p2
%% 8 p2    p1
%% 9       p1p2
\[
\begin{array}{rl}
\coctx{\emptyset}{ \{  \} } &\hspace{-0.7em}\vdash (\ldots) : 
  \ident{unit} \xrightarrow{ \{ \ident{?p}_1:\mathbb{Z}, \ident{?p}_2:\mathbb{Z} \} } \mathbb{Z}
\\
\coctx{\emptyset}{ \{ \ident{?p}_1:\mathbb{Z} \} } &\hspace{-0.7em} \vdash (\ldots) : 
  \ident{unit} \xrightarrow{ \{ \ident{?p}_2:\mathbb{Z} \} } \mathbb{Z}
\end{array}
\]
In the first case, both parameters are dynamically scoped and have to be provided by the caller.
In the second case, the parameter $\ident{?p}_1$ is available in the declaring scope and so it is
(lexically) captured.

Although structural coeffects have more desirable syntactic properties, we aim to capture this
non-principality too as it is practically useful -- Haskell's implicit parameters use it and
it can be used to model resource rebinding in distributed systems such as~\cite{app-distributed-acute}).

% --------------------------------------------------------------------------------------------------

\begin{figure}
\[
\tyrule{exch}
  {\coctx{\Gamma_1,x\!:\!\tau,y:\sigma,\Gamma_2}{r \cup \cclrd{s} \cup \cclrd{t} \cup \cclrd{q}} \vdash e : \tau}
  {\coctx{\Gamma_1,y\!:\!\sigma,x:\tau,\Gamma_2}{\cclrd{r} \cup \cclrd{t} \cup \cclrd{s} \cup \cclrd{q}} \vdash e : \tau}
\]
\[
\tyrule{app}
  { \coctx{\Gamma_1}{\cclrd{r}} \vdash e_1 : \sigma \xrightarrow{\cclrd{t}} \tau &
    \coctx{\Gamma_2}{\cclrd{s}} \vdash e_2 : \sigma }
  { \coctx{\Gamma_1, \Gamma_2}{\cclrd{r} \cup \cclrd{t} \cup \cclrd{s}} \vdash e_1 \, e_2 : \tau} 
\]
\[
\tyrule{param}{}
  {\coctx{()}{ \{ \ident{?p}:\tau \} } \vdash \ident{?p} : \tau}
\quad\;
\tyrule{abs}
  {\coctx{\Gamma, x \!:\! \sigma}{\cclrd{r} \cup \cclrd{s}} \vdash e : \tau}
  {\coctx{\Gamma}{\cclrd{r}} \vdash \lambda x . e : \sigma \xrightarrow{\cclrd{s}} \tau}
\]
\vspace{-0.5em}
\caption{Type and coeffect system for implicit parameters}
\label{fig:implpar-coeff}
\end{figure}

% ==================================================================================================

\section{Beyond passive contexts}

In the systems discussed so far, the context provides additional data (resources, implicit 
parameters, historical values) or meta-data (security, provenance). However, it is impossible to
write a function that modifies the context. We use the term \emph{passive} context for such 
applications. 

However, there is a number of systems where the context may be changed -- not just be evaluating
certain code block in a different scope (e.g. by wrapping it in $\ident{prev}$ in data-flow), but
also by calling a function that, for example, acquires new capabilities. While this thesis focuses
on systems with passive context, we quickly look at the most important examples of the 
\emph{active} variant.

% --------------------------------------------------------------------------------------------------

\paragraph{Calculus of capabilities}
Crary et al. \cite{app-capabilities} introduced the Calculus of Capabilities to provide 
a sound system with region-based memory management for low-level code that can be easily 
compiled to assembly language. They build on the work of Tofte and Talpin \cite{app-region-memory}
who developed an \emph{effect system} (discussed in Section~\ref{sec:path-sem-effects}) that uses
lexically scoped \emph{memory regions} to provide an efficient and controlled memory management.

In the work of Tofte and Talpin, the context is \emph{passive}. They extend a simple functional language
with the \kvd{letrgn} construct that defines a new memory region, evaluates an expression (possibly)
using memory in that region and then deallocates the memory of the region:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{calculate} = \lambda \ident{input} \rightarrow\\
\quad\kvd{letrgn}~\rho~\kvd{in}\\
\quad\kvd{let}~\ident{x} = \kvd{ref}_\rho \ident{input}~\kvd{in}~!\ident{x}
\end{array}
\end{equation*}
%
The memory region $\rho$ is a part of the context, but only in the scope of the body of 
\kvd{letrgn}. It is only available to the last line which allocates a memory cell in the region
and reads it (before the region is deallocated). There is no way to allocate a region inside a 
function and pass it back to the caller.

Calculus of capabilities differs in two ways. First, it allows explicit allocation and deallocation
of memory regions (and so region lifetimes do not follow strict LIFO ordering). Second, it
uses continuation-passing style. We ignore the latter aspect and so the following example:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{calculate} = \lambda \ident{input} \rightarrow\\
\quad \kvd{letrgn}~\rho~\kvd{in}\\
\quad \kvd{let}~\ident{x} = \kvd{ref}_\rho \ident{input}~\kvd{in}~\ident{x}
\end{array}
\end{equation*}
%
The example is almost identical to the previous one, except that it does not return the value
of reference \ident{x}. Instead, it returns the reference, which is located in a newly allocated
region. Together with the value, the function returns a \emph{capability} to access the region
$\rho$.

This is where systems with active context differ. To type check such programs, we do not only need
to know what context is required to call \ident{calculate}. We also need to know what effects it
has on the context when it evaluates and the current context meeds to be appropriately adjusted
after a function call. We briefly consider this problem in Section~X. % future work

% --------------------------------------------------------------------------------------------------

\paragraph{Software updating}
Dynamic software updating (DSU) \cite{app-dsu-programs,app-dsu} is the ability to update programs at
runtime without stopping them. The Proteus system developed by Stoyle et al. \cite{app-dsu-mutatis} 
investigates what language support is needed to enable safe dynamic software updating in C-like 
languages. The system is based on the idea of capabilities.

The system distinguishes between \emph{concrete} uses and \emph{abstract} uses of a value. When
a value is used concretely, the program examines its representation (and so it is not safe to
change the representation during an update). An abstract use of a value does not need to examine
the representation and so updating the value does not break the program.

The Proteus system uses capabilities to restrict what types may be used concretely after any point
in the program. All other types, not listed in the capability, can be dynamically updated as this
will not change concrete representation of types accessed later in the evaluation.

Similarly to Capability Calculus, capabilities in DSU can be changed by a function call. For 
example, calling a function that may update certain types makes it impossible to use those types
concretely following the function call. This means that DSU uses the context \emph{actively}
and not just \emph{passively}.

% --------------------------------------------------------------------------------------------------

\paragraph{Thesis perspective}

As demonstrated in this section, there is a huge number of systems and applications that exhibit
a form of context-dependence. The range includes different static analyses (liveness, provenance), 
well-known programming language features (implicit parameters and type classes) as well as features
not widely available (e.g. for distributed programming).

It is impossible to cover all of these topics in a single coherent thesis and so we focus on 
two key aspects:

\begin{compactitem}
\item \textbf{Flat vs. structural.} We look at both flat coeffects (single value for entire context) and 
  structural coeffects (single value per variable). We use liveness, implicit parameters and 
  data-flow to introduce flat coeffects (Section~X) and liveness, refined data-flow and tainting
  to talk about structural coeffects (Section~Y).
  
\item \textbf{Analysis vs. restriction.} Some of the discussed examples can be viewed as static
  analyses that obtain some information about programs (i.e.~the number of required past values
  in data-flow). Other examples provide type system that rules out certain invalid programs 
  (e.g.~safe locking). We cover this topic when discussing \emph{partial coeffects} in Section~Z.
  
\item \textbf{May vs. must analysis.} When discussing liveness, we observed that we can obtain 
  two different analyses depending on how conditionals are treated. We discuss this topic in 
  Section~X. % TBD - could be a chapter
\end{compactitem}

Although we also looked at examples of \emph{active} contextual computations (where developers can
write functions that modify the context), we do not consider these applications, to keep the 
material presented in this thesis focused. We briefly discuss them as future work in Section~X.

%===================================================================================================

\section{Context oriented programming}

The importance of context-aware computations is perhaps most obvious when considering mobile
application, client/server web applications or even the internet of things. A pioneering work
in the area using functional languages has been done by Serrano \cite{app-hop-diffuse,app-hop-lang}
(which also inspired the example presented in Chapter~\ref{ch:intro}). His HOP language supports 
cross-compilation and programs execute in different contexts. However, HOP is not statically 
type checked.

In the software engineering community, a number of authors have addressed the
problem of context-aware computations. Hirschfeld et al. propose \emph{Context-Oriented Programming} 
(COP) as a methodology \cite{app-cop-method}. The COP paradigm has been later implemented by
programming language features. Costanza \cite{app-cop-contextl} develops a domain-specific LISP-like 
language ContextL and Bardram \cite{app-cop-javafwk} proposes a Java framework for COP.

Finally, the subject of context-awareness has also been addressed in work focusing on the development 
of mobile applications \cite{app-cop-mobile,app-cop-mobile2}. Here, the \emph{context} focuses more 
on concrete physical context (obtained from the device sensors) than context as an abstract 
language feature.

We approach the problem from a different perspective, building on the tradition of 
statically-typed functional programming languages and their theories. 

%===================================================================================================

\section{Summary}

TODO

% \section{Missing}
% ~
% 
% indexed/layered/etc. monads, productors or whatever